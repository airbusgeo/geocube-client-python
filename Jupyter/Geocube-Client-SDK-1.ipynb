{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geocube SDK Tutorial\n",
    "\n",
    "-------\n",
    "\n",
    "#### Short description\n",
    "\n",
    "This notebook introduces you to the SDK framework with a complete Geocube workflow using the Python Client. You will see a typical workflow and how to parallelize an image processing algorithm.\n",
    "This notebook is in two chapters. The first presents the SDK, the second gives an example of a workflow.\n",
    "\n",
    "-------\n",
    "\n",
    "#### Requirements\n",
    "\n",
    "- Python 3.7\n",
    "- The Geocube Python Client library : https://github.com/airbusgeo/geocube-client-python.git\n",
    "- The url of a [Geocube Server](https://github.com/airbusgeo/geocube.git) & its Client ApiKey (for the purpose of this notebook, `GEOCUBE_SERVER` and `GEOCUBE_CLIENTAPIKEY` environment variable) - [Installation](https://github.com/airbusgeo/geocube/blob/main/INSTALL.MD) \n",
    "- The url of a [Geocube Downloader](https://github.com/airbusgeo/geocube/blob/main/INSTALL.MD#Downloader) (for the purpose of this notebook, `GEOCUBE_DOWNLOADER` environment variable)\n",
    "\n",
    "-------\n",
    "\n",
    "#### Table of content\n",
    "\n",
    "- [Part 1 - SDK](#SDK)\n",
    "  * [Connection Parameters](#Connection)\n",
    "  * [Downloader Service](#Downloader-Service)\n",
    "  * [Catalogue Functions](#Catalogue-functions)\n",
    "  * [Multiprocess and Dask](#Multiprocess-and-Dask)\n",
    "  * [XArray and Collection](#XArray-and-Collection)\n",
    "  \n",
    "  \n",
    "- [Part 2 - Geocube Workflow by example: Abnormal change detection](Geocube-Client-SDK-2.ipynb#Table-of-content) (Geocube-Client-SDK-2.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from shapely import geometry\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "from geocube import utils, entities, Consolidater, sdk\n",
    "\n",
    "# Define the connection to the server\n",
    "secure = False # in local, or true to use TLS\n",
    "geocube_client_server  = os.environ['GEOCUBE_SERVER']        # e.g. 127.0.0.1:8080 for local use\n",
    "geocube_client_api_key = os.environ['GEOCUBE_CLIENTAPIKEY']  # Usually empty for local use\n",
    "geocube_downloader_server = os.environ['GEOCUBE_DOWNLOADER']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDK\n",
    "Geocube Client Python provides several functions to easily scale-up an image processing pipeline.\n",
    "In particular, Geocube implements an [xarray](https://xarray.pydata.org/en/stable/) backend to access geocube images using the standard `xarray.Dataset`.\n",
    "\n",
    "As scaling-up a pipeline implies parallel computing, the Geocube entities are picklable to be transferred between processes.\n",
    "\n",
    "### Connection\n",
    "A `geocube.Client` is not picklable. `geocube.sdk` provides a convenient way to pass connection parameters: `sdk.ConnectionParams`. This function takes the same parameters as `geocube.Client` and has a function `new_client()` to connect to the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters to connect to the Geocube server\n",
    "connection_params = sdk.ConnectionParams(geocube_client_server, secure, geocube_client_api_key)\n",
    "\n",
    "# Connect to the server\n",
    "client = connection_params.new_client()\n",
    "print(\"Connected to server: \", client.version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloader Service\n",
    "Because the Geocube Server can be easily overwhelmed by a lot of connections, two solutions are possible to massively download data:\n",
    "- deploy several Geocube servers\n",
    "- run (locally or remotely) a lighter service that is in charge of downloading the images using metadata returned by the Geocube Server.\n",
    "\n",
    "The latter case is handled by the [Geocube Downloader service](https://github.com/airbusgeo/geocube/blob/main/cmd/downloader). It can be run as a docker:\n",
    "```bash\n",
    "export STORAGE=[...]\n",
    "docker run --rm -p 127.0.0.1:8081:8081/tcp -v $STORAGE:$STORAGE geocube-downloader -local -port 8081\n",
    "```\n",
    "Don't forget to mount all the local storage folders and give the proper access rights to the remote storages.\n",
    "More details on the [Geocube INSTALL.MD](https://github.com/airbusgeo/geocube/blob/main/INSTALL.MD#downloader).\n",
    "\n",
    "Downloader Service needs `CubeMetadata` to request a cube. It can be retrieved using `get_cube_metadata()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_params = entities.CubeParams.from_tile(\n",
    "    tile          = entities.Tile.from_bbox((573440., 6184960.,  593920., 6205440), crs=32632, resolution=20),\n",
    "    instance      = client.variable(\"RGB\").instance(\"master\"),\n",
    "    tags          = {\"source\":\"tutorial\"},\n",
    "    from_time     = datetime(2019, 1, 1),\n",
    "    to_time       = datetime(2019, 5, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geocube import Downloader\n",
    "downloader = Downloader(geocube_downloader_server)\n",
    "\n",
    "# Request metadata\n",
    "metadata = client.get_cube_metadata(cube_params)\n",
    "\n",
    "# Download the cube described by metadata\n",
    "images, _ = downloader.get_cube(metadata)\n",
    "\n",
    "print(\"Finished !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metadata\n",
    "`CubeMetadata` and `CubeMetadata.slices` contains all that is necessary to download and format the cube and 2d-slices of data : the underlying files, their internal data format, the mapping to `CubeMetadata.ref_dformat`, the records, the transform and the crs, the resampling algorithm...\n",
    "\n",
    "It can be used to have direct access to the file or change the resampling algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, s in enumerate(metadata.slices):\n",
    "    print(f\"Image {i}:\")\n",
    "    for file_metadata in s.metadata:\n",
    "        print(f\"   - file {file_metadata.container_uri}, subdir {file_metadata.container_subdir}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A client can be linked to a downloader and the former will automatically use the latter to download a cube of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.use_downloader(downloader)\n",
    "\n",
    "# Or using ConnectionParams\n",
    "connection_params = sdk.ConnectionParams(geocube_client_server, secure, geocube_client_api_key,\n",
    "                                         downloader=sdk.ConnectionParams(geocube_downloader_server))\n",
    "client = connection_params.new_client()\n",
    "\n",
    "_ = client.get_cube(cube_params, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catalogue functions\n",
    "`sdk.get_cube()` is a convenient function to process a cube of data in a parallel workflow.\n",
    "It takes `ConnectionParams` and `CubeParams`, downloads the cube and process it.\n",
    "\n",
    "Two callback functions can be passed as parameter of this function:\n",
    "- `image_callback` will be called for every image received by `get_cube` (see `sdk.image_callback_t`). It has to return an image  and takes as parameters:\n",
    "  * `image`\n",
    "  * `grouped_records` (optional)\n",
    "  * `crs` or `projection`  (optional)\n",
    "  * `transform` (optional)\n",
    "- `cube_callback` will be called with the results of a `get_cube` (see `sdk.cube_callback_t`). The result of this function will be the returned value of `get_cube()`. It takes as parameters:\n",
    "  * `timeseries` or `cube`\n",
    "  * `grouped_records` (optional)\n",
    "  * `crs` or `projection` (optional)\n",
    "  * `transform` (optional): geotransform\n",
    "\n",
    "All these fields will be automatically provided by `get_cube()` if they are defined.\n",
    "\n",
    "`sdk.get_cube` is equivalent to:\n",
    "```python\n",
    "def sdk.get_cube():\n",
    "    for image in client.get_cube():\n",
    "        image = image_callback(image, [grouped_records, crs, projection, transform])\n",
    "        cube.append(image)\n",
    "    return cube_allback(cube, [grouped_records, crs, projection, transform])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from geocube import utils\n",
    "import functools\n",
    "\n",
    "def mean(timeseries, projection, transform, instance):\n",
    "    \"\"\" Compute the mean of a timeseries over time and save it as a GeoTiff\"\"\"\n",
    "    if len(timeseries) != 0:\n",
    "        m = np.nanmean(timeseries, axis=-1)\n",
    "        filename=\"outputs/\" + (\"_\".join([f\"{v:.2f}\" for v in transform.to_gdal()]))+\".tiff\"\n",
    "        utils.image_to_geotiff(m, transform, projection, instance.dformat.no_data, filename)\n",
    "        return filename\n",
    "    return None\n",
    "\n",
    "# Download cube and call mean().\n",
    "sdk.get_cube(connection_params, cube_params, cube_callback=functools.partial(mean, instance=client.variable(\"RGB\").instance(\"master\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocess and Dask\n",
    "The `sdk.get_cube()` function can be used for parallel processing as well as any picklable user-defined function.\n",
    "With `dask.delayed`, a pool of tasks can be easily created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import functools\n",
    "\n",
    "# Define the AOI, the records and the instance\n",
    "aoi = utils.read_aoi('inputs/Denmark.json')\n",
    "records = client.list_records(aoi=aoi, tags={\"source\":\"tutorial\"})\n",
    "instance = client.variable(\"RGB\").instance(\"master\")\n",
    "\n",
    "# Tile the AOI and create the pool of tasks\n",
    "tiles = client.tile_aoi(aoi, resolution=20, crs=\"epsg:32632\", shape=(1024,1024))\n",
    "tasks = [dask.delayed(sdk.get_cube)(\n",
    "    connection_params=connection_params,\n",
    "    cube_params=entities.CubeParams.from_tile(t, records=records, instance=instance),\n",
    "    cube_callback=functools.partial(mean, instance=instance))\n",
    "         for t in tiles]\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 16]\n",
    "print(f\"Plot {len(tiles)} tiles...\")\n",
    "entities.Tile.plot(tiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tasks can be computed using `dask.scheduler`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.config.set(scheduler='synchronous')\n",
    "dask.compute(tasks)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or with `dask.distributed`\n",
    "```shell\n",
    "python -m pip install \"dask[distributed]\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, wait\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "c = None\n",
    "\n",
    "try:\n",
    "    c = Client(n_workers=4)\n",
    "    futures = c.compute(tasks)\n",
    "\n",
    "    with tqdm(total=len(futures)) as pbar:\n",
    "        while len(futures) > 0:\n",
    "            nf = []\n",
    "            for f in futures:\n",
    "                if f.status==\"finished\":\n",
    "                    pbar.update(1)\n",
    "                else:\n",
    "                    nf.append(f)\n",
    "                    if f.status == \"error\":\n",
    "                        print(\"retry\", f)\n",
    "                        f.retry()\n",
    "            time.sleep(0.5)\n",
    "            futures = nf\n",
    "    print(\"done\")\n",
    "finally:\n",
    "    if c is not None:\n",
    "        c.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask on GCP\n",
    "\n",
    "reference: https://cloudprovider.dask.org/en/latest/gcp.html\n",
    "\n",
    "#### Installation\n",
    "\n",
    "``` bash\n",
    "pip install dask-cloudprovider[gcp]>=2022.3.3 Jinja2>=3\n",
    "```\n",
    "\n",
    "Dask runs a docker on gcp workers. To build a docker embedding dask, geocube-client-python and a downloader client, run the following command in the <geocube-client-python> root folder:\n",
    "``` bash\n",
    "docker build -f docker/Dockerfile.dask-downloader -t dask-downloader:<tag> .\n",
    "```\n",
    "The downloader client is available with the following configuration: \n",
    "```python\n",
    "sdk.ConnectionParams(\"localhost:8083\")\n",
    "```\n",
    "\n",
    "Feel free to edit the dockerfile with your own librairies or use the dask-standard environnement variables `EXTRA_APT_PACKAGES` and `EXTRA_PIP_PACKAGES` (add `docker_args=\"-e EXTRA_PIP_PACKAGES \"... ...\"` when creating the cluster)\n",
    "    \n",
    "    \n",
    "#### Configuration \n",
    "\n",
    "In `~/.config/dask`, you can create or edit two configuration files:\n",
    "\n",
    "- **cloudprovider.yaml**: where it is possible to configure the image used, the type of VM, the GCP project etc. The elements defined in this file will be the default values when instantiating a GCPCluster object.\n",
    "\n",
    "Ex:\n",
    "``` yaml\n",
    "cloudprovider:\n",
    "  gcp:\n",
    "    source_image: \"projects/ubuntu-os-cloud/global/images/ubuntu-minimal-2004-focal-v20220419a\" # the gcp image to use for all instances (`gcloud compute images list`)\n",
    "    zone: \"<zone-id>\" # the zone of where to launch the instances (eg: europe-west1-d)\n",
    "    network: \"<subnet>\" # the network/subnetwork in GCP to use\n",
    "    network_projectid: null # GCP project id where the network exists\n",
    "    projectid: \"<project-id>\" # name of the google cloud project\n",
    "    on_host_maintenance: \"TERMINATE\"\n",
    "    machine_type: \"n1-standard-16\" # size of the machine type to use (`gcloud compute machine-types list`)\n",
    "    filesystem_size: 50 # amount in GBs of hard drive space to allocate\n",
    "    ngpus: \"\" # number of GPUs to use\n",
    "    gpu_type: \"\" # type of gpus to use: nvidia-tesla-k80, nvidia-tesla-p100, nvidia-tesla-t4\n",
    "    disk_type: \"pd-ssd\" # type of disk to use: pd-standard, pd-ssd\n",
    "    docker_image: \"<image>:<tag>\" # docker image to use (eg. eu.gcr.io/<project-id>/<image>:<tag>)\n",
    "    auto_shutdown: true # Shutdown instances automatically if the scheduler or worker services time out.\n",
    "    preemptible: true  # Whether to use preemptible instances for workers\n",
    "    public_ingress: true # configure the scheduler to be externally accessible.  This assumes firefwall rules for 8787 and 8786\n",
    "    extra_bootstrap: [\"gcloud auth print-access-token | docker login -u oauth2accesstoken --password-stdin https://eu.gcr.io\"] # If the image is private and stored in the gcp registry\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "- **debug.yaml**: where it is possible to define logging strategy\n",
    "\n",
    "Ex:\n",
    "\n",
    "``` yaml\n",
    "\n",
    "logging:\n",
    "  version: 1\n",
    "  handlers:\n",
    "    file:\n",
    "      class: logging.handlers.RotatingFileHandler\n",
    "      filename: output.log\n",
    "      level: INFO\n",
    "    console:\n",
    "      class: logging.StreamHandler\n",
    "      level: INFO\n",
    "  loggers:\n",
    "    distributed.worker:\n",
    "      level: INFO\n",
    "      handlers:\n",
    "        - file\n",
    "        - console\n",
    "    distributed.scheduler:\n",
    "      level: INFO\n",
    "      handlers:\n",
    "        - file\n",
    "        - console\n",
    "```\n",
    "\n",
    "#### Prerequisite\n",
    "\n",
    "- Build and push the dask-downloader docker image\n",
    "- Grant the appropriate rights to the default service account for pulling the docker image.\n",
    "- Set your GCP authentication credentials.\n",
    "\n",
    "#### Create GCPCluster\n",
    "\n",
    "1. A scheduler VM is created\n",
    "2. The dask-downloader docker image is pulled and dask-scheduler is started\n",
    "3. Multiple Workers VM are created (n_workers=number of VM)\n",
    "\n",
    "NB: \n",
    "- It takes a couple of minutes to create the scheduler and the workers. Be patient ! Connect to the VM and look at the logs if you think it takes longer than usual.\n",
    "```shell\n",
    "gcloud compute ssh --project=<PROJECT-ID> --zone <ZONE> <dask-########-scheduler> --command \"tail /var/log/cloud-init-output.log -n 100 -f\"\n",
    "```\n",
    "- If the docker image is stored on a private container registry, you need to log docker using extra_boostrap. (see: https://cloudprovider.dask.org/en/latest/troubleshooting.html#pulling-private-docker-images)\n",
    "- By default, the scheduler runs on 8786 port and the dashboard is viewable on 8787. If these ports are blocked, they can be override using for example `scheduler_options={\"port\":\"8080\", \"dashboard_address\":\"80\"}`.\n",
    "- **Don't forget to close the cluster with `cluster.close()` or manually delete the vm in case of failure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_cloudprovider.gcp import GCPCluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "# Create Cluster\n",
    "cluster = GCPCluster(n_workers=1, scheduler_options={\"port\":\"8080\"}, docker_args=\"-v /var/log/container:/var/log\")\n",
    "\n",
    "# Create client\n",
    "gcpclient = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To connect to the downloader embedded in the dask worker, use `sdk.ConnectionParams(\"127.0.0.1:8083\")`. It will be faster than using the geocube to download the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "\n",
    "@dask.delayed\n",
    "def get_cube(connection_params, cube_params):\n",
    "    connection_params.downloader = sdk.ConnectionParams(\"127.0.0.1:8083\")\n",
    "    client = connection_params.new_client()\n",
    "    return client.get_cube(cube_params, verbose=True)\n",
    "\n",
    "images, records = get_cube(connection_params, cube_params).compute()\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(images[0][...,0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to close the client and the cluster to delete the virtual machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcpclient.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logging and debug\n",
    "\n",
    "Logs are available :\n",
    "- in the VM: `/var/log/cloud-init-output.log` and `/var/log/cloud-init.log`\n",
    "- in the container: `/var/log/downloader_output.log` and `/var/log/python_output.log` or directly in the `/var/log/container` folder of the VM with `docker_args=\"-v /var/log/container:/var/log\"` argument when creating `GCPCluster` .\n",
    "\n",
    "\n",
    "`gcloud compute ssh --project=<PROJECT-ID> --zone <ZONE> <dask-########-worker-########> --command \"tail /var/log/container/python_output.log -n 100 -f\"`\n",
    "\n",
    "With `debug=True`, GCPCluster prints some logs:\n",
    "\n",
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = GCPCluster(n_workers=1, debug=True, docker_args=\"-v /var/log/container:/var/log\")\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XArray and Collection\n",
    "A `Collection` describes a collection of datasets corresponding to several variables and a set of records.\n",
    "It is readable by `xarray`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray\n",
    "from geocube import sdk, entities\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# Create a tile\n",
    "record = client.list_records(\"S2B_MSIL1C_20190105T103429_N0207_R108_T32UNG_20190105T122413\", with_aoi=True)[0]\n",
    "tile = entities.Tile.from_record(record=record, crs=\"epsg:32632\", resolution=20)\n",
    "\n",
    "# Select variables\n",
    "instances = [\n",
    "    client.variable(\"RGB\").instance(\"master\"),\n",
    "    client.variable(\"NDVI\").instance(\"master\")\n",
    "]\n",
    "\n",
    "# Select records\n",
    "records = client.list_records(tags={'source':'tutorial','constellation':'SENTINEL2'})\n",
    "\n",
    "# Create collection\n",
    "collection = sdk.Collection.from_tile(tile, records=records, instances=instances)\n",
    "\n",
    "# Open collection\n",
    "#ds = xarray.open_dataset(collection, connection_params=connection_params, block_size=(256, 256), engine=sdk.GeocubeBackendEntrypoint)\n",
    "ds = sdk.open_geocube(collection, connection_params=connection_params, block_size=(256, 256))\n",
    "\n",
    "# Get timeseries of RGB\n",
    "images = ds[\"RGB:master\"][0:1000,3000:4000].compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nbimages=images.shape[3]\n",
    "plt.rcParams['figure.figsize'] = [20, 16]\n",
    "for f in range(0, nbimages):\n",
    "    plt.subplot(math.ceil(nbimages/4), 4, f+1).set_axis_off()\n",
    "    plt.imshow(images[:,:,:, f]/255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next step: demonstration of a full workflow by example\n",
    "In the [next notebook](Geocube-Client-SDK-2.ipynb), the sdk will be used to address a simple but typical use-case: abnormal change detection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
