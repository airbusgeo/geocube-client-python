{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geocube SDK Tutorial\n",
    "\n",
    "-------\n",
    "\n",
    "#### Short description\n",
    "\n",
    "This notebook introduces you to the SDK framework with a complete Geocube workflow using the Python Client. You will see a typical workflow and how to parallelize an image processing algorithm.\n",
    "This notebook is in two chapters. The first presents the SDK, the second gives an example of a workflow.\n",
    "\n",
    "-------\n",
    "\n",
    "#### Requirements\n",
    "\n",
    "- Python 3.7\n",
    "- The Geocube Python Client library : https://github.com/airbusgeo/geocube-client-python.git\n",
    "- The url of a [Geocube Server](https://github.com/airbusgeo/geocube.git) & its Client ApiKey (for the purpose of this notebook, `GEOCUBE_SERVER` and `GEOCUBE_CLIENTAPIKEY` environment variable) - [Installation](https://github.com/airbusgeo/geocube/blob/main/INSTALL.MD) \n",
    "- The url of a [Geocube Downloader](https://github.com/airbusgeo/geocube/blob/main/INSTALL.MD#Downloader) (for the purpose of this notebook, `GEOCUBE_DOWNLOADER` environment variable)\n",
    "\n",
    "-------\n",
    "\n",
    "#### Table of content\n",
    "\n",
    "- [Part 1 - SDK](#SDK)\n",
    "  * [Connection Parameters](#Connection)\n",
    "  * [Downloader Service](#Downloader-Service)\n",
    "  * [Catalogue Functions](#Catalogue-functions)\n",
    "  * [Multiprocess and Dask](#Multiprocess-and-Dask)\n",
    "  * [XArray and Collection](#XArray-and-Collection)\n",
    "  \n",
    "  \n",
    "- [Part 2 - Geocube Workflow by example: Abnormal change detection](Geocube-Client-SDK-2.ipynb#Table-of-content) (Geocube-Client-SDK-2.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from shapely import geometry\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "from geocube import utils, entities, Consolidater, sdk\n",
    "\n",
    "# Define the connection to the server\n",
    "secure = False # in local, or true to use TLS\n",
    "geocube_client_server  = os.environ['GEOCUBE_SERVER']        # e.g. 127.0.0.1:8080 for local use\n",
    "geocube_client_api_key = os.environ['GEOCUBE_CLIENTAPIKEY']  # Usually empty for local use\n",
    "geocube_downloader_server = os.environ['GEOCUBE_DOWNLOADER']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDK\n",
    "Geocube Client Python provides several functions to easily scale-up an image processing pipeline.\n",
    "In particular, Geocube implements an [xarray](https://xarray.pydata.org/en/stable/) backend to access geocube images using the standard `xarray.Dataset`.\n",
    "\n",
    "As scaling-up a pipeline implies parallel computing, the Geocube entities are picklable to be transferred between processes.\n",
    "\n",
    "### Connection\n",
    "A `geocube.Client` is not picklable. `geocube.sdk` provides a convenient way to pass connection parameters: `sdk.ConnectionParams`. This function takes the same parameters as `geocube.Client` and has a function `new_client()` to connect to the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters to connect to the Geocube server\n",
    "connection_params = sdk.ConnectionParams(geocube_client_server, secure, geocube_client_api_key)\n",
    "\n",
    "# Connect to the server\n",
    "client = connection_params.new_client()\n",
    "print(\"Connected to server: \", client.version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloader Service\n",
    "Because the Geocube Server can be easily overwhelmed by a lot of connections, two solutions are possible to massively download data:\n",
    "- deploy several Geocube servers\n",
    "- run (locally or remotely) a lighter service that is in charge of downloading the images using metadata returned by the Geocube Server.\n",
    "\n",
    "The latter case is handled by the [Geocube Downloader service](https://github.com/airbusgeo/geocube/blob/main/cmd/downloader). It can be run as a docker:\n",
    "```bash\n",
    "export STORAGE=[...]\n",
    "docker run --rm -p 127.0.0.1:8081:8081/tcp -v $STORAGE:$STORAGE geocube-downloader -local -port 8081\n",
    "```\n",
    "Don't forget to mount all the local storage folders and give the proper access rights to the remote storages.\n",
    "More details on the [Geocube INSTALL.MD](https://github.com/airbusgeo/geocube/blob/main/INSTALL.MD#downloader).\n",
    "\n",
    "Downloader Service needs `CubeMetadata` to request a cube. It can be retrieved using `get_cube_metadata()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geocube import Downloader\n",
    "downloader = Downloader(geocube_downloader_server)\n",
    "\n",
    "\n",
    "cube_params = entities.CubeParams.from_tile(\n",
    "    tile          = entities.Tile.from_bbox((573440., 6184960.,  593920., 6205440), crs=32632, resolution=20),\n",
    "    instance      = client.variable(\"RGB\").instance(\"master\"),\n",
    "    tags          = {\"source\":\"tutorial\"},\n",
    "    from_time     = datetime(2019, 1, 1),\n",
    "    to_time       = datetime(2019, 5, 1),\n",
    ")\n",
    "\n",
    "# Request metadata\n",
    "metadata = client.get_cube_metadata(cube_params)\n",
    "\n",
    "# Download the cube described by metadata\n",
    "images, _ = downloader.get_cube(metadata)\n",
    "\n",
    "print(\"Finished !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metadata\n",
    "`CubeMetadata` and `CubeMetadata.slices` contains all that is necessary to download and format the cube and 2d-slices of data : the underlying files, their internal data format, the mapping to `CubeMetadata.ref_dformat`, the records, the transform and the crs, the resampling algorithm...\n",
    "\n",
    "It can be used to have direct access to the file or change the resampling algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, s in enumerate(metadata.slices):\n",
    "    print(f\"Image {i}:\")\n",
    "    for file_metadata in s.metadata:\n",
    "        print(f\"   - file {file_metadata.container_uri}, subdir {file_metadata.container_subdir}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A client can be linked to a downloader and the former will automatically use the latter to download a cube of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.use_downloader(downloader)\n",
    "\n",
    "# Or using ConnectionParams\n",
    "connection_params = sdk.ConnectionParams(geocube_client_server, secure, geocube_client_api_key,\n",
    "                                         downloader=sdk.ConnectionParams(geocube_downloader_server))\n",
    "client = connection_params.new_client()\n",
    "\n",
    "_ = client.get_cube(cube_params, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catalogue functions\n",
    "`sdk.get_cube()` is a convenient function to process a cube of data in a parallel workflow.\n",
    "It takes `ConnectionParams` and `CubeParams`, downloads the cube and process it.\n",
    "\n",
    "Two callback functions can be passed as parameter of this function:\n",
    "- `image_callback` will be called for every image received by `get_cube` (see `sdk.image_callback_t`). It has to return an image  and takes as parameters:\n",
    "  * `image`\n",
    "  * `grouped_records` (optional)\n",
    "  * `crs` or `projection`  (optional)\n",
    "  * `transform` (optional)\n",
    "- `cube_callback` will be called with the results of a `get_cube` (see `sdk.cube_callback_t`). The result of this function will be the returned value of `get_cube()`. It takes as parameters:\n",
    "  * `timeseries` or `cube`\n",
    "  * `grouped_records` (optional)\n",
    "  * `crs` or `projection` (optional)\n",
    "  * `transform` (optional): geotransform\n",
    "\n",
    "All these fields will be automatically provided by `get_cube()` if they are defined.\n",
    "\n",
    "`sdk.get_cube` is equivalent to:\n",
    "```python\n",
    "def sdk.get_cube():\n",
    "    for image in client.get_cube():\n",
    "        image = image_callback(image, [grouped_records, crs, projection, transform])\n",
    "        cube.append(image)\n",
    "    return cube_allback(cube, [grouped_records, crs, projection, transform])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from geocube import utils\n",
    "import functools\n",
    "\n",
    "def mean(timeseries, projection, transform, instance):\n",
    "    \"\"\" Compute the mean of a timeseries over time and save it as a GeoTiff\"\"\"\n",
    "    if len(timeseries) != 0:\n",
    "        m = np.nanmean(timeseries, axis=-1)\n",
    "        filename=\"outputs/\" + (\"_\".join([f\"{v:.2f}\" for v in transform.to_gdal()]))+\".tiff\"\n",
    "        utils.image_to_geotiff(m, transform, projection, instance.dformat.no_data, filename)\n",
    "        return filename\n",
    "    return None\n",
    "\n",
    "# Download cube and call mean().\n",
    "sdk.get_cube(connection_params, cube_params, cube_callback=functools.partial(mean, instance=client.variable(\"RGB\").instance(\"master\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocess and Dask\n",
    "The `sdk.get_cube()` function can be used for parallel processing as well as any picklable user-defined function.\n",
    "With `dask.delayed`, a pool of tasks can be easily created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import functools\n",
    "\n",
    "# Define the AOI, the records and the instance\n",
    "aoi = utils.read_aoi('inputs/Denmark.json')\n",
    "records = client.list_records(aoi=aoi, tags={\"source\":\"tutorial\"})\n",
    "instance = client.variable(\"RGB\").instance(\"master\")\n",
    "\n",
    "# Tile the AOI and create the pool of tasks\n",
    "tiles = client.tile_aoi(aoi, resolution=20, crs=\"epsg:32632\", shape=(1024,1024))\n",
    "tasks = [dask.delayed(sdk.get_cube)(\n",
    "    connection_params=connection_params,\n",
    "    cube_params=entities.CubeParams.from_tile(t, records=records, instance=instance),\n",
    "    cube_callback=functools.partial(mean, instance=instance))\n",
    "         for t in tiles]\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 16]\n",
    "print(f\"Plot {len(tiles)} tiles...\")\n",
    "entities.Tile.plot(tiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tasks can be computed using `dask.scheduler`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.config.set(scheduler='synchronous')\n",
    "dask.compute(tasks)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or with `dask.distributed`\n",
    "```shell\n",
    "python -m pip install \"dask[distributed]\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, wait\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "c = None\n",
    "\n",
    "try:\n",
    "    c = Client(n_workers=4)\n",
    "    futures = c.compute(tasks)\n",
    "\n",
    "    with tqdm(total=len(futures)) as pbar:\n",
    "        while len(futures) > 0:\n",
    "            nf = []\n",
    "            for f in futures:\n",
    "                if f.status==\"finished\":\n",
    "                    pbar.update(1)\n",
    "                else:\n",
    "                    nf.append(f)\n",
    "                    if f.status == \"error\":\n",
    "                        print(\"retry\", f)\n",
    "                        f.retry()\n",
    "            time.sleep(0.5)\n",
    "            futures = nf\n",
    "    print(\"done\")\n",
    "finally:\n",
    "    if c is not None:\n",
    "        c.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XArray and Collection\n",
    "A `Collection` describes a collection of datasets corresponding to several variables and a set of records.\n",
    "It is readable by `xarray`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray\n",
    "from geocube import sdk, entities\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# Create a tile\n",
    "record = client.list_records(\"S2B_MSIL1C_20190105T103429_N0207_R108_T32UNG_20190105T122413\", with_aoi=True)[0]\n",
    "tile = entities.Tile.from_record(record=record, crs=\"epsg:32632\", resolution=20)\n",
    "\n",
    "# Select variables\n",
    "instances = [\n",
    "    client.variable(\"RGB\").instance(\"master\"),\n",
    "    client.variable(\"NDVI\").instance(\"master\")\n",
    "]\n",
    "\n",
    "# Select records\n",
    "records = client.list_records(tags={'source':'tutorial','constellation':'SENTINEL2'})\n",
    "\n",
    "# Create collection\n",
    "collection = sdk.Collection.from_tile(tile, records=records, instances=instances)\n",
    "\n",
    "# Open collection\n",
    "#ds = xarray.open_dataset(collection, connection_params=connection_params, block_size=(256, 256), engine=sdk.GeocubeBackendEntrypoint)\n",
    "ds = sdk.open_geocube(collection, connection_params=connection_params, block_size=(256, 256))\n",
    "\n",
    "# Get timeseries of RGB\n",
    "images = ds[\"RGB:master\"][0:1000,3000:4000].compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nbimages=images.shape[3]\n",
    "plt.rcParams['figure.figsize'] = [20, 16]\n",
    "for f in range(0, nbimages):\n",
    "    plt.subplot(math.ceil(nbimages/4), 4, f+1).set_axis_off()\n",
    "    plt.imshow(images[:,:,:, f]/255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next step: demonstration of a full workflow by example\n",
    "In the [next notebook](Geocube-Client-SDK-2.ipynb), the sdk will be used to address a simple but typical use-case: abnormal change detection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
