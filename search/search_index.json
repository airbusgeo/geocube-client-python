{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Geocube Client Python Geocube Python Client Library is delivered as an example of a client for a Geocube server . Credits Geocube is a project under development by Airbus DS Geo SA with the support of CNES . Geocube-Client-Python is licensed under the Apache License, Version 2.0. See LICENSE for the full license text.","title":"Home"},{"location":"#geocube-client-python","text":"Geocube Python Client Library is delivered as an example of a client for a Geocube server .","title":"Geocube Client Python"},{"location":"#credits","text":"Geocube is a project under development by Airbus DS Geo SA with the support of CNES . Geocube-Client-Python is licensed under the Apache License, Version 2.0. See LICENSE for the full license text.","title":"Credits"},{"location":"quickstart/","text":"Quickstart Requirements Python >= 3.7 An instance of the Geocube Server , its url and, depending on the configuration, its ApiKey Installation pip install git+https://github.com/airbusgeo/geocube-client-python.git Connect to the server Start a python console and type import geocube import os client = geocube.Client(\"127.0.0.1:8080\") # Or client = geocube.Client(os.environ['GEOCUBE_SERVER'], True, os.environ['GEOCUBE_CLIENTAPIKEY']) You are connected ! Then, you can do the tutorials to learn how to feed the geocube, access and optimize the data.","title":"Getting started"},{"location":"quickstart/#quickstart","text":"","title":"Quickstart"},{"location":"quickstart/#requirements","text":"Python >= 3.7 An instance of the Geocube Server , its url and, depending on the configuration, its ApiKey","title":"Requirements"},{"location":"quickstart/#installation","text":"pip install git+https://github.com/airbusgeo/geocube-client-python.git","title":"Installation"},{"location":"quickstart/#connect-to-the-server","text":"Start a python console and type import geocube import os client = geocube.Client(\"127.0.0.1:8080\") # Or client = geocube.Client(os.environ['GEOCUBE_SERVER'], True, os.environ['GEOCUBE_CLIENTAPIKEY']) You are connected ! Then, you can do the tutorials to learn how to feed the geocube, access and optimize the data.","title":"Connect to the server"},{"location":"about/CONTRIBUTING/","text":"How to contribute Thank you for stopping by. Please read these few small guidelines before creating an issue or a pull request. Reporting issues Bugs, feature requests, and development-related questions should be directed to our GitHub issue tracker . If reporting a bug, please try and provide as much context as possible and a reproducible test case. Submitting a patch Patches are to be submitted through pull-requests: https://docs.github.com/en/github/collaborating-with-issues-and-pull-requests/creating-a-pull-request Make sure each group of changes be done in distinct branches in order to ensure that a pull request only includes code related to that bug or feature. Always run go fmt on your code before committing it. Do not squash / force-push your commits inside the pull request branch as these tend to mess up the review comments.","title":"Contributing"},{"location":"about/CONTRIBUTING/#how-to-contribute","text":"Thank you for stopping by. Please read these few small guidelines before creating an issue or a pull request.","title":"How to contribute"},{"location":"about/CONTRIBUTING/#reporting-issues","text":"Bugs, feature requests, and development-related questions should be directed to our GitHub issue tracker . If reporting a bug, please try and provide as much context as possible and a reproducible test case.","title":"Reporting issues"},{"location":"about/CONTRIBUTING/#submitting-a-patch","text":"Patches are to be submitted through pull-requests: https://docs.github.com/en/github/collaborating-with-issues-and-pull-requests/creating-a-pull-request Make sure each group of changes be done in distinct branches in order to ensure that a pull request only includes code related to that bug or feature. Always run go fmt on your code before committing it. Do not squash / force-push your commits inside the pull request branch as these tend to mess up the review comments.","title":"Submitting a patch"},{"location":"about/help/","text":"Do not hesitate to ask for help or report issues .","title":"Getting help"},{"location":"about/license/","text":"Geocube-Client-Python is licensed under the Apache License, Version 2.0. See LICENSE for the full license text.","title":"License"},{"location":"about/release-notes/","text":"Release notes","title":"Release Notes"},{"location":"about/release-notes/#release-notes","text":"","title":"Release notes"},{"location":"user-guide/grpc/","text":"Update GRPC Interface Geocube-Client-Python uses the protobuf GRPC interface, automatically generated from the protobuf files provided by the Geocube . The pb files can be generated using the package grpcio-tools , the geocube protobuf folder and the following commands: sed -i \"s/import \\\"pb/import \\\"geocube\\/pb/g\" <temp folder>/geocube/pb/*.proto python3 -m grpc_tools.protoc -I <temp folder> -I ../geocube/api/v1/ --python_out=. geocube/pb/geocube.proto geocube/pb/catalog.proto geocube/pb/records.proto geocube/pb/dataformat.proto geocube/pb/variables.proto geocube/pb/layouts.proto geocube/pb/operations.proto python3 -m grpc_tools.protoc -I <temp folder> -I ../geocube/api/v1/ --grpc_python_out=. geocube/pb/geocube.proto python3 -m grpc_tools.protoc -I <temp folder> -I ../geocube/api/v1/ --python_out=. --grpc_python_out=. geocube/pb/admin.proto","title":"GRPC Interface"},{"location":"user-guide/grpc/#update-grpc-interface","text":"Geocube-Client-Python uses the protobuf GRPC interface, automatically generated from the protobuf files provided by the Geocube . The pb files can be generated using the package grpcio-tools , the geocube protobuf folder and the following commands: sed -i \"s/import \\\"pb/import \\\"geocube\\/pb/g\" <temp folder>/geocube/pb/*.proto python3 -m grpc_tools.protoc -I <temp folder> -I ../geocube/api/v1/ --python_out=. geocube/pb/geocube.proto geocube/pb/catalog.proto geocube/pb/records.proto geocube/pb/dataformat.proto geocube/pb/variables.proto geocube/pb/layouts.proto geocube/pb/operations.proto python3 -m grpc_tools.protoc -I <temp folder> -I ../geocube/api/v1/ --grpc_python_out=. geocube/pb/geocube.proto python3 -m grpc_tools.protoc -I <temp folder> -I ../geocube/api/v1/ --python_out=. --grpc_python_out=. geocube/pb/admin.proto","title":"Update GRPC Interface"},{"location":"user-guide/tutorials/","text":"Tutorials Feed the Geocube - Indexation Please follow the Data Indexation Jupyter notebook Access to the Geocube Please follow the Data Access Jupyter notebook Optimize the dataformat (Consolidation) Please follow the Consolidation Jupyter notebook Scale-up Please follow the SDK Jupyter notebook-1 and SDK Jupyter notebook-2","title":"Tutorials"},{"location":"user-guide/tutorials/#tutorials","text":"","title":"Tutorials"},{"location":"user-guide/tutorials/#feed-the-geocube-indexation","text":"Please follow the Data Indexation Jupyter notebook","title":"Feed the Geocube - Indexation"},{"location":"user-guide/tutorials/#access-to-the-geocube","text":"Please follow the Data Access Jupyter notebook","title":"Access to the Geocube"},{"location":"user-guide/tutorials/#optimize-the-dataformat-consolidation","text":"Please follow the Consolidation Jupyter notebook","title":"Optimize the dataformat (Consolidation)"},{"location":"user-guide/tutorials/#scale-up","text":"Please follow the SDK Jupyter notebook-1 and SDK Jupyter notebook-2","title":"Scale-up"},{"location":"user-guide/client/admin-reference/","text":"Admin Bases: Consolidater Source code in geocube/admin.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 class Admin ( Consolidater ): def __init__ ( self , uri : str , secure : bool = False , api_key : str = \"\" , verbose : bool = True ): \"\"\" Initialise the connexion to the Geocube Server Args: uri: of the Geocube Server secure: True to use a TLS Connexion api_key: (optional) API Key if Geocube Server is secured using a bearer authentication verbose: display the version of the Geocube Server \"\"\" super () . __init__ ( uri , secure , api_key , verbose ) self . admin_stub = Stub ( admin_pb2_grpc . AdminStub ( self . _channel )) def set_timeout ( self , timeout_sec : float ): super () . set_timeout ( timeout_sec ) self . admin_stub . timeout = timeout_sec def admin_tidy ( self , aois : bool = False , records : bool = False , variables : bool = False , instances : bool = False , containers : bool = False , consolidation_params : bool = False , simulate : bool = True ): \"\"\" Admin function to tidy the Geocube Database. Remove all the entities that are not linked to any dataset. Should be used with caution when no ingestion or indexation task is in progress. Args: aois: remove the pending AOI records: remove the pending Records variables: remove the pending Variables instances: remove the pending Instances containers: remove the pending Containers consolidation_params: remove the pending ConsolidationParams simulate: if True no operation is performed. Only the number of entities that would have been deleted \"\"\" return self . _admin_tidy ( aois , records , variables , instances , containers , consolidation_params , simulate ) def admin_update_datasets ( self , instance : Union [ str , entities . VariableInstance ], records : List [ Union [ str , entities . Record ]], dformat : Union [ Dict , Tuple , str ], min_out : float , max_out : float , exponent : float , simulate : bool ): \"\"\" Admin function to update some sensitive information of datasets referenced by an instance and a list of records Args: instance: select the datasets that are referenced by this instance records: select the datasets that are referenced by these records dformat: new dataformat min_out: new min_out max_out: new max_out exponent: new exponent simulate: if True, no operation is performed. Only display the datasets that would have been updated. \"\"\" self . _admin_update_datasets ( instance , records , dformat , min_out , max_out , exponent , simulate ) def admin_delete_datasets ( self , instances : List [ Union [ str , entities . VariableInstance ]], records : List [ Union [ str , entities . Record ]], file_patterns : List [ str ] = None , execution_level : entities . ExecutionLevel = entities . ExecutionLevel . STEP_BY_STEP_CRITICAL , job_name : str = None , allow_empty_instances = False , allow_empty_records = False ) \\ -> entities . Job : \"\"\" Admin function to delete datasets that are referenced by a list of instances and a list of records. This function is provided without any guaranties of service continuity. In the future, a secured function will be provided to safely delete datasets. Args: instances: select all the datasets referenced by these instances. records: select all the datasets referenced by these records. file_patterns: select all the datasets with on of the given file patterns (support * and ? for all or any characters and trailing (?i) for case-insensitiveness) execution_level: see entities.ExecutionLevel. job_name: [optional] gives a name to the job, otherwise, a name will be automatically generated allow_empty_instances: [optional] allows instances to be empty. @warning It means that the job will delete all the instances for the given records. allow_empty_records: [optional] allows records to be empty. @warning It means that the job will delete all the records for the given instances. \"\"\" return self . _admin_delete_datasets ( instances , records , file_patterns , execution_level , job_name , allow_empty_instances , allow_empty_records ) @utils . catch_rpc_error def _admin_tidy ( self , aois : bool , records : bool , variables : bool , instances : bool , containers : bool , consolidation_params : bool , simulate : bool ): res = self . admin_stub . TidyDB ( admin_pb2 . TidyDBRequest ( PendingAOIs = aois , PendingRecords = records , PendingVariables = variables , PendingInstances = instances , PendingContainers = containers , PendingParams = consolidation_params , Simulate = simulate )) if simulate : print ( \"Simulation:\" ) print ( \" {} aois deleted \\n \" \" {} records deleted \\n \" \" {} variables deleted \\n \" \" {} instances deleted \\n \" \" {} containers deleted \\n \" . format ( res . NbAOIs , res . NbRecords , res . NbVariables , res . NbInstances , res . NbContainers )) @utils . catch_rpc_error def _admin_update_datasets ( self , instance : Union [ str , entities . VariableInstance ], records : List [ Union [ str , entities . Record ]], dformat : Union [ Dict , Tuple , str ], min_out : float , max_out : float , exponent : float , simulate : bool ): res = self . admin_stub . UpdateDatasets ( admin_pb2 . UpdateDatasetsRequest ( simulate = simulate , instance_id = entities . get_id ( instance ), record_ids = entities . get_ids ( records ), dformat = entities . DataFormat . from_user ( dformat ) . to_pb (), real_min_value = min_out , real_max_value = max_out , exponent = exponent )) if simulate : print ( \"Simulation:\" ) for r , count in res . results . items (): print ( \" {} : {} \\n \" . format ( r , count )) @utils . catch_rpc_error def _admin_delete_datasets ( self , instances : List [ Union [ str , entities . VariableInstance ]], records : List [ Union [ str , entities . Record ]], file_patterns : List [ str ], execution_level : entities . ExecutionLevel , job_name : str , allow_empty_instances , allow_empty_records ) \\ -> entities . Job : if len ( records ) == 0 and not allow_empty_records : raise ValueError ( \"DeleteDataset: records is empty, but it has not been allowed. \" \"Empty records means that all the datasets for the given instances are about to be \" \"deleted. If this is what is wanted, please set allow_empty_records=True\" ) if len ( instances ) == 0 and not allow_empty_instances : raise ValueError ( \"DeleteDataset: instances is empty, but it has not been allowed. \" \"Empty instances means that all the datasets for the given records are about to be \" \"deleted. If this is what is wanted, please set allow_empty_instances=True\" ) if file_patterns is not None : if isinstance ( file_patterns , str ): file_patterns = [ file_patterns ] assert isinstance ( file_patterns , list ) if len ( records ) == 0 and len ( instances ) == 0 : warnings . warn ( \"this job may be about to delete the whole database\" ) if execution_level == entities . ExecutionLevel . ASYNCHRONOUS or \\ execution_level == entities . ExecutionLevel . SYNCHRONOUS : raise ValueError ( \"I cannot allow that in a non-interactive execution_level. \" \"Please use execution_level == entities.ExecutionLevel.STEP_BY_STEP_CRITICAL.\" ) res = self . admin_stub . DeleteDatasets ( admin_pb2 . DeleteDatasetsRequest ( job_name = job_name if job_name is not None else f \"Deletion_ { datetime . now () } _ { len ( records ) } _records\" , execution_level = execution_level . value , instance_ids = entities . get_ids ( instances ), record_ids = entities . get_ids ( records ), dataset_patterns = file_patterns ) ) return entities . Job . from_pb ( self . stub , res . job ) __init__ ( uri , secure = False , api_key = '' , verbose = True ) Initialise the connexion to the Geocube Server Parameters: uri ( str ) \u2013 of the Geocube Server secure ( bool , default: False ) \u2013 True to use a TLS Connexion api_key ( str , default: '' ) \u2013 (optional) API Key if Geocube Server is secured using a bearer authentication verbose ( bool , default: True ) \u2013 display the version of the Geocube Server Source code in geocube/admin.py 11 12 13 14 15 16 17 18 19 20 21 22 def __init__ ( self , uri : str , secure : bool = False , api_key : str = \"\" , verbose : bool = True ): \"\"\" Initialise the connexion to the Geocube Server Args: uri: of the Geocube Server secure: True to use a TLS Connexion api_key: (optional) API Key if Geocube Server is secured using a bearer authentication verbose: display the version of the Geocube Server \"\"\" super () . __init__ ( uri , secure , api_key , verbose ) self . admin_stub = Stub ( admin_pb2_grpc . AdminStub ( self . _channel )) admin_delete_datasets ( instances , records , file_patterns = None , execution_level = entities . ExecutionLevel . STEP_BY_STEP_CRITICAL , job_name = None , allow_empty_instances = False , allow_empty_records = False ) Admin function to delete datasets that are referenced by a list of instances and a list of records. This function is provided without any guaranties of service continuity. In the future, a secured function will be provided to safely delete datasets. Parameters: instances ( List [ Union [ str , VariableInstance ]] ) \u2013 select all the datasets referenced by these instances. records ( List [ Union [ str , Record ]] ) \u2013 select all the datasets referenced by these records. file_patterns ( List [ str ] , default: None ) \u2013 select all the datasets with on of the given file patterns (support * and ? for all or any characters and trailing (?i) for case-insensitiveness) execution_level ( ExecutionLevel , default: STEP_BY_STEP_CRITICAL ) \u2013 see entities.ExecutionLevel. job_name ( str , default: None ) \u2013 [optional] gives a name to the job, otherwise, a name will be automatically generated allow_empty_instances \u2013 [optional] allows instances to be empty. @warning It means that the job will delete all the instances for the given records. allow_empty_records \u2013 [optional] allows records to be empty. @warning It means that the job will delete all the records for the given instances. Source code in geocube/admin.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 def admin_delete_datasets ( self , instances : List [ Union [ str , entities . VariableInstance ]], records : List [ Union [ str , entities . Record ]], file_patterns : List [ str ] = None , execution_level : entities . ExecutionLevel = entities . ExecutionLevel . STEP_BY_STEP_CRITICAL , job_name : str = None , allow_empty_instances = False , allow_empty_records = False ) \\ -> entities . Job : \"\"\" Admin function to delete datasets that are referenced by a list of instances and a list of records. This function is provided without any guaranties of service continuity. In the future, a secured function will be provided to safely delete datasets. Args: instances: select all the datasets referenced by these instances. records: select all the datasets referenced by these records. file_patterns: select all the datasets with on of the given file patterns (support * and ? for all or any characters and trailing (?i) for case-insensitiveness) execution_level: see entities.ExecutionLevel. job_name: [optional] gives a name to the job, otherwise, a name will be automatically generated allow_empty_instances: [optional] allows instances to be empty. @warning It means that the job will delete all the instances for the given records. allow_empty_records: [optional] allows records to be empty. @warning It means that the job will delete all the records for the given instances. \"\"\" return self . _admin_delete_datasets ( instances , records , file_patterns , execution_level , job_name , allow_empty_instances , allow_empty_records ) admin_tidy ( aois = False , records = False , variables = False , instances = False , containers = False , consolidation_params = False , simulate = True ) Admin function to tidy the Geocube Database. Remove all the entities that are not linked to any dataset. Should be used with caution when no ingestion or indexation task is in progress. Parameters: aois ( bool , default: False ) \u2013 remove the pending AOI records ( bool , default: False ) \u2013 remove the pending Records variables ( bool , default: False ) \u2013 remove the pending Variables instances ( bool , default: False ) \u2013 remove the pending Instances containers ( bool , default: False ) \u2013 remove the pending Containers consolidation_params ( bool , default: False ) \u2013 remove the pending ConsolidationParams simulate ( bool , default: True ) \u2013 if True no operation is performed. Only the number of entities that would have been deleted Source code in geocube/admin.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 def admin_tidy ( self , aois : bool = False , records : bool = False , variables : bool = False , instances : bool = False , containers : bool = False , consolidation_params : bool = False , simulate : bool = True ): \"\"\" Admin function to tidy the Geocube Database. Remove all the entities that are not linked to any dataset. Should be used with caution when no ingestion or indexation task is in progress. Args: aois: remove the pending AOI records: remove the pending Records variables: remove the pending Variables instances: remove the pending Instances containers: remove the pending Containers consolidation_params: remove the pending ConsolidationParams simulate: if True no operation is performed. Only the number of entities that would have been deleted \"\"\" return self . _admin_tidy ( aois , records , variables , instances , containers , consolidation_params , simulate ) admin_update_datasets ( instance , records , dformat , min_out , max_out , exponent , simulate ) Admin function to update some sensitive information of datasets referenced by an instance and a list of records Parameters: instance ( Union [ str , VariableInstance ] ) \u2013 select the datasets that are referenced by this instance records ( List [ Union [ str , Record ]] ) \u2013 select the datasets that are referenced by these records dformat ( Union [ Dict , Tuple , str ] ) \u2013 new dataformat min_out ( float ) \u2013 new min_out max_out ( float ) \u2013 new max_out exponent ( float ) \u2013 new exponent simulate ( bool ) \u2013 if True, no operation is performed. Only display the datasets that would have been updated. Source code in geocube/admin.py 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 def admin_update_datasets ( self , instance : Union [ str , entities . VariableInstance ], records : List [ Union [ str , entities . Record ]], dformat : Union [ Dict , Tuple , str ], min_out : float , max_out : float , exponent : float , simulate : bool ): \"\"\" Admin function to update some sensitive information of datasets referenced by an instance and a list of records Args: instance: select the datasets that are referenced by this instance records: select the datasets that are referenced by these records dformat: new dataformat min_out: new min_out max_out: new max_out exponent: new exponent simulate: if True, no operation is performed. Only display the datasets that would have been updated. \"\"\" self . _admin_update_datasets ( instance , records , dformat , min_out , max_out , exponent , simulate )","title":"Admin"},{"location":"user-guide/client/admin-reference/#admin","text":"Bases: Consolidater Source code in geocube/admin.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 class Admin ( Consolidater ): def __init__ ( self , uri : str , secure : bool = False , api_key : str = \"\" , verbose : bool = True ): \"\"\" Initialise the connexion to the Geocube Server Args: uri: of the Geocube Server secure: True to use a TLS Connexion api_key: (optional) API Key if Geocube Server is secured using a bearer authentication verbose: display the version of the Geocube Server \"\"\" super () . __init__ ( uri , secure , api_key , verbose ) self . admin_stub = Stub ( admin_pb2_grpc . AdminStub ( self . _channel )) def set_timeout ( self , timeout_sec : float ): super () . set_timeout ( timeout_sec ) self . admin_stub . timeout = timeout_sec def admin_tidy ( self , aois : bool = False , records : bool = False , variables : bool = False , instances : bool = False , containers : bool = False , consolidation_params : bool = False , simulate : bool = True ): \"\"\" Admin function to tidy the Geocube Database. Remove all the entities that are not linked to any dataset. Should be used with caution when no ingestion or indexation task is in progress. Args: aois: remove the pending AOI records: remove the pending Records variables: remove the pending Variables instances: remove the pending Instances containers: remove the pending Containers consolidation_params: remove the pending ConsolidationParams simulate: if True no operation is performed. Only the number of entities that would have been deleted \"\"\" return self . _admin_tidy ( aois , records , variables , instances , containers , consolidation_params , simulate ) def admin_update_datasets ( self , instance : Union [ str , entities . VariableInstance ], records : List [ Union [ str , entities . Record ]], dformat : Union [ Dict , Tuple , str ], min_out : float , max_out : float , exponent : float , simulate : bool ): \"\"\" Admin function to update some sensitive information of datasets referenced by an instance and a list of records Args: instance: select the datasets that are referenced by this instance records: select the datasets that are referenced by these records dformat: new dataformat min_out: new min_out max_out: new max_out exponent: new exponent simulate: if True, no operation is performed. Only display the datasets that would have been updated. \"\"\" self . _admin_update_datasets ( instance , records , dformat , min_out , max_out , exponent , simulate ) def admin_delete_datasets ( self , instances : List [ Union [ str , entities . VariableInstance ]], records : List [ Union [ str , entities . Record ]], file_patterns : List [ str ] = None , execution_level : entities . ExecutionLevel = entities . ExecutionLevel . STEP_BY_STEP_CRITICAL , job_name : str = None , allow_empty_instances = False , allow_empty_records = False ) \\ -> entities . Job : \"\"\" Admin function to delete datasets that are referenced by a list of instances and a list of records. This function is provided without any guaranties of service continuity. In the future, a secured function will be provided to safely delete datasets. Args: instances: select all the datasets referenced by these instances. records: select all the datasets referenced by these records. file_patterns: select all the datasets with on of the given file patterns (support * and ? for all or any characters and trailing (?i) for case-insensitiveness) execution_level: see entities.ExecutionLevel. job_name: [optional] gives a name to the job, otherwise, a name will be automatically generated allow_empty_instances: [optional] allows instances to be empty. @warning It means that the job will delete all the instances for the given records. allow_empty_records: [optional] allows records to be empty. @warning It means that the job will delete all the records for the given instances. \"\"\" return self . _admin_delete_datasets ( instances , records , file_patterns , execution_level , job_name , allow_empty_instances , allow_empty_records ) @utils . catch_rpc_error def _admin_tidy ( self , aois : bool , records : bool , variables : bool , instances : bool , containers : bool , consolidation_params : bool , simulate : bool ): res = self . admin_stub . TidyDB ( admin_pb2 . TidyDBRequest ( PendingAOIs = aois , PendingRecords = records , PendingVariables = variables , PendingInstances = instances , PendingContainers = containers , PendingParams = consolidation_params , Simulate = simulate )) if simulate : print ( \"Simulation:\" ) print ( \" {} aois deleted \\n \" \" {} records deleted \\n \" \" {} variables deleted \\n \" \" {} instances deleted \\n \" \" {} containers deleted \\n \" . format ( res . NbAOIs , res . NbRecords , res . NbVariables , res . NbInstances , res . NbContainers )) @utils . catch_rpc_error def _admin_update_datasets ( self , instance : Union [ str , entities . VariableInstance ], records : List [ Union [ str , entities . Record ]], dformat : Union [ Dict , Tuple , str ], min_out : float , max_out : float , exponent : float , simulate : bool ): res = self . admin_stub . UpdateDatasets ( admin_pb2 . UpdateDatasetsRequest ( simulate = simulate , instance_id = entities . get_id ( instance ), record_ids = entities . get_ids ( records ), dformat = entities . DataFormat . from_user ( dformat ) . to_pb (), real_min_value = min_out , real_max_value = max_out , exponent = exponent )) if simulate : print ( \"Simulation:\" ) for r , count in res . results . items (): print ( \" {} : {} \\n \" . format ( r , count )) @utils . catch_rpc_error def _admin_delete_datasets ( self , instances : List [ Union [ str , entities . VariableInstance ]], records : List [ Union [ str , entities . Record ]], file_patterns : List [ str ], execution_level : entities . ExecutionLevel , job_name : str , allow_empty_instances , allow_empty_records ) \\ -> entities . Job : if len ( records ) == 0 and not allow_empty_records : raise ValueError ( \"DeleteDataset: records is empty, but it has not been allowed. \" \"Empty records means that all the datasets for the given instances are about to be \" \"deleted. If this is what is wanted, please set allow_empty_records=True\" ) if len ( instances ) == 0 and not allow_empty_instances : raise ValueError ( \"DeleteDataset: instances is empty, but it has not been allowed. \" \"Empty instances means that all the datasets for the given records are about to be \" \"deleted. If this is what is wanted, please set allow_empty_instances=True\" ) if file_patterns is not None : if isinstance ( file_patterns , str ): file_patterns = [ file_patterns ] assert isinstance ( file_patterns , list ) if len ( records ) == 0 and len ( instances ) == 0 : warnings . warn ( \"this job may be about to delete the whole database\" ) if execution_level == entities . ExecutionLevel . ASYNCHRONOUS or \\ execution_level == entities . ExecutionLevel . SYNCHRONOUS : raise ValueError ( \"I cannot allow that in a non-interactive execution_level. \" \"Please use execution_level == entities.ExecutionLevel.STEP_BY_STEP_CRITICAL.\" ) res = self . admin_stub . DeleteDatasets ( admin_pb2 . DeleteDatasetsRequest ( job_name = job_name if job_name is not None else f \"Deletion_ { datetime . now () } _ { len ( records ) } _records\" , execution_level = execution_level . value , instance_ids = entities . get_ids ( instances ), record_ids = entities . get_ids ( records ), dataset_patterns = file_patterns ) ) return entities . Job . from_pb ( self . stub , res . job )","title":"Admin"},{"location":"user-guide/client/admin-reference/#geocube.Admin.__init__","text":"Initialise the connexion to the Geocube Server Parameters: uri ( str ) \u2013 of the Geocube Server secure ( bool , default: False ) \u2013 True to use a TLS Connexion api_key ( str , default: '' ) \u2013 (optional) API Key if Geocube Server is secured using a bearer authentication verbose ( bool , default: True ) \u2013 display the version of the Geocube Server Source code in geocube/admin.py 11 12 13 14 15 16 17 18 19 20 21 22 def __init__ ( self , uri : str , secure : bool = False , api_key : str = \"\" , verbose : bool = True ): \"\"\" Initialise the connexion to the Geocube Server Args: uri: of the Geocube Server secure: True to use a TLS Connexion api_key: (optional) API Key if Geocube Server is secured using a bearer authentication verbose: display the version of the Geocube Server \"\"\" super () . __init__ ( uri , secure , api_key , verbose ) self . admin_stub = Stub ( admin_pb2_grpc . AdminStub ( self . _channel ))","title":"__init__"},{"location":"user-guide/client/admin-reference/#geocube.Admin.admin_delete_datasets","text":"Admin function to delete datasets that are referenced by a list of instances and a list of records. This function is provided without any guaranties of service continuity. In the future, a secured function will be provided to safely delete datasets. Parameters: instances ( List [ Union [ str , VariableInstance ]] ) \u2013 select all the datasets referenced by these instances. records ( List [ Union [ str , Record ]] ) \u2013 select all the datasets referenced by these records. file_patterns ( List [ str ] , default: None ) \u2013 select all the datasets with on of the given file patterns (support * and ? for all or any characters and trailing (?i) for case-insensitiveness) execution_level ( ExecutionLevel , default: STEP_BY_STEP_CRITICAL ) \u2013 see entities.ExecutionLevel. job_name ( str , default: None ) \u2013 [optional] gives a name to the job, otherwise, a name will be automatically generated allow_empty_instances \u2013 [optional] allows instances to be empty. @warning It means that the job will delete all the instances for the given records. allow_empty_records \u2013 [optional] allows records to be empty. @warning It means that the job will delete all the records for the given instances. Source code in geocube/admin.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 def admin_delete_datasets ( self , instances : List [ Union [ str , entities . VariableInstance ]], records : List [ Union [ str , entities . Record ]], file_patterns : List [ str ] = None , execution_level : entities . ExecutionLevel = entities . ExecutionLevel . STEP_BY_STEP_CRITICAL , job_name : str = None , allow_empty_instances = False , allow_empty_records = False ) \\ -> entities . Job : \"\"\" Admin function to delete datasets that are referenced by a list of instances and a list of records. This function is provided without any guaranties of service continuity. In the future, a secured function will be provided to safely delete datasets. Args: instances: select all the datasets referenced by these instances. records: select all the datasets referenced by these records. file_patterns: select all the datasets with on of the given file patterns (support * and ? for all or any characters and trailing (?i) for case-insensitiveness) execution_level: see entities.ExecutionLevel. job_name: [optional] gives a name to the job, otherwise, a name will be automatically generated allow_empty_instances: [optional] allows instances to be empty. @warning It means that the job will delete all the instances for the given records. allow_empty_records: [optional] allows records to be empty. @warning It means that the job will delete all the records for the given instances. \"\"\" return self . _admin_delete_datasets ( instances , records , file_patterns , execution_level , job_name , allow_empty_instances , allow_empty_records )","title":"admin_delete_datasets"},{"location":"user-guide/client/admin-reference/#geocube.Admin.admin_tidy","text":"Admin function to tidy the Geocube Database. Remove all the entities that are not linked to any dataset. Should be used with caution when no ingestion or indexation task is in progress. Parameters: aois ( bool , default: False ) \u2013 remove the pending AOI records ( bool , default: False ) \u2013 remove the pending Records variables ( bool , default: False ) \u2013 remove the pending Variables instances ( bool , default: False ) \u2013 remove the pending Instances containers ( bool , default: False ) \u2013 remove the pending Containers consolidation_params ( bool , default: False ) \u2013 remove the pending ConsolidationParams simulate ( bool , default: True ) \u2013 if True no operation is performed. Only the number of entities that would have been deleted Source code in geocube/admin.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 def admin_tidy ( self , aois : bool = False , records : bool = False , variables : bool = False , instances : bool = False , containers : bool = False , consolidation_params : bool = False , simulate : bool = True ): \"\"\" Admin function to tidy the Geocube Database. Remove all the entities that are not linked to any dataset. Should be used with caution when no ingestion or indexation task is in progress. Args: aois: remove the pending AOI records: remove the pending Records variables: remove the pending Variables instances: remove the pending Instances containers: remove the pending Containers consolidation_params: remove the pending ConsolidationParams simulate: if True no operation is performed. Only the number of entities that would have been deleted \"\"\" return self . _admin_tidy ( aois , records , variables , instances , containers , consolidation_params , simulate )","title":"admin_tidy"},{"location":"user-guide/client/admin-reference/#geocube.Admin.admin_update_datasets","text":"Admin function to update some sensitive information of datasets referenced by an instance and a list of records Parameters: instance ( Union [ str , VariableInstance ] ) \u2013 select the datasets that are referenced by this instance records ( List [ Union [ str , Record ]] ) \u2013 select the datasets that are referenced by these records dformat ( Union [ Dict , Tuple , str ] ) \u2013 new dataformat min_out ( float ) \u2013 new min_out max_out ( float ) \u2013 new max_out exponent ( float ) \u2013 new exponent simulate ( bool ) \u2013 if True, no operation is performed. Only display the datasets that would have been updated. Source code in geocube/admin.py 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 def admin_update_datasets ( self , instance : Union [ str , entities . VariableInstance ], records : List [ Union [ str , entities . Record ]], dformat : Union [ Dict , Tuple , str ], min_out : float , max_out : float , exponent : float , simulate : bool ): \"\"\" Admin function to update some sensitive information of datasets referenced by an instance and a list of records Args: instance: select the datasets that are referenced by this instance records: select the datasets that are referenced by these records dformat: new dataformat min_out: new min_out max_out: new max_out exponent: new exponent simulate: if True, no operation is performed. Only display the datasets that would have been updated. \"\"\" self . _admin_update_datasets ( instance , records , dformat , min_out , max_out , exponent , simulate )","title":"admin_update_datasets"},{"location":"user-guide/client/client-reference/","text":"Client Geocube-client has three level of access: Client is for basic access. The Client has CRUD access to most entities. It can also index new images. Consolidater is for optimization of the database, through consolidation of the datasets. It has CRUD access to entities.job . Admin is for operation that must be done wisely and cautiously. Source code in geocube/client.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 class Client : def __init__ ( self , uri : str , secure : bool = False , api_key : str = \"\" , verbose : bool = True ): \"\"\" Initialise the connexion to the Geocube Server Args: uri: of the Geocube Server secure: True to use a TLS Connexion api_key: (optional) API Key if Geocube Server is secured using a bearer authentication verbose: set the default verbose mode \"\"\" assert uri is not None and uri != \"\" , \"geocube.Client: Cannot connect: uri is not defined\" self . pid = os . getpid () if secure : credentials = grpc . ssl_channel_credentials () if api_key != \"\" : token_credentials = grpc . access_token_call_credentials ( api_key ) credentials = grpc . composite_channel_credentials ( credentials , token_credentials ) self . _channel = grpc . secure_channel ( uri , credentials ) else : self . _channel = grpc . insecure_channel ( uri ) self . stub = Stub ( geocube_grpc . GeocubeStub ( self . _channel )) self . verbose = verbose if verbose : print ( \"Connected to Geocube v\" + self . version ()) self . downloader = None def is_pid_ok ( self ) -> bool : return self . pid == os . getpid () def use_downloader ( self , downloader : Downloader ): self . downloader = downloader def set_timeout ( self , timeout_sec : float ): self . stub . timeout = timeout_sec def version ( self ) -> str : \"\"\" Returns the version of the Geocube Server \"\"\" return self . _version () def variable ( self , name : str = None , id_ : str = None , instance_id : str = None ) \\ -> Union [ entities . Variable , entities . VariableInstance ]: \"\"\" Fetch a variable given an id, a name or an instance id (mutually exclusive) Args: name: id_: internal id of the variable (uuid4) instance_id: internal id of one instance of the variable (uuid4) Returns: either a Variable (first two cases) or a VariableInstance (specialization of the variable) \"\"\" return self . _variable ( name , id_ , instance_id ) def create_variable ( self , name : str , dformat : entities . DataFormat , bands : List [ str ], unit : str = \"\" , description : str = \"\" , palette : str = \"\" , resampling_alg : entities . Resampling = entities . Resampling . bilinear , exist_ok : bool = False ) \\ -> entities . Variable : \"\"\" Create a single Variable Args: name: Name of the variable dformat: data format of the variable (min and max are the theoretical extrema) bands: Name of the bands unit: of the data (for user information only) description: of the data (for user information only) palette: for rendering in png (TileServer). Must be created using create_palette. resampling_alg: when reprojection is needed (see entities.Resampling) exist_ok: (optional, see warning): if already exists, do not raise an error. !!! WARNING: it does not mean that the variable already stored in the geocube is exactly the same !!! Returns: the variable \"\"\" return self . _create_variable ( name , dformat , bands , unit , description , palette , resampling_alg , exist_ok ) def create_palette ( self , name : str , colors : List [ Tuple [ float , int , int , int , int ]], replace : bool = False ): \"\"\" Create a new palette from [0, 1] to RGBA, providing a list of index from 0 to 1. The intermediate values are linearly interpolated. Args: name: Name of the palette colors: a list of tuple[index, R, G, B, A] mapping index to the corresponding RGBA value replace: if a palette already exists with the same name, replace it else raise an error. \"\"\" return self . _create_palette ( name , colors , replace ) def list_variables ( self , name : str = \"\" , limit : int = 0 , page : int = 0 ) -> List [ entities . Variable ]: \"\"\" List all the variables given a pattern Args: name: pattern of the name. * and ? are supported to match all or any character. (?i) can be added at the end to be insensitive to case limit: limit the number of variables returned page: number of the page (starting at 0). Returns: a list of variable \"\"\" return self . _list_variables ( name , limit , page ) def create_aoi ( self , aoi : Union [ geometry . Polygon , geometry . MultiPolygon ], exist_ok : bool = False ) -> str : \"\"\" Create a new AOI. Raise an error if an AOI with the same coordinates already exists. The id of the AOI can be retrieved from the details of the error. Args: aoi: in geographic coordinates exist_ok: (optional): if already exists, do not raise an error and return the aoi_id Returns: the id of the AOI \"\"\" return self . _create_aoi ( aoi , exist_ok ) def create_record ( self , aoi_id : str , name : str , tags : Dict [ str , str ], date : datetime , exist_ok : bool = False ) \\ -> str : \"\"\" Create a new record. A record is uniquely identified with the tuple (name, tags, date) Raise an error if a record with the same Name, Tags and Date already exists. Args: aoi_id: uuid4 of the AOI. name: of the records. tags: user-defined tags associated to the record. date: date of the data referenced by the record. exist_ok: (optional, see warning): if already exists, do not raise an error !!! WARNING: it does not mean that the record in the geocube is the same: its aoi may be different !!! Returns: the ID of the record \"\"\" try : return self . create_records ([ aoi_id ], [ name ], [ tags ], [ date ])[ 0 ] except utils . GeocubeError as e : if e . is_already_exists () and exist_ok : record = self . list_records ( name , tags = tags , from_time = date , to_time = date )[ 0 ] if record . aoi_id != aoi_id : warnings . warn ( \"Record already exists in the Geocube but the aoi_id is different\" ) return record . id raise def create_records ( self , aoi_ids : List [ str ], names : List [ str ], tags : List [ Dict [ str , str ]], dates : List [ datetime ]) -> List [ str ]: \"\"\" Create a list of records. All inputs must have the same length. (see create_record for the description of the parameters) \"\"\" return self . _create_records ( aoi_ids , names , tags , dates ) def get_record ( self , _id : str ) -> entities . Record : \"\"\" Deprecated: use record() instead \"\"\" return self . record ( _id ) def record ( self , _id : str ) -> entities . Record : \"\"\" Get a record by id \"\"\" r = self . get_records ([ _id ]) assert len ( r ) > 0 , utils . GeocubeError ( \"get_record\" , grpc . StatusCode . NOT_FOUND . name , \"record with id \" + _id ) return r [ 0 ] def get_records ( self , ids : List [ str ]) -> List [ entities . Record ]: \"\"\" Get a list of records. \"\"\" return self . _get_records ( ids ) def list_records ( self , name : str = \"\" , tags : Dict [ str , str ] = None , from_time : datetime = None , to_time : datetime = None , aoi : geometry . MultiPolygon = None , limit : int = 10000 , page : int = 0 , with_aoi : bool = False ) -> List [ entities . Record ]: \"\"\" List records given filters Args: name: pattern of the name. * and ? are supported to match all or any character. (?i) can be added at the end to be insensitive to case tags: list of mandatory tags. Support the same pattern as name. from_time: filter by date to_time: filter by date aoi: records that intersect the AOI in geographic coordinates limit: the number of records returned (0 to return all records) page: start at 0 with_aoi: also returns the AOI of the record. Otherwise, only the ID of the aoi is returned. load_aoi(record) can be called to retrieve the AOI later. Returns: a list of records \"\"\" return self . _list_records ( name , tags , from_time , to_time , aoi , limit , page , with_aoi ) def load_aoi ( self , aoi_id : Union [ str , entities . Record ]) -> geometry . MultiPolygon : \"\"\" Load the geometry of the AOI of the given record Args: aoi_id: uuid of the AOI or the record. If the record is provided, its geometry will be updated Returns: the geometry of the AOI \"\"\" return self . _load_aoi ( aoi_id ) def add_records_tags ( self , records : List [ Union [ str , entities . Record ]], tags : Dict [ str , str ]) -> int : \"\"\" Add or update tags to a list of records Args: records: List of records to be updated tags: List of new tags or tags to be updated Returns: the number of updated records \"\"\" return self . _add_records_tags ( records , tags ) def remove_records_tags ( self , records : List [ Union [ str , entities . Record ]], tag_keys : List [ str ]) -> int : \"\"\" Remove tags keys from a list of records Args: records: List of records to be updated tag_keys: List of keys to be deleted Returns: the number of updated records \"\"\" return self . _remove_records_tags ( records , tag_keys ) def delete_records ( self , records : List [ Union [ str , entities . Record ]], no_fail : bool = False ): \"\"\" Delete records iif no dataset are indexed to them. Args: records: List of records to be deleted no_fail: if true, do not fail if some records still have datasets that refer to them, and delete the others \"\"\" return self . _delete_records ( records , no_fail ) def containers ( self , uris : Union [ str , List [ str ]]) -> Union [ entities . Container , List [ entities . Container ]]: \"\"\" Get containers and their datasets by uris Args: uris: uri or list of uris \"\"\" return self . _containers ( uris ) def index ( self , containers : List [ entities . Container ]): \"\"\" Index a new container. Args: containers: List of container to index. \"\"\" return self . _index ( containers ) def index_dataset ( self , uri : str , record : Union [ str , entities . Record , Tuple [ str , Dict [ str , str ], datetime ]], instance : entities . VariableInstance , dformat : entities . DataFormat , bands : List [ int ] = None , min_out : float = None , max_out : float = None , exponent : float = 1 , managed : bool = False ): \"\"\" Index the given \"bands\" of the dataset located at \"uri\", referenced by a record and an instance. Args: uri: of the file to index record: id of the record describing the data-take or a tuple (name, metadata, datetime) to create the record on the fly instance: describing the data dformat: describing the internal format (see entities.DataFormat.from_user()) bands: subset of bands' file (start at 1) that maps to `variable.bands` (by default, all the bands) min_out: (optional, default: instance.dformat.min_value, instance.dformat.dtype) maps dformat.min_value max_out: (optional, default: instance.dformat.max_value, instance.dformat.dtype) maps dformat.max_value exponent: (optional, default: 1) non-linear scaling between dformat.min_max_value to min_max_out. managed: if True, the geocube takes the ownership of the file, removing it if the dataset is removed \"\"\" return self . _index_dataset ( uri , record , instance , dformat , bands , min_out , max_out , exponent , managed ) def get_cube_metadata ( self , params : entities . CubeParams ) -> entities . CubeMetadata : return self . _get_cube_metadata ( params ) def get_cube ( self , params : entities . CubeParams , * , resampling_alg : entities . Resampling = entities . Resampling . undefined , headers_only : bool = False , compression : int = 0 , verbose : bool = None ) \\ -> Tuple [ List [ np . array ], List [ entities . GroupedRecords ]]: \"\"\" Get a cube given a CubeParameters Args: params: CubeParams (see entities.CubeParams) resampling_alg: if defined, overwrite the variable.Resampling used for reprojection. headers_only: Only returns the header of each image (gives an overview of the query) compression: define a level of compression to speed up the transfer. (0: no compression, 1 fastest to 9 best, -2: huffman-only) The data is compressed by the server and decompressed by the Client. Compression=0 or -2 is advised if the bandwidth is not limited verbose: display information during the transfer (if None, use the default verbose mode) Returns: list of images (np.ndarray) and the list of corresponding records (several records can be returned for each image when they are grouped together, by date or something else. See entities.Record.group_by) \"\"\" cube = self . _get_cube_it ( params , resampling_alg = resampling_alg , headers_only = headers_only , compression = compression ) images , grouped_records = [], [] verbose = self . verbose if verbose is None else verbose if verbose : print ( \"GetCube returns {} images from {} datasets\" . format ( cube . count , cube . nb_datasets )) for image , metadata , err in cube : if err is not None : if err == cubeiterator . NOT_FOUND_ERROR : if verbose : print ( err ) continue raise ValueError ( err ) if verbose : min_date = metadata . min_date . strftime ( \"%Y-%m- %d _%H:%M:%S\" ) max_date = metadata . max_date . strftime ( \"%Y-%m- %d _%H:%M:%S\" ) print ( \"Image {} received ( {}{} kb) RecordTime: {} RecordName: {} Shape: {} \" . format ( cube . index + 1 , '<' if headers_only else '' , metadata . bytes // 1024 , min_date if min_date == max_date else min_date + \" to \" + max_date , metadata . grouped_records [ 0 ] . name , image . shape )) images . append ( image ) grouped_records . append ( metadata . grouped_records ) return images , grouped_records def get_cube_it ( self , params : entities . CubeParams , * , resampling_alg : entities . Resampling = entities . Resampling . undefined , headers_only : bool = False , compression : int = 0 , file_format = FileFormatRaw , file_pattern : str = None ) -> entities . CubeIterator : \"\"\" Returns a cube iterator over the requested images Args: params: CubeParams (see entities.CubeParams) resampling_alg: if defined, overwrite the variable.Resampling used for reprojection. headers_only : returns only the header of the dataset (use this option to control the output of get_cube) compression : define a level of compression to speed up the transfer (0: no compression, 1 fastest to 9 best, -2: huffman-only) The data is compressed by the server and decompressed by the Client. Compression=0 or -2 is advised if the bandwidth is not limited file_format : (optional) currently supported geocube.FileFormatRaw & geocube.FileFormatGTiff file_pattern : (optional) iif file_format != Raw, pattern of the file name. {#} will be replaced by the number of image, {date} and {id} by the value of the record Returns: an iterator yielding an image, its associated records, an error (or None) and the size of the image >>> client = Client('127.0.0.1:8080', False) >>> cube_params = entities.CubeParams.from_records(\"+proj=utm +zone=31\", ... entities.geo_transform(366162, 4833123, 30), (512, 512), ... client.variable(name=\"test/rgb\").instance(\"master\"), records=client.list_records('france')) affine.Affine.translation(366162, 4833123)*affine.Affine.scale(30, -30)) >>> cube_it = client.get_cube_it(cube_params) >>> from matplotlib import pyplot as plt >>> for image, _, _, err in cube_it: ... if err != cubeiterator.NOT_FOUND_ERROR: ... raise ValueError(err) ... if not err: ... plt.figure(cube_it.index+1) ... plt.imshow(image) \"\"\" return self . _get_cube_it ( params , resampling_alg = resampling_alg , headers_only = headers_only , compression = compression , file_format = file_format , file_pattern = file_pattern ) def tile_aoi ( self , aoi : Union [ geometry . MultiPolygon , geometry . Polygon ], layout_name : Optional [ str ] = None , layout : Optional [ entities . Layout ] = None , resolution : Optional [ float ] = None , crs : Optional [ str ] = None , shape : Optional [ Tuple [ int , int ]] = None ) -> List [ entities . Tile ]: \"\"\" Tile an AOI Args: aoi: AOI to be tiled in **geographic coordinates** crs: CRS of the tile (not the AOI) resolution: resolution of the tile shape: shape of each tile layout_name: use a defined layout. layout: use a customer defined layout Returns: a list of Tiles covering the AOI in the given CRS at the given resolution \"\"\" return self . _tile_aoi ( aoi , layout_name , layout , resolution , crs , shape ) def get_xyz_tile ( self , instance : Union [ str , entities . VariableInstance ], records : List [ Union [ str , entities . Record ]], x : int , y : int , z : int , file : str ): \"\"\" Create a PNG file covering the (X,Y,Z) web-mercator tile, using the palette of the variable. Args: instance: instance of the variable records: list of records x: coordinate of the web-mercator XYZ tile y: coordinate of the web-mercator XYZ tile z: coordinate of the web-mercator XYZ tile file: output PNG file \"\"\" return self . _get_xyz_tile ( instance , records , x , y , z , file ) def create_layout ( self , layout : entities . Layout , exist_ok = False ): \"\"\" Create a layout in the Geocube exist_ok: (optional, see warning): if already exists, do not raise an error. !!! WARNING: it does not mean that the layout already stored in the geocube is exactly the same !!! \"\"\" return self . _create_layout ( layout , exist_ok ) def layout ( self , name : str ) -> entities . Layout : \"\"\" Get layout by name \"\"\" return self . _layout ( name ) def list_layouts ( self , name_like : str = \"\" ) -> List [ entities . Layout ]: \"\"\" List available layouts by name name_like: pattern of the name. * and ? are supported to match all or any character. \"\"\" return self . _list_layouts ( name_like ) def find_container_layouts ( self , instance : Union [ str , entities . VariableInstance ], records : List [ Union [ str , entities . Record ]] = None , tags : Dict [ str , str ] = None , from_time : datetime = None , to_time : datetime = None , aoi : geometry . MultiPolygon = None ) -> Dict [ str , List [ str ]]: \"\"\" Find layouts of the containers covering an area or a list of records for a given instance \"\"\" return self . _find_container_layouts ( instance , records , tags , from_time , to_time , aoi ) def delete_layout ( self , name : str = \"\" ): \"\"\" Delete a layout from the Geocube \"\"\" return self . _delete_layout ( name ) def create_grid ( self , grid : entities . Grid ): \"\"\" Create a grid in the Geocube\"\"\" return self . _create_grid ( grid ) def list_grids ( self , name_like : str = \"\" ) -> List [ entities . Grid ]: \"\"\" List grids by name name_like: pattern of the name. * and ? are supported to match all or any character. \"\"\" return self . _list_grids ( name_like ) def delete_grid ( self , name : str = \"\" ): \"\"\" Delete a grid by its name \"\"\" return self . _delete_grid ( name ) @utils . catch_rpc_error def _version ( self ) -> str : return self . stub . Version ( version_pb2 . GetVersionRequest ()) . Version @utils . catch_rpc_error def _variable ( self , name : str , id_ : str , instance_id : str ) \\ -> Union [ entities . Variable , entities . VariableInstance ]: if id_ : req = variables_pb2 . GetVariableRequest ( id = id_ ) elif name : req = variables_pb2 . GetVariableRequest ( name = name ) elif instance_id : req = variables_pb2 . GetVariableRequest ( instance_id = instance_id ) else : raise ValueError ( \"One of id_, name or instance_id must be defined\" ) resp = self . stub . GetVariable ( req ) v = entities . Variable . from_pb ( self . stub , resp . variable ) for i in v . instances . values (): if i . id == instance_id : return v . instance ( i . name ) return v @utils . catch_rpc_error def _create_variable ( self , name : str , dformat : entities . DataFormat , bands : List [ str ], unit : str , description : str , palette : str , resampling_alg : entities . Resampling , exist_ok : bool ) \\ -> entities . Variable : req = variables_pb2 . CreateVariableRequest ( variable = variables_pb2 . Variable ( name = name , unit = unit , description = description , dformat = entities . DataFormat . from_user ( dformat ) . to_pb (), bands = bands , palette = palette , resampling_alg = typing . cast ( int , resampling_alg . value ) - 1 )) try : return self . variable ( id_ = self . stub . CreateVariable ( req ) . id ) except grpc . RpcError as e : e = utils . GeocubeError . from_rpc ( e ) if e . is_already_exists () and exist_ok : return self . variable ( name ) raise @utils . catch_rpc_error def _create_palette ( self , name : str , colors : List [ Tuple [ float , int , int , int , int ]], replace : bool ): colors = [ variables_pb2 . colorPoint ( value = v [ 0 ], r = v [ 1 ], g = v [ 2 ], b = v [ 3 ], a = v [ 4 ]) for v in colors ] req = variables_pb2 . CreatePaletteRequest ( palette = variables_pb2 . Palette ( name = name , colors = colors ), replace = replace ) self . stub . CreatePalette ( req ) @utils . catch_rpc_error def _list_variables ( self , name : str , limit : int , page : int ) -> List [ entities . Variable ]: req = variables_pb2 . ListVariablesRequest ( name = name , limit = limit , page = page ) return [ entities . Variable . from_pb ( self . stub , resp . variable ) for resp in self . stub . ListVariables ( req )] @utils . catch_rpc_error def _create_aoi ( self , aoi : Union [ geometry . Polygon , geometry . MultiPolygon ], exist_ok : bool ) -> str : try : req = records_pb2 . CreateAOIRequest ( aoi = entities . aoi_to_pb ( aoi )) return self . stub . CreateAOI ( req ) . id except grpc . RpcError as e : e = utils . GeocubeError . from_rpc ( e ) if e . is_already_exists () and exist_ok : return e . details [ e . details . rindex ( ' ' ) + 1 :] raise @utils . catch_rpc_error def _create_records ( self , aoi_ids : List [ str ], names : List [ str ], tags : List [ Dict [ str , str ]], dates : List [ datetime ]) -> List [ str ]: if len ( names ) != len ( aoi_ids ) or len ( names ) != len ( dates ) or len ( names ) != len ( tags ): raise ValueError ( \"All fields must have the same length\" ) records = [] for i in range ( len ( names )): record = records_pb2 . NewRecord ( aoi_id = aoi_ids [ i ], name = names [ i ], tags = tags [ i ]) record . time . FromDatetime ( dates [ i ]) records . append ( record ) req = records_pb2 . CreateRecordsRequest ( records = records ) return self . stub . CreateRecords ( req ) . ids @utils . catch_rpc_error def _get_records ( self , ids : List [ str ]) -> List [ entities . Record ]: req = records_pb2 . GetRecordsRequest ( ids = ids ) return [ entities . Record . from_pb ( resp . record ) for resp in self . stub . GetRecords ( req )] @utils . catch_rpc_error def _list_records ( self , name : str , tags : Dict [ str , str ], from_time : datetime , to_time : datetime , aoi : geometry . MultiPolygon , limit : int , page : int , with_aoi : bool ) -> List [ entities . Record ]: req = records_pb2 . ListRecordsRequest ( name = name , tags = tags , aoi = entities . aoi_to_pb ( aoi ), limit = limit , page = page , with_aoi = with_aoi ) if from_time is not None : req . from_time . FromDatetime ( from_time ) if to_time is not None : req . to_time . FromDatetime ( to_time ) records = [ entities . Record . from_pb ( resp . record ) for resp in self . stub . ListRecords ( req )] if limit != 0 and len ( records ) == limit : warnings . warn ( \"Maximum number of records reached. Call list_records(..., page=) or \" \"list_records(..., limit=) to get more records.\" ) return records @utils . catch_rpc_error def _load_aoi ( self , aoi_id : Union [ str , entities . Record ]) -> geometry . MultiPolygon : record = None if isinstance ( aoi_id , entities . Record ): record = aoi_id aoi_id = record . aoi_id resp = self . stub . GetAOI ( records_pb2 . GetAOIRequest ( id = aoi_id )) aoi = entities . aoi_from_pb ( resp . aoi ) if record : record . aoi = aoi return aoi @utils . catch_rpc_error def _add_records_tags ( self , records : List [ Union [ str , entities . Record ]], tags : Dict [ str , str ]) -> int : req = records_pb2 . AddRecordsTagsRequest ( ids = entities . get_ids ( records ), tags = tags ) return self . stub . AddRecordsTags ( req ) . nb @utils . catch_rpc_error def _remove_records_tags ( self , records : List [ Union [ str , entities . Record ]], tag_keys : List [ str ]) -> int : req = records_pb2 . RemoveRecordsTagsRequest ( ids = entities . get_ids ( records ), tagsKey = tag_keys ) return self . stub . RemoveRecordsTags ( req ) . nb @utils . catch_rpc_error def _delete_records ( self , records : List [ Union [ str , entities . Record ]], no_fail : bool ): req = records_pb2 . DeleteRecordsRequest ( ids = entities . get_ids ( records ), no_fail = no_fail ) self . stub . DeleteRecords ( req ) @utils . catch_rpc_error def _containers ( self , uris : Union [ str , List [ str ]]) -> Union [ entities . Container , List [ entities . Container ]]: singleton = isinstance ( uris , str ) if singleton : uris = [ uris ] req = operations_pb2 . GetContainersRequest ( uris = uris ) res = self . stub . GetContainers ( req ) containers = [ entities . Container . from_pb ( pb_container ) for pb_container in res . containers ] return containers [ 0 ] if singleton else containers @utils . catch_rpc_error def _index ( self , containers : List [ entities . Container ]): pb_containers = [] for container in containers : datasets = [ dataset . to_pb () for dataset in container . datasets ] pb_containers . append ( operations_pb2 . Container ( uri = container . uri , managed = container . managed , datasets = datasets )) for c in pb_containers : req = operations_pb2 . IndexDatasetsRequest ( container = c ) self . stub . IndexDatasets ( req ) @utils . catch_rpc_error def _index_dataset ( self , uri : str , record : Union [ str , entities . Record , Tuple [ str , Dict [ str , str ], datetime ]], instance : entities . VariableInstance , dformat : entities . DataFormat , bands : List [ int ], min_out : float , max_out : float , exponent : float , managed : bool ): ds_dtype = \"u1\" if isinstance ( record , tuple ) or dformat is None : try : with rasterio . open ( uri ) as ds : tile = entities . Tile . from_geotransform ( ds . transform , ds . crs , ds . shape [:: - 1 ]) ds_dtype = ds . dtypes [ 0 ] except Exception as e : raise ValueError ( f 'if \"record\" is a tuple or \"bands\" or \"dformat\" is not defined, geocube-client tries' f ' to deduce some information reading the file { uri } , but it encountered' f ' the following error : { e } .' ) if isinstance ( record , tuple ): aoi_id = self . create_aoi ( tile . geometry ( 4326 ), exist_ok = True ) r_name , r_tags , r_date = record record = self . create_record ( aoi_id , name = r_name , tags = r_tags , date = r_date , exist_ok = True ) if dformat is None : dformat = entities . DataFormat . from_user ( ds_dtype ) cs = [ entities . Container ( uri , managed = managed , datasets = [ entities . Dataset ( record , instance , bands = bands , dformat = entities . DataFormat . from_user ( dformat ), min_out = min_out , max_out = max_out , exponent = exponent )])] return self . index ( cs ) @utils . catch_rpc_error def _get_cube_metadata ( self , params : entities . CubeParams ) -> entities . CubeMetadata : cube_it = self . _get_cube_it ( params , headers_only = True ) return cube_it . metadata () @utils . catch_rpc_error def _get_cube_it ( self , params : entities . CubeParams , * , resampling_alg : entities . Resampling = entities . Resampling . undefined , headers_only : bool = False , compression : int = 0 , file_format = FileFormatRaw , file_pattern : str = None ) -> entities . CubeIterator : if self . downloader is not None and not headers_only : metadata = self . _get_cube_it ( params , headers_only = True ) . metadata () if resampling_alg != entities . Resampling . undefined : metadata . resampling_alg = resampling_alg return self . downloader . get_cube_it ( metadata , file_format = file_format , file_pattern = file_pattern , predownload = self . downloader . always_predownload ) common = { \"instances_id\" : [ params . instance ], \"crs\" : params . crs , \"pix_to_crs\" : layouts_pb2 . GeoTransform ( a = params . transform . c , b = params . transform . a , c = params . transform . b , d = params . transform . f , e = params . transform . d , f = params . transform . e ), \"size\" : layouts_pb2 . Size ( width = params . shape [ 0 ], height = params . shape [ 1 ]), \"compression_level\" : compression , \"headers_only\" : headers_only , \"format\" : file_format , \"resampling_alg\" : typing . cast ( int , resampling_alg . value ) - 1 } if params . records is not None : req = catalog_pb2 . GetCubeRequest ( ** common , grouped_records = records_pb2 . GroupedRecordIdsList ( records = [ records_pb2 . GroupedRecordIds ( ids = rs ) for rs in params . records ] )) else : from_time_pb = utils . pb_null_timestamp () if params . from_time is not None : from_time_pb . FromDatetime ( params . from_time ) to_time_pb = utils . pb_null_timestamp () if params . to_time is not None : to_time_pb . FromDatetime ( params . to_time ) req = catalog_pb2 . GetCubeRequest ( ** common , filters = records_pb2 . RecordFilters ( tags = params . tags , from_time = from_time_pb , to_time = to_time_pb )) return entities . CubeIterator ( self . stub . GetCube ( req ), file_format , file_pattern ) @utils . catch_rpc_error def _tile_aoi ( self , aoi : Union [ geometry . MultiPolygon , geometry . Polygon ], layout_name : Optional [ str ], layout : Optional [ entities . Layout ], resolution : Optional [ float ], crs : Optional [ str ], shape : Optional [ Tuple [ int , int ]]) -> List [ entities . Tile ]: \"\"\" TODO: use Grid or GridName \"\"\" aoi = entities . aoi_to_pb ( aoi ) if layout_name is not None : req = layouts_pb2 . TileAOIRequest ( aoi = aoi , layout_name = layout_name ) else : if layout is None : layout = entities . Layout . regular ( \"\" , crs , shape , resolution ) req = layouts_pb2 . TileAOIRequest ( aoi = aoi , layout = layout . to_pb ()) return [ entities . Tile . from_pb ( tile ) for resp in self . stub . TileAOI ( req ) for tile in resp . tiles ] @utils . catch_rpc_error def _get_xyz_tile ( self , instance : Union [ str , entities . VariableInstance ], records : List [ Union [ str , entities . Record ]], x : int , y : int , z : int , file : str ): req = catalog_pb2 . GetTileRequest ( records = records_pb2 . GroupedRecordIds ( ids = entities . get_ids ( records )), instance_id = entities . get_id ( instance ), x = x , y = y , z = z ) resp = self . stub . GetXYZTile ( req ) f = open ( file , \"wb\" ) f . write ( resp . image . data ) f . close () @utils . catch_rpc_error def _create_layout ( self , layout : entities . Layout , exist_ok ): try : self . stub . CreateLayout ( layouts_pb2 . CreateLayoutRequest ( layout = layout . to_pb ())) except grpc . RpcError as e : e = utils . GeocubeError . from_rpc ( e ) if not e . is_already_exists () or not exist_ok : raise @utils . catch_rpc_error def _layout ( self , name : str ) -> entities . Layout : res = self . stub . ListLayouts ( layouts_pb2 . ListLayoutsRequest ( name_like = name )) if len ( res . layouts ) == 0 : raise utils . GeocubeError ( \"layout\" , grpc . StatusCode . ALREADY_EXISTS . name , \"with name: \" + name ) return entities . Layout . from_pb ( res . layouts [ 0 ]) @utils . catch_rpc_error def _list_layouts ( self , name_like : str ) -> List [ entities . Layout ]: res = self . stub . ListLayouts ( layouts_pb2 . ListLayoutsRequest ( name_like = name_like )) return [ entities . Layout . from_pb ( layout ) for layout in res . layouts ] @utils . catch_rpc_error def _find_container_layouts ( self , instance : Union [ str , entities . VariableInstance ], records : List [ Union [ str , entities . Record ]], tags : Dict [ str , str ], from_time : datetime , to_time : datetime , aoi : geometry . MultiPolygon ) -> Dict [ str , List [ str ]]: if records is not None : req = layouts_pb2 . FindContainerLayoutsRequest ( instance_id = entities . get_id ( instance ), records = records_pb2 . RecordIdList ( ids = entities . get_ids ( records )) ) else : from_time_pb = utils . pb_null_timestamp () if from_time is not None : from_time_pb . FromDatetime ( from_time ) to_time_pb = utils . pb_null_timestamp () if to_time is not None : to_time_pb . FromDatetime ( to_time ) req = catalog_pb2 . FindContainerLayoutsRequest ( instance_id = entities . get_id ( instance ), filters = records_pb2 . RecordFiltersWithAOI ( aoi = aoi , tags = tags , from_time = from_time_pb , to_time = to_time_pb )) return { resp . layout_name : resp . container_uris for resp in self . stub . FindContainerLayouts ( req )} @utils . catch_rpc_error def _delete_layout ( self , name : str ): self . stub . DeleteLayout ( layouts_pb2 . DeleteLayoutRequest ( name = name )) @utils . catch_rpc_error def _create_grid ( self , grid : entities . Grid ): max_cells = min ( len ( grid . cells ), 10000000 ) while True : try : req = [ layouts_pb2 . CreateGridRequest ( grid = grid . to_pb ( max_cells * i , max_cells * ( i + 1 ))) for i in range (( len ( grid . cells ) - 1 ) // max_cells + 1 )] return self . stub . CreateGrid ( iter ( req )) except grpc . RpcError as e : e = utils . GeocubeError . from_rpc ( e ) if e . codename != \"RESOURCE_EXHAUSTED\" : raise r = parse . search ( \"( {volume:d} vs. {max:d} )\" , e . details ) max_cells //= max ( r [ \"volume\" ] // r [ \"max\" ], 2 ) @utils . catch_rpc_error def _list_grids ( self , name_like : str ) -> List [ entities . Grid ]: res = self . stub . ListGrids ( layouts_pb2 . ListGridsRequest ( name_like = name_like )) return [ entities . Grid . from_pb ( grid ) for grid in res . grids ] @utils . catch_rpc_error def _delete_grid ( self , name : str ): self . stub . DeleteGrid ( layouts_pb2 . DeleteGridRequest ( name = name )) __init__ ( uri , secure = False , api_key = '' , verbose = True ) Initialise the connexion to the Geocube Server Parameters: uri ( str ) \u2013 of the Geocube Server secure ( bool , default: False ) \u2013 True to use a TLS Connexion api_key ( str , default: '' ) \u2013 (optional) API Key if Geocube Server is secured using a bearer authentication verbose ( bool , default: True ) \u2013 set the default verbose mode Source code in geocube/client.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 def __init__ ( self , uri : str , secure : bool = False , api_key : str = \"\" , verbose : bool = True ): \"\"\" Initialise the connexion to the Geocube Server Args: uri: of the Geocube Server secure: True to use a TLS Connexion api_key: (optional) API Key if Geocube Server is secured using a bearer authentication verbose: set the default verbose mode \"\"\" assert uri is not None and uri != \"\" , \"geocube.Client: Cannot connect: uri is not defined\" self . pid = os . getpid () if secure : credentials = grpc . ssl_channel_credentials () if api_key != \"\" : token_credentials = grpc . access_token_call_credentials ( api_key ) credentials = grpc . composite_channel_credentials ( credentials , token_credentials ) self . _channel = grpc . secure_channel ( uri , credentials ) else : self . _channel = grpc . insecure_channel ( uri ) self . stub = Stub ( geocube_grpc . GeocubeStub ( self . _channel )) self . verbose = verbose if verbose : print ( \"Connected to Geocube v\" + self . version ()) self . downloader = None add_records_tags ( records , tags ) Add or update tags to a list of records Parameters: records ( List [ Union [ str , Record ]] ) \u2013 List of records to be updated tags ( Dict [ str , str ] ) \u2013 List of new tags or tags to be updated Returns: int \u2013 the number of updated records Source code in geocube/client.py 230 231 232 233 234 235 236 237 238 239 240 def add_records_tags ( self , records : List [ Union [ str , entities . Record ]], tags : Dict [ str , str ]) -> int : \"\"\" Add or update tags to a list of records Args: records: List of records to be updated tags: List of new tags or tags to be updated Returns: the number of updated records \"\"\" return self . _add_records_tags ( records , tags ) containers ( uris ) Get containers and their datasets by uris Parameters: uris ( Union [ str , List [ str ]] ) \u2013 uri or list of uris Source code in geocube/client.py 264 265 266 267 268 269 270 271 def containers ( self , uris : Union [ str , List [ str ]]) -> Union [ entities . Container , List [ entities . Container ]]: \"\"\" Get containers and their datasets by uris Args: uris: uri or list of uris \"\"\" return self . _containers ( uris ) create_aoi ( aoi , exist_ok = False ) Create a new AOI. Raise an error if an AOI with the same coordinates already exists. The id of the AOI can be retrieved from the details of the error. Parameters: aoi ( Union [ Polygon , MultiPolygon ] ) \u2013 in geographic coordinates exist_ok ( bool , default: False ) \u2013 (optional): if already exists, do not raise an error and return the aoi_id Returns: str \u2013 the id of the AOI Source code in geocube/client.py 129 130 131 132 133 134 135 136 137 138 139 140 141 def create_aoi ( self , aoi : Union [ geometry . Polygon , geometry . MultiPolygon ], exist_ok : bool = False ) -> str : \"\"\" Create a new AOI. Raise an error if an AOI with the same coordinates already exists. The id of the AOI can be retrieved from the details of the error. Args: aoi: in geographic coordinates exist_ok: (optional): if already exists, do not raise an error and return the aoi_id Returns: the id of the AOI \"\"\" return self . _create_aoi ( aoi , exist_ok ) create_grid ( grid ) Create a grid in the Geocube Source code in geocube/client.py 459 460 461 def create_grid ( self , grid : entities . Grid ): \"\"\" Create a grid in the Geocube\"\"\" return self . _create_grid ( grid ) create_layout ( layout , exist_ok = False ) Create a layout in the Geocube exist_ok: (optional, see warning): if already exists, do not raise an error. !!! WARNING: it does not mean that the layout already stored in the geocube is exactly the same !!! Source code in geocube/client.py 425 426 427 428 429 430 def create_layout ( self , layout : entities . Layout , exist_ok = False ): \"\"\" Create a layout in the Geocube exist_ok: (optional, see warning): if already exists, do not raise an error. !!! WARNING: it does not mean that the layout already stored in the geocube is exactly the same !!! \"\"\" return self . _create_layout ( layout , exist_ok ) create_palette ( name , colors , replace = False ) Create a new palette from [0, 1] to RGBA, providing a list of index from 0 to 1. The intermediate values are linearly interpolated. Parameters: name ( str ) \u2013 Name of the palette colors ( List [ Tuple [ float , int , int , int , int ]] ) \u2013 a list of tuple[index, R, G, B, A] mapping index to the corresponding RGBA value replace ( bool , default: False ) \u2013 if a palette already exists with the same name, replace it else raise an error. Source code in geocube/client.py 102 103 104 105 106 107 108 109 110 111 112 def create_palette ( self , name : str , colors : List [ Tuple [ float , int , int , int , int ]], replace : bool = False ): \"\"\" Create a new palette from [0, 1] to RGBA, providing a list of index from 0 to 1. The intermediate values are linearly interpolated. Args: name: Name of the palette colors: a list of tuple[index, R, G, B, A] mapping index to the corresponding RGBA value replace: if a palette already exists with the same name, replace it else raise an error. \"\"\" return self . _create_palette ( name , colors , replace ) create_record ( aoi_id , name , tags , date , exist_ok = False ) Create a new record. A record is uniquely identified with the tuple (name, tags, date) Raise an error if a record with the same Name, Tags and Date already exists. Parameters: aoi_id ( str ) \u2013 uuid4 of the AOI. name ( str ) \u2013 of the records. tags ( Dict [ str , str ] ) \u2013 user-defined tags associated to the record. date ( datetime ) \u2013 date of the data referenced by the record. exist_ok ( bool , default: False ) \u2013 (optional, see warning): if already exists, do not raise an error !!! WARNING: it does not mean that the record in the geocube is the same: its aoi may be different !!! Returns: str \u2013 the ID of the record Source code in geocube/client.py 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 def create_record ( self , aoi_id : str , name : str , tags : Dict [ str , str ], date : datetime , exist_ok : bool = False ) \\ -> str : \"\"\" Create a new record. A record is uniquely identified with the tuple (name, tags, date) Raise an error if a record with the same Name, Tags and Date already exists. Args: aoi_id: uuid4 of the AOI. name: of the records. tags: user-defined tags associated to the record. date: date of the data referenced by the record. exist_ok: (optional, see warning): if already exists, do not raise an error !!! WARNING: it does not mean that the record in the geocube is the same: its aoi may be different !!! Returns: the ID of the record \"\"\" try : return self . create_records ([ aoi_id ], [ name ], [ tags ], [ date ])[ 0 ] except utils . GeocubeError as e : if e . is_already_exists () and exist_ok : record = self . list_records ( name , tags = tags , from_time = date , to_time = date )[ 0 ] if record . aoi_id != aoi_id : warnings . warn ( \"Record already exists in the Geocube but the aoi_id is different\" ) return record . id raise create_records ( aoi_ids , names , tags , dates ) Create a list of records. All inputs must have the same length. (see create_record for the description of the parameters) Source code in geocube/client.py 170 171 172 173 174 175 176 def create_records ( self , aoi_ids : List [ str ], names : List [ str ], tags : List [ Dict [ str , str ]], dates : List [ datetime ]) -> List [ str ]: \"\"\" Create a list of records. All inputs must have the same length. (see create_record for the description of the parameters) \"\"\" return self . _create_records ( aoi_ids , names , tags , dates ) create_variable ( name , dformat , bands , unit = '' , description = '' , palette = '' , resampling_alg = entities . Resampling . bilinear , exist_ok = False ) Create a single Variable Parameters: name ( str ) \u2013 Name of the variable dformat ( DataFormat ) \u2013 data format of the variable (min and max are the theoretical extrema) bands ( List [ str ] ) \u2013 Name of the bands unit ( str , default: '' ) \u2013 of the data (for user information only) description ( str , default: '' ) \u2013 of the data (for user information only) palette ( str , default: '' ) \u2013 for rendering in png (TileServer). Must be created using create_palette. resampling_alg ( Resampling , default: bilinear ) \u2013 when reprojection is needed (see entities.Resampling) exist_ok ( bool , default: False ) \u2013 (optional, see warning): if already exists, do not raise an error. !!! WARNING: it does not mean that the variable already stored in the geocube is exactly the same !!! Returns: Variable \u2013 the variable Source code in geocube/client.py 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 def create_variable ( self , name : str , dformat : entities . DataFormat , bands : List [ str ], unit : str = \"\" , description : str = \"\" , palette : str = \"\" , resampling_alg : entities . Resampling = entities . Resampling . bilinear , exist_ok : bool = False ) \\ -> entities . Variable : \"\"\" Create a single Variable Args: name: Name of the variable dformat: data format of the variable (min and max are the theoretical extrema) bands: Name of the bands unit: of the data (for user information only) description: of the data (for user information only) palette: for rendering in png (TileServer). Must be created using create_palette. resampling_alg: when reprojection is needed (see entities.Resampling) exist_ok: (optional, see warning): if already exists, do not raise an error. !!! WARNING: it does not mean that the variable already stored in the geocube is exactly the same !!! Returns: the variable \"\"\" return self . _create_variable ( name , dformat , bands , unit , description , palette , resampling_alg , exist_ok ) delete_grid ( name = '' ) Delete a grid by its name Source code in geocube/client.py 470 471 472 def delete_grid ( self , name : str = \"\" ): \"\"\" Delete a grid by its name \"\"\" return self . _delete_grid ( name ) delete_layout ( name = '' ) Delete a layout from the Geocube Source code in geocube/client.py 455 456 457 def delete_layout ( self , name : str = \"\" ): \"\"\" Delete a layout from the Geocube \"\"\" return self . _delete_layout ( name ) delete_records ( records , no_fail = False ) Delete records iif no dataset are indexed to them. Parameters: records ( List [ Union [ str , Record ]] ) \u2013 List of records to be deleted no_fail ( bool , default: False ) \u2013 if true, do not fail if some records still have datasets that refer to them, and delete the others Source code in geocube/client.py 254 255 256 257 258 259 260 261 262 def delete_records ( self , records : List [ Union [ str , entities . Record ]], no_fail : bool = False ): \"\"\" Delete records iif no dataset are indexed to them. Args: records: List of records to be deleted no_fail: if true, do not fail if some records still have datasets that refer to them, and delete the others \"\"\" return self . _delete_records ( records , no_fail ) find_container_layouts ( instance , records = None , tags = None , from_time = None , to_time = None , aoi = None ) Find layouts of the containers covering an area or a list of records for a given instance Source code in geocube/client.py 445 446 447 448 449 450 451 452 453 def find_container_layouts ( self , instance : Union [ str , entities . VariableInstance ], records : List [ Union [ str , entities . Record ]] = None , tags : Dict [ str , str ] = None , from_time : datetime = None , to_time : datetime = None , aoi : geometry . MultiPolygon = None ) -> Dict [ str , List [ str ]]: \"\"\" Find layouts of the containers covering an area or a list of records for a given instance \"\"\" return self . _find_container_layouts ( instance , records , tags , from_time , to_time , aoi ) get_cube ( params , * , resampling_alg = entities . Resampling . undefined , headers_only = False , compression = 0 , verbose = None ) Get a cube given a CubeParameters Parameters: params ( CubeParams ) \u2013 CubeParams (see entities.CubeParams) resampling_alg ( Resampling , default: undefined ) \u2013 if defined, overwrite the variable.Resampling used for reprojection. headers_only ( bool , default: False ) \u2013 Only returns the header of each image (gives an overview of the query) compression ( int , default: 0 ) \u2013 define a level of compression to speed up the transfer. (0: no compression, 1 fastest to 9 best, -2: huffman-only) The data is compressed by the server and decompressed by the Client. Compression=0 or -2 is advised if the bandwidth is not limited verbose ( bool , default: None ) \u2013 display information during the transfer (if None, use the default verbose mode) Returns: Tuple [ List [ array ], List [ GroupedRecords ]] \u2013 list of images (np.ndarray) and the list of corresponding records (several records can be returned for each image when they are grouped together, by date or something else. See entities.Record.group_by) Source code in geocube/client.py 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 def get_cube ( self , params : entities . CubeParams , * , resampling_alg : entities . Resampling = entities . Resampling . undefined , headers_only : bool = False , compression : int = 0 , verbose : bool = None ) \\ -> Tuple [ List [ np . array ], List [ entities . GroupedRecords ]]: \"\"\" Get a cube given a CubeParameters Args: params: CubeParams (see entities.CubeParams) resampling_alg: if defined, overwrite the variable.Resampling used for reprojection. headers_only: Only returns the header of each image (gives an overview of the query) compression: define a level of compression to speed up the transfer. (0: no compression, 1 fastest to 9 best, -2: huffman-only) The data is compressed by the server and decompressed by the Client. Compression=0 or -2 is advised if the bandwidth is not limited verbose: display information during the transfer (if None, use the default verbose mode) Returns: list of images (np.ndarray) and the list of corresponding records (several records can be returned for each image when they are grouped together, by date or something else. See entities.Record.group_by) \"\"\" cube = self . _get_cube_it ( params , resampling_alg = resampling_alg , headers_only = headers_only , compression = compression ) images , grouped_records = [], [] verbose = self . verbose if verbose is None else verbose if verbose : print ( \"GetCube returns {} images from {} datasets\" . format ( cube . count , cube . nb_datasets )) for image , metadata , err in cube : if err is not None : if err == cubeiterator . NOT_FOUND_ERROR : if verbose : print ( err ) continue raise ValueError ( err ) if verbose : min_date = metadata . min_date . strftime ( \"%Y-%m- %d _%H:%M:%S\" ) max_date = metadata . max_date . strftime ( \"%Y-%m- %d _%H:%M:%S\" ) print ( \"Image {} received ( {}{} kb) RecordTime: {} RecordName: {} Shape: {} \" . format ( cube . index + 1 , '<' if headers_only else '' , metadata . bytes // 1024 , min_date if min_date == max_date else min_date + \" to \" + max_date , metadata . grouped_records [ 0 ] . name , image . shape )) images . append ( image ) grouped_records . append ( metadata . grouped_records ) return images , grouped_records get_cube_it ( params , * , resampling_alg = entities . Resampling . undefined , headers_only = False , compression = 0 , file_format = FileFormatRaw , file_pattern = None ) Returns a cube iterator over the requested images Parameters: params ( CubeParams ) \u2013 CubeParams (see entities.CubeParams) resampling_alg ( Resampling , default: undefined ) \u2013 if defined, overwrite the variable.Resampling used for reprojection. headers_only \u2013 returns only the header of the dataset (use this option to control the output of get_cube) compression \u2013 define a level of compression to speed up the transfer (0: no compression, 1 fastest to 9 best, -2: huffman-only) The data is compressed by the server and decompressed by the Client. Compression=0 or -2 is advised if the bandwidth is not limited file_format \u2013 (optional) currently supported geocube.FileFormatRaw & geocube.FileFormatGTiff file_pattern \u2013 (optional) iif file_format != Raw, pattern of the file name. {#} will be replaced by the number of image, {date} and {id} by the value of the record Returns: CubeIterator \u2013 an iterator yielding an image, its associated records, an error (or None) and the size of the image client = Client('127.0.0.1:8080', False) cube_params = entities.CubeParams.from_records(\"+proj=utm +zone=31\", ... entities.geo_transform(366162, 4833123, 30), (512, 512), ... client.variable(name=\"test/rgb\").instance(\"master\"), records=client.list_records('france')) affine.Affine.translation(366162, 4833123)*affine.Affine.scale(30, -30)) cube_it = client.get_cube_it(cube_params) from matplotlib import pyplot as plt for image, , , err in cube_it: ... if err != cubeiterator.NOT_FOUND_ERROR: ... raise ValueError(err) ... if not err: ... plt.figure(cube_it.index+1) ... plt.imshow(image) Source code in geocube/client.py 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 def get_cube_it ( self , params : entities . CubeParams , * , resampling_alg : entities . Resampling = entities . Resampling . undefined , headers_only : bool = False , compression : int = 0 , file_format = FileFormatRaw , file_pattern : str = None ) -> entities . CubeIterator : \"\"\" Returns a cube iterator over the requested images Args: params: CubeParams (see entities.CubeParams) resampling_alg: if defined, overwrite the variable.Resampling used for reprojection. headers_only : returns only the header of the dataset (use this option to control the output of get_cube) compression : define a level of compression to speed up the transfer (0: no compression, 1 fastest to 9 best, -2: huffman-only) The data is compressed by the server and decompressed by the Client. Compression=0 or -2 is advised if the bandwidth is not limited file_format : (optional) currently supported geocube.FileFormatRaw & geocube.FileFormatGTiff file_pattern : (optional) iif file_format != Raw, pattern of the file name. {#} will be replaced by the number of image, {date} and {id} by the value of the record Returns: an iterator yielding an image, its associated records, an error (or None) and the size of the image >>> client = Client('127.0.0.1:8080', False) >>> cube_params = entities.CubeParams.from_records(\"+proj=utm +zone=31\", ... entities.geo_transform(366162, 4833123, 30), (512, 512), ... client.variable(name=\"test/rgb\").instance(\"master\"), records=client.list_records('france')) affine.Affine.translation(366162, 4833123)*affine.Affine.scale(30, -30)) >>> cube_it = client.get_cube_it(cube_params) >>> from matplotlib import pyplot as plt >>> for image, _, _, err in cube_it: ... if err != cubeiterator.NOT_FOUND_ERROR: ... raise ValueError(err) ... if not err: ... plt.figure(cube_it.index+1) ... plt.imshow(image) \"\"\" return self . _get_cube_it ( params , resampling_alg = resampling_alg , headers_only = headers_only , compression = compression , file_format = file_format , file_pattern = file_pattern ) get_record ( _id ) Deprecated: use record() instead Source code in geocube/client.py 178 179 180 def get_record ( self , _id : str ) -> entities . Record : \"\"\" Deprecated: use record() instead \"\"\" return self . record ( _id ) get_records ( ids ) Get a list of records. Source code in geocube/client.py 188 189 190 191 192 def get_records ( self , ids : List [ str ]) -> List [ entities . Record ]: \"\"\" Get a list of records. \"\"\" return self . _get_records ( ids ) get_xyz_tile ( instance , records , x , y , z , file ) Create a PNG file covering the (X,Y,Z) web-mercator tile, using the palette of the variable. Parameters: instance ( Union [ str , VariableInstance ] ) \u2013 instance of the variable records ( List [ Union [ str , Record ]] ) \u2013 list of records x ( int ) \u2013 coordinate of the web-mercator XYZ tile y ( int ) \u2013 coordinate of the web-mercator XYZ tile z ( int ) \u2013 coordinate of the web-mercator XYZ tile file ( str ) \u2013 output PNG file Source code in geocube/client.py 410 411 412 413 414 415 416 417 418 419 420 421 422 423 def get_xyz_tile ( self , instance : Union [ str , entities . VariableInstance ], records : List [ Union [ str , entities . Record ]], x : int , y : int , z : int , file : str ): \"\"\" Create a PNG file covering the (X,Y,Z) web-mercator tile, using the palette of the variable. Args: instance: instance of the variable records: list of records x: coordinate of the web-mercator XYZ tile y: coordinate of the web-mercator XYZ tile z: coordinate of the web-mercator XYZ tile file: output PNG file \"\"\" return self . _get_xyz_tile ( instance , records , x , y , z , file ) index ( containers ) Index a new container. Parameters: containers ( List [ Container ] ) \u2013 List of container to index. Source code in geocube/client.py 273 274 275 276 277 278 279 280 def index ( self , containers : List [ entities . Container ]): \"\"\" Index a new container. Args: containers: List of container to index. \"\"\" return self . _index ( containers ) index_dataset ( uri , record , instance , dformat , bands = None , min_out = None , max_out = None , exponent = 1 , managed = False ) Index the given \"bands\" of the dataset located at \"uri\", referenced by a record and an instance. Parameters: uri ( str ) \u2013 of the file to index record ( Union [ str , Record , Tuple [ str , Dict [ str , str ], datetime ]] ) \u2013 id of the record describing the data-take or a tuple (name, metadata, datetime) to create the record on the fly instance ( VariableInstance ) \u2013 describing the data dformat ( DataFormat ) \u2013 describing the internal format (see entities.DataFormat.from_user()) bands ( List [ int ] , default: None ) \u2013 subset of bands' file (start at 1) that maps to variable.bands (by default, all the bands) min_out ( float , default: None ) \u2013 (optional, default: instance.dformat.min_value, instance.dformat.dtype) maps dformat.min_value max_out ( float , default: None ) \u2013 (optional, default: instance.dformat.max_value, instance.dformat.dtype) maps dformat.max_value exponent ( float , default: 1 ) \u2013 (optional, default: 1) non-linear scaling between dformat.min_max_value to min_max_out. managed ( bool , default: False ) \u2013 if True, the geocube takes the ownership of the file, removing it if the dataset is removed Source code in geocube/client.py 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 def index_dataset ( self , uri : str , record : Union [ str , entities . Record , Tuple [ str , Dict [ str , str ], datetime ]], instance : entities . VariableInstance , dformat : entities . DataFormat , bands : List [ int ] = None , min_out : float = None , max_out : float = None , exponent : float = 1 , managed : bool = False ): \"\"\" Index the given \"bands\" of the dataset located at \"uri\", referenced by a record and an instance. Args: uri: of the file to index record: id of the record describing the data-take or a tuple (name, metadata, datetime) to create the record on the fly instance: describing the data dformat: describing the internal format (see entities.DataFormat.from_user()) bands: subset of bands' file (start at 1) that maps to `variable.bands` (by default, all the bands) min_out: (optional, default: instance.dformat.min_value, instance.dformat.dtype) maps dformat.min_value max_out: (optional, default: instance.dformat.max_value, instance.dformat.dtype) maps dformat.max_value exponent: (optional, default: 1) non-linear scaling between dformat.min_max_value to min_max_out. managed: if True, the geocube takes the ownership of the file, removing it if the dataset is removed \"\"\" return self . _index_dataset ( uri , record , instance , dformat , bands , min_out , max_out , exponent , managed ) layout ( name ) Get layout by name Source code in geocube/client.py 432 433 434 435 436 def layout ( self , name : str ) -> entities . Layout : \"\"\" Get layout by name \"\"\" return self . _layout ( name ) list_grids ( name_like = '' ) List grids by name name_like: pattern of the name. * and ? are supported to match all or any character. Source code in geocube/client.py 463 464 465 466 467 468 def list_grids ( self , name_like : str = \"\" ) -> List [ entities . Grid ]: \"\"\" List grids by name name_like: pattern of the name. * and ? are supported to match all or any character. \"\"\" return self . _list_grids ( name_like ) list_layouts ( name_like = '' ) List available layouts by name name_like: pattern of the name. * and ? are supported to match all or any character. Source code in geocube/client.py 438 439 440 441 442 443 def list_layouts ( self , name_like : str = \"\" ) -> List [ entities . Layout ]: \"\"\" List available layouts by name name_like: pattern of the name. * and ? are supported to match all or any character. \"\"\" return self . _list_layouts ( name_like ) list_records ( name = '' , tags = None , from_time = None , to_time = None , aoi = None , limit = 10000 , page = 0 , with_aoi = False ) List records given filters Parameters: name ( str , default: '' ) \u2013 pattern of the name. * and ? are supported to match all or any character. (?i) can be added at the end to be insensitive to case tags ( Dict [ str , str ] , default: None ) \u2013 list of mandatory tags. Support the same pattern as name. from_time ( datetime , default: None ) \u2013 filter by date to_time ( datetime , default: None ) \u2013 filter by date aoi ( MultiPolygon , default: None ) \u2013 records that intersect the AOI in geographic coordinates limit ( int , default: 10000 ) \u2013 the number of records returned (0 to return all records) page ( int , default: 0 ) \u2013 start at 0 with_aoi ( bool , default: False ) \u2013 also returns the AOI of the record. Otherwise, only the ID of the aoi is returned. load_aoi(record) can be called to retrieve the AOI later. Returns: List [ Record ] \u2013 a list of records Source code in geocube/client.py 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 def list_records ( self , name : str = \"\" , tags : Dict [ str , str ] = None , from_time : datetime = None , to_time : datetime = None , aoi : geometry . MultiPolygon = None , limit : int = 10000 , page : int = 0 , with_aoi : bool = False ) -> List [ entities . Record ]: \"\"\" List records given filters Args: name: pattern of the name. * and ? are supported to match all or any character. (?i) can be added at the end to be insensitive to case tags: list of mandatory tags. Support the same pattern as name. from_time: filter by date to_time: filter by date aoi: records that intersect the AOI in geographic coordinates limit: the number of records returned (0 to return all records) page: start at 0 with_aoi: also returns the AOI of the record. Otherwise, only the ID of the aoi is returned. load_aoi(record) can be called to retrieve the AOI later. Returns: a list of records \"\"\" return self . _list_records ( name , tags , from_time , to_time , aoi , limit , page , with_aoi ) list_variables ( name = '' , limit = 0 , page = 0 ) List all the variables given a pattern Parameters: name ( str , default: '' ) \u2013 pattern of the name. * and ? are supported to match all or any character. (?i) can be added at the end to be insensitive to case limit ( int , default: 0 ) \u2013 limit the number of variables returned page ( int , default: 0 ) \u2013 number of the page (starting at 0). Returns: List [ Variable ] \u2013 a list of variable Source code in geocube/client.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 def list_variables ( self , name : str = \"\" , limit : int = 0 , page : int = 0 ) -> List [ entities . Variable ]: \"\"\" List all the variables given a pattern Args: name: pattern of the name. * and ? are supported to match all or any character. (?i) can be added at the end to be insensitive to case limit: limit the number of variables returned page: number of the page (starting at 0). Returns: a list of variable \"\"\" return self . _list_variables ( name , limit , page ) load_aoi ( aoi_id ) Load the geometry of the AOI of the given record Parameters: aoi_id ( Union [ str , Record ] ) \u2013 uuid of the AOI or the record. If the record is provided, its geometry will be updated Returns: MultiPolygon \u2013 the geometry of the AOI Source code in geocube/client.py 218 219 220 221 222 223 224 225 226 227 228 def load_aoi ( self , aoi_id : Union [ str , entities . Record ]) -> geometry . MultiPolygon : \"\"\" Load the geometry of the AOI of the given record Args: aoi_id: uuid of the AOI or the record. If the record is provided, its geometry will be updated Returns: the geometry of the AOI \"\"\" return self . _load_aoi ( aoi_id ) record ( _id ) Get a record by id Source code in geocube/client.py 182 183 184 185 186 def record ( self , _id : str ) -> entities . Record : \"\"\" Get a record by id \"\"\" r = self . get_records ([ _id ]) assert len ( r ) > 0 , utils . GeocubeError ( \"get_record\" , grpc . StatusCode . NOT_FOUND . name , \"record with id \" + _id ) return r [ 0 ] remove_records_tags ( records , tag_keys ) Remove tags keys from a list of records Parameters: records ( List [ Union [ str , Record ]] ) \u2013 List of records to be updated tag_keys ( List [ str ] ) \u2013 List of keys to be deleted Returns: int \u2013 the number of updated records Source code in geocube/client.py 242 243 244 245 246 247 248 249 250 251 252 def remove_records_tags ( self , records : List [ Union [ str , entities . Record ]], tag_keys : List [ str ]) -> int : \"\"\" Remove tags keys from a list of records Args: records: List of records to be updated tag_keys: List of keys to be deleted Returns: the number of updated records \"\"\" return self . _remove_records_tags ( records , tag_keys ) tile_aoi ( aoi , layout_name = None , layout = None , resolution = None , crs = None , shape = None ) Tile an AOI Parameters: aoi ( Union [ MultiPolygon , Polygon ] ) \u2013 AOI to be tiled in geographic coordinates crs ( Optional [ str ] , default: None ) \u2013 CRS of the tile (not the AOI) resolution ( Optional [ float ] , default: None ) \u2013 resolution of the tile shape ( Optional [ Tuple [ int , int ]] , default: None ) \u2013 shape of each tile layout_name ( Optional [ str ] , default: None ) \u2013 use a defined layout. layout ( Optional [ Layout ] , default: None ) \u2013 use a customer defined layout Returns: List [ Tile ] \u2013 a list of Tiles covering the AOI in the given CRS at the given resolution Source code in geocube/client.py 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 def tile_aoi ( self , aoi : Union [ geometry . MultiPolygon , geometry . Polygon ], layout_name : Optional [ str ] = None , layout : Optional [ entities . Layout ] = None , resolution : Optional [ float ] = None , crs : Optional [ str ] = None , shape : Optional [ Tuple [ int , int ]] = None ) -> List [ entities . Tile ]: \"\"\" Tile an AOI Args: aoi: AOI to be tiled in **geographic coordinates** crs: CRS of the tile (not the AOI) resolution: resolution of the tile shape: shape of each tile layout_name: use a defined layout. layout: use a customer defined layout Returns: a list of Tiles covering the AOI in the given CRS at the given resolution \"\"\" return self . _tile_aoi ( aoi , layout_name , layout , resolution , crs , shape ) variable ( name = None , id_ = None , instance_id = None ) Fetch a variable given an id, a name or an instance id (mutually exclusive) Parameters: name ( str , default: None ) \u2013 id_ ( str , default: None ) \u2013 internal id of the variable (uuid4) instance_id ( str , default: None ) \u2013 internal id of one instance of the variable (uuid4) Returns: Union [ Variable , VariableInstance ] \u2013 either a Variable (first two cases) or a VariableInstance (specialization of the variable) Source code in geocube/client.py 65 66 67 68 69 70 71 72 73 74 75 76 77 78 def variable ( self , name : str = None , id_ : str = None , instance_id : str = None ) \\ -> Union [ entities . Variable , entities . VariableInstance ]: \"\"\" Fetch a variable given an id, a name or an instance id (mutually exclusive) Args: name: id_: internal id of the variable (uuid4) instance_id: internal id of one instance of the variable (uuid4) Returns: either a Variable (first two cases) or a VariableInstance (specialization of the variable) \"\"\" return self . _variable ( name , id_ , instance_id ) version () Returns the version of the Geocube Server Source code in geocube/client.py 61 62 63 def version ( self ) -> str : \"\"\" Returns the version of the Geocube Server \"\"\" return self . _version ()","title":"Basic access"},{"location":"user-guide/client/client-reference/#client","text":"Geocube-client has three level of access: Client is for basic access. The Client has CRUD access to most entities. It can also index new images. Consolidater is for optimization of the database, through consolidation of the datasets. It has CRUD access to entities.job . Admin is for operation that must be done wisely and cautiously. Source code in geocube/client.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 class Client : def __init__ ( self , uri : str , secure : bool = False , api_key : str = \"\" , verbose : bool = True ): \"\"\" Initialise the connexion to the Geocube Server Args: uri: of the Geocube Server secure: True to use a TLS Connexion api_key: (optional) API Key if Geocube Server is secured using a bearer authentication verbose: set the default verbose mode \"\"\" assert uri is not None and uri != \"\" , \"geocube.Client: Cannot connect: uri is not defined\" self . pid = os . getpid () if secure : credentials = grpc . ssl_channel_credentials () if api_key != \"\" : token_credentials = grpc . access_token_call_credentials ( api_key ) credentials = grpc . composite_channel_credentials ( credentials , token_credentials ) self . _channel = grpc . secure_channel ( uri , credentials ) else : self . _channel = grpc . insecure_channel ( uri ) self . stub = Stub ( geocube_grpc . GeocubeStub ( self . _channel )) self . verbose = verbose if verbose : print ( \"Connected to Geocube v\" + self . version ()) self . downloader = None def is_pid_ok ( self ) -> bool : return self . pid == os . getpid () def use_downloader ( self , downloader : Downloader ): self . downloader = downloader def set_timeout ( self , timeout_sec : float ): self . stub . timeout = timeout_sec def version ( self ) -> str : \"\"\" Returns the version of the Geocube Server \"\"\" return self . _version () def variable ( self , name : str = None , id_ : str = None , instance_id : str = None ) \\ -> Union [ entities . Variable , entities . VariableInstance ]: \"\"\" Fetch a variable given an id, a name or an instance id (mutually exclusive) Args: name: id_: internal id of the variable (uuid4) instance_id: internal id of one instance of the variable (uuid4) Returns: either a Variable (first two cases) or a VariableInstance (specialization of the variable) \"\"\" return self . _variable ( name , id_ , instance_id ) def create_variable ( self , name : str , dformat : entities . DataFormat , bands : List [ str ], unit : str = \"\" , description : str = \"\" , palette : str = \"\" , resampling_alg : entities . Resampling = entities . Resampling . bilinear , exist_ok : bool = False ) \\ -> entities . Variable : \"\"\" Create a single Variable Args: name: Name of the variable dformat: data format of the variable (min and max are the theoretical extrema) bands: Name of the bands unit: of the data (for user information only) description: of the data (for user information only) palette: for rendering in png (TileServer). Must be created using create_palette. resampling_alg: when reprojection is needed (see entities.Resampling) exist_ok: (optional, see warning): if already exists, do not raise an error. !!! WARNING: it does not mean that the variable already stored in the geocube is exactly the same !!! Returns: the variable \"\"\" return self . _create_variable ( name , dformat , bands , unit , description , palette , resampling_alg , exist_ok ) def create_palette ( self , name : str , colors : List [ Tuple [ float , int , int , int , int ]], replace : bool = False ): \"\"\" Create a new palette from [0, 1] to RGBA, providing a list of index from 0 to 1. The intermediate values are linearly interpolated. Args: name: Name of the palette colors: a list of tuple[index, R, G, B, A] mapping index to the corresponding RGBA value replace: if a palette already exists with the same name, replace it else raise an error. \"\"\" return self . _create_palette ( name , colors , replace ) def list_variables ( self , name : str = \"\" , limit : int = 0 , page : int = 0 ) -> List [ entities . Variable ]: \"\"\" List all the variables given a pattern Args: name: pattern of the name. * and ? are supported to match all or any character. (?i) can be added at the end to be insensitive to case limit: limit the number of variables returned page: number of the page (starting at 0). Returns: a list of variable \"\"\" return self . _list_variables ( name , limit , page ) def create_aoi ( self , aoi : Union [ geometry . Polygon , geometry . MultiPolygon ], exist_ok : bool = False ) -> str : \"\"\" Create a new AOI. Raise an error if an AOI with the same coordinates already exists. The id of the AOI can be retrieved from the details of the error. Args: aoi: in geographic coordinates exist_ok: (optional): if already exists, do not raise an error and return the aoi_id Returns: the id of the AOI \"\"\" return self . _create_aoi ( aoi , exist_ok ) def create_record ( self , aoi_id : str , name : str , tags : Dict [ str , str ], date : datetime , exist_ok : bool = False ) \\ -> str : \"\"\" Create a new record. A record is uniquely identified with the tuple (name, tags, date) Raise an error if a record with the same Name, Tags and Date already exists. Args: aoi_id: uuid4 of the AOI. name: of the records. tags: user-defined tags associated to the record. date: date of the data referenced by the record. exist_ok: (optional, see warning): if already exists, do not raise an error !!! WARNING: it does not mean that the record in the geocube is the same: its aoi may be different !!! Returns: the ID of the record \"\"\" try : return self . create_records ([ aoi_id ], [ name ], [ tags ], [ date ])[ 0 ] except utils . GeocubeError as e : if e . is_already_exists () and exist_ok : record = self . list_records ( name , tags = tags , from_time = date , to_time = date )[ 0 ] if record . aoi_id != aoi_id : warnings . warn ( \"Record already exists in the Geocube but the aoi_id is different\" ) return record . id raise def create_records ( self , aoi_ids : List [ str ], names : List [ str ], tags : List [ Dict [ str , str ]], dates : List [ datetime ]) -> List [ str ]: \"\"\" Create a list of records. All inputs must have the same length. (see create_record for the description of the parameters) \"\"\" return self . _create_records ( aoi_ids , names , tags , dates ) def get_record ( self , _id : str ) -> entities . Record : \"\"\" Deprecated: use record() instead \"\"\" return self . record ( _id ) def record ( self , _id : str ) -> entities . Record : \"\"\" Get a record by id \"\"\" r = self . get_records ([ _id ]) assert len ( r ) > 0 , utils . GeocubeError ( \"get_record\" , grpc . StatusCode . NOT_FOUND . name , \"record with id \" + _id ) return r [ 0 ] def get_records ( self , ids : List [ str ]) -> List [ entities . Record ]: \"\"\" Get a list of records. \"\"\" return self . _get_records ( ids ) def list_records ( self , name : str = \"\" , tags : Dict [ str , str ] = None , from_time : datetime = None , to_time : datetime = None , aoi : geometry . MultiPolygon = None , limit : int = 10000 , page : int = 0 , with_aoi : bool = False ) -> List [ entities . Record ]: \"\"\" List records given filters Args: name: pattern of the name. * and ? are supported to match all or any character. (?i) can be added at the end to be insensitive to case tags: list of mandatory tags. Support the same pattern as name. from_time: filter by date to_time: filter by date aoi: records that intersect the AOI in geographic coordinates limit: the number of records returned (0 to return all records) page: start at 0 with_aoi: also returns the AOI of the record. Otherwise, only the ID of the aoi is returned. load_aoi(record) can be called to retrieve the AOI later. Returns: a list of records \"\"\" return self . _list_records ( name , tags , from_time , to_time , aoi , limit , page , with_aoi ) def load_aoi ( self , aoi_id : Union [ str , entities . Record ]) -> geometry . MultiPolygon : \"\"\" Load the geometry of the AOI of the given record Args: aoi_id: uuid of the AOI or the record. If the record is provided, its geometry will be updated Returns: the geometry of the AOI \"\"\" return self . _load_aoi ( aoi_id ) def add_records_tags ( self , records : List [ Union [ str , entities . Record ]], tags : Dict [ str , str ]) -> int : \"\"\" Add or update tags to a list of records Args: records: List of records to be updated tags: List of new tags or tags to be updated Returns: the number of updated records \"\"\" return self . _add_records_tags ( records , tags ) def remove_records_tags ( self , records : List [ Union [ str , entities . Record ]], tag_keys : List [ str ]) -> int : \"\"\" Remove tags keys from a list of records Args: records: List of records to be updated tag_keys: List of keys to be deleted Returns: the number of updated records \"\"\" return self . _remove_records_tags ( records , tag_keys ) def delete_records ( self , records : List [ Union [ str , entities . Record ]], no_fail : bool = False ): \"\"\" Delete records iif no dataset are indexed to them. Args: records: List of records to be deleted no_fail: if true, do not fail if some records still have datasets that refer to them, and delete the others \"\"\" return self . _delete_records ( records , no_fail ) def containers ( self , uris : Union [ str , List [ str ]]) -> Union [ entities . Container , List [ entities . Container ]]: \"\"\" Get containers and their datasets by uris Args: uris: uri or list of uris \"\"\" return self . _containers ( uris ) def index ( self , containers : List [ entities . Container ]): \"\"\" Index a new container. Args: containers: List of container to index. \"\"\" return self . _index ( containers ) def index_dataset ( self , uri : str , record : Union [ str , entities . Record , Tuple [ str , Dict [ str , str ], datetime ]], instance : entities . VariableInstance , dformat : entities . DataFormat , bands : List [ int ] = None , min_out : float = None , max_out : float = None , exponent : float = 1 , managed : bool = False ): \"\"\" Index the given \"bands\" of the dataset located at \"uri\", referenced by a record and an instance. Args: uri: of the file to index record: id of the record describing the data-take or a tuple (name, metadata, datetime) to create the record on the fly instance: describing the data dformat: describing the internal format (see entities.DataFormat.from_user()) bands: subset of bands' file (start at 1) that maps to `variable.bands` (by default, all the bands) min_out: (optional, default: instance.dformat.min_value, instance.dformat.dtype) maps dformat.min_value max_out: (optional, default: instance.dformat.max_value, instance.dformat.dtype) maps dformat.max_value exponent: (optional, default: 1) non-linear scaling between dformat.min_max_value to min_max_out. managed: if True, the geocube takes the ownership of the file, removing it if the dataset is removed \"\"\" return self . _index_dataset ( uri , record , instance , dformat , bands , min_out , max_out , exponent , managed ) def get_cube_metadata ( self , params : entities . CubeParams ) -> entities . CubeMetadata : return self . _get_cube_metadata ( params ) def get_cube ( self , params : entities . CubeParams , * , resampling_alg : entities . Resampling = entities . Resampling . undefined , headers_only : bool = False , compression : int = 0 , verbose : bool = None ) \\ -> Tuple [ List [ np . array ], List [ entities . GroupedRecords ]]: \"\"\" Get a cube given a CubeParameters Args: params: CubeParams (see entities.CubeParams) resampling_alg: if defined, overwrite the variable.Resampling used for reprojection. headers_only: Only returns the header of each image (gives an overview of the query) compression: define a level of compression to speed up the transfer. (0: no compression, 1 fastest to 9 best, -2: huffman-only) The data is compressed by the server and decompressed by the Client. Compression=0 or -2 is advised if the bandwidth is not limited verbose: display information during the transfer (if None, use the default verbose mode) Returns: list of images (np.ndarray) and the list of corresponding records (several records can be returned for each image when they are grouped together, by date or something else. See entities.Record.group_by) \"\"\" cube = self . _get_cube_it ( params , resampling_alg = resampling_alg , headers_only = headers_only , compression = compression ) images , grouped_records = [], [] verbose = self . verbose if verbose is None else verbose if verbose : print ( \"GetCube returns {} images from {} datasets\" . format ( cube . count , cube . nb_datasets )) for image , metadata , err in cube : if err is not None : if err == cubeiterator . NOT_FOUND_ERROR : if verbose : print ( err ) continue raise ValueError ( err ) if verbose : min_date = metadata . min_date . strftime ( \"%Y-%m- %d _%H:%M:%S\" ) max_date = metadata . max_date . strftime ( \"%Y-%m- %d _%H:%M:%S\" ) print ( \"Image {} received ( {}{} kb) RecordTime: {} RecordName: {} Shape: {} \" . format ( cube . index + 1 , '<' if headers_only else '' , metadata . bytes // 1024 , min_date if min_date == max_date else min_date + \" to \" + max_date , metadata . grouped_records [ 0 ] . name , image . shape )) images . append ( image ) grouped_records . append ( metadata . grouped_records ) return images , grouped_records def get_cube_it ( self , params : entities . CubeParams , * , resampling_alg : entities . Resampling = entities . Resampling . undefined , headers_only : bool = False , compression : int = 0 , file_format = FileFormatRaw , file_pattern : str = None ) -> entities . CubeIterator : \"\"\" Returns a cube iterator over the requested images Args: params: CubeParams (see entities.CubeParams) resampling_alg: if defined, overwrite the variable.Resampling used for reprojection. headers_only : returns only the header of the dataset (use this option to control the output of get_cube) compression : define a level of compression to speed up the transfer (0: no compression, 1 fastest to 9 best, -2: huffman-only) The data is compressed by the server and decompressed by the Client. Compression=0 or -2 is advised if the bandwidth is not limited file_format : (optional) currently supported geocube.FileFormatRaw & geocube.FileFormatGTiff file_pattern : (optional) iif file_format != Raw, pattern of the file name. {#} will be replaced by the number of image, {date} and {id} by the value of the record Returns: an iterator yielding an image, its associated records, an error (or None) and the size of the image >>> client = Client('127.0.0.1:8080', False) >>> cube_params = entities.CubeParams.from_records(\"+proj=utm +zone=31\", ... entities.geo_transform(366162, 4833123, 30), (512, 512), ... client.variable(name=\"test/rgb\").instance(\"master\"), records=client.list_records('france')) affine.Affine.translation(366162, 4833123)*affine.Affine.scale(30, -30)) >>> cube_it = client.get_cube_it(cube_params) >>> from matplotlib import pyplot as plt >>> for image, _, _, err in cube_it: ... if err != cubeiterator.NOT_FOUND_ERROR: ... raise ValueError(err) ... if not err: ... plt.figure(cube_it.index+1) ... plt.imshow(image) \"\"\" return self . _get_cube_it ( params , resampling_alg = resampling_alg , headers_only = headers_only , compression = compression , file_format = file_format , file_pattern = file_pattern ) def tile_aoi ( self , aoi : Union [ geometry . MultiPolygon , geometry . Polygon ], layout_name : Optional [ str ] = None , layout : Optional [ entities . Layout ] = None , resolution : Optional [ float ] = None , crs : Optional [ str ] = None , shape : Optional [ Tuple [ int , int ]] = None ) -> List [ entities . Tile ]: \"\"\" Tile an AOI Args: aoi: AOI to be tiled in **geographic coordinates** crs: CRS of the tile (not the AOI) resolution: resolution of the tile shape: shape of each tile layout_name: use a defined layout. layout: use a customer defined layout Returns: a list of Tiles covering the AOI in the given CRS at the given resolution \"\"\" return self . _tile_aoi ( aoi , layout_name , layout , resolution , crs , shape ) def get_xyz_tile ( self , instance : Union [ str , entities . VariableInstance ], records : List [ Union [ str , entities . Record ]], x : int , y : int , z : int , file : str ): \"\"\" Create a PNG file covering the (X,Y,Z) web-mercator tile, using the palette of the variable. Args: instance: instance of the variable records: list of records x: coordinate of the web-mercator XYZ tile y: coordinate of the web-mercator XYZ tile z: coordinate of the web-mercator XYZ tile file: output PNG file \"\"\" return self . _get_xyz_tile ( instance , records , x , y , z , file ) def create_layout ( self , layout : entities . Layout , exist_ok = False ): \"\"\" Create a layout in the Geocube exist_ok: (optional, see warning): if already exists, do not raise an error. !!! WARNING: it does not mean that the layout already stored in the geocube is exactly the same !!! \"\"\" return self . _create_layout ( layout , exist_ok ) def layout ( self , name : str ) -> entities . Layout : \"\"\" Get layout by name \"\"\" return self . _layout ( name ) def list_layouts ( self , name_like : str = \"\" ) -> List [ entities . Layout ]: \"\"\" List available layouts by name name_like: pattern of the name. * and ? are supported to match all or any character. \"\"\" return self . _list_layouts ( name_like ) def find_container_layouts ( self , instance : Union [ str , entities . VariableInstance ], records : List [ Union [ str , entities . Record ]] = None , tags : Dict [ str , str ] = None , from_time : datetime = None , to_time : datetime = None , aoi : geometry . MultiPolygon = None ) -> Dict [ str , List [ str ]]: \"\"\" Find layouts of the containers covering an area or a list of records for a given instance \"\"\" return self . _find_container_layouts ( instance , records , tags , from_time , to_time , aoi ) def delete_layout ( self , name : str = \"\" ): \"\"\" Delete a layout from the Geocube \"\"\" return self . _delete_layout ( name ) def create_grid ( self , grid : entities . Grid ): \"\"\" Create a grid in the Geocube\"\"\" return self . _create_grid ( grid ) def list_grids ( self , name_like : str = \"\" ) -> List [ entities . Grid ]: \"\"\" List grids by name name_like: pattern of the name. * and ? are supported to match all or any character. \"\"\" return self . _list_grids ( name_like ) def delete_grid ( self , name : str = \"\" ): \"\"\" Delete a grid by its name \"\"\" return self . _delete_grid ( name ) @utils . catch_rpc_error def _version ( self ) -> str : return self . stub . Version ( version_pb2 . GetVersionRequest ()) . Version @utils . catch_rpc_error def _variable ( self , name : str , id_ : str , instance_id : str ) \\ -> Union [ entities . Variable , entities . VariableInstance ]: if id_ : req = variables_pb2 . GetVariableRequest ( id = id_ ) elif name : req = variables_pb2 . GetVariableRequest ( name = name ) elif instance_id : req = variables_pb2 . GetVariableRequest ( instance_id = instance_id ) else : raise ValueError ( \"One of id_, name or instance_id must be defined\" ) resp = self . stub . GetVariable ( req ) v = entities . Variable . from_pb ( self . stub , resp . variable ) for i in v . instances . values (): if i . id == instance_id : return v . instance ( i . name ) return v @utils . catch_rpc_error def _create_variable ( self , name : str , dformat : entities . DataFormat , bands : List [ str ], unit : str , description : str , palette : str , resampling_alg : entities . Resampling , exist_ok : bool ) \\ -> entities . Variable : req = variables_pb2 . CreateVariableRequest ( variable = variables_pb2 . Variable ( name = name , unit = unit , description = description , dformat = entities . DataFormat . from_user ( dformat ) . to_pb (), bands = bands , palette = palette , resampling_alg = typing . cast ( int , resampling_alg . value ) - 1 )) try : return self . variable ( id_ = self . stub . CreateVariable ( req ) . id ) except grpc . RpcError as e : e = utils . GeocubeError . from_rpc ( e ) if e . is_already_exists () and exist_ok : return self . variable ( name ) raise @utils . catch_rpc_error def _create_palette ( self , name : str , colors : List [ Tuple [ float , int , int , int , int ]], replace : bool ): colors = [ variables_pb2 . colorPoint ( value = v [ 0 ], r = v [ 1 ], g = v [ 2 ], b = v [ 3 ], a = v [ 4 ]) for v in colors ] req = variables_pb2 . CreatePaletteRequest ( palette = variables_pb2 . Palette ( name = name , colors = colors ), replace = replace ) self . stub . CreatePalette ( req ) @utils . catch_rpc_error def _list_variables ( self , name : str , limit : int , page : int ) -> List [ entities . Variable ]: req = variables_pb2 . ListVariablesRequest ( name = name , limit = limit , page = page ) return [ entities . Variable . from_pb ( self . stub , resp . variable ) for resp in self . stub . ListVariables ( req )] @utils . catch_rpc_error def _create_aoi ( self , aoi : Union [ geometry . Polygon , geometry . MultiPolygon ], exist_ok : bool ) -> str : try : req = records_pb2 . CreateAOIRequest ( aoi = entities . aoi_to_pb ( aoi )) return self . stub . CreateAOI ( req ) . id except grpc . RpcError as e : e = utils . GeocubeError . from_rpc ( e ) if e . is_already_exists () and exist_ok : return e . details [ e . details . rindex ( ' ' ) + 1 :] raise @utils . catch_rpc_error def _create_records ( self , aoi_ids : List [ str ], names : List [ str ], tags : List [ Dict [ str , str ]], dates : List [ datetime ]) -> List [ str ]: if len ( names ) != len ( aoi_ids ) or len ( names ) != len ( dates ) or len ( names ) != len ( tags ): raise ValueError ( \"All fields must have the same length\" ) records = [] for i in range ( len ( names )): record = records_pb2 . NewRecord ( aoi_id = aoi_ids [ i ], name = names [ i ], tags = tags [ i ]) record . time . FromDatetime ( dates [ i ]) records . append ( record ) req = records_pb2 . CreateRecordsRequest ( records = records ) return self . stub . CreateRecords ( req ) . ids @utils . catch_rpc_error def _get_records ( self , ids : List [ str ]) -> List [ entities . Record ]: req = records_pb2 . GetRecordsRequest ( ids = ids ) return [ entities . Record . from_pb ( resp . record ) for resp in self . stub . GetRecords ( req )] @utils . catch_rpc_error def _list_records ( self , name : str , tags : Dict [ str , str ], from_time : datetime , to_time : datetime , aoi : geometry . MultiPolygon , limit : int , page : int , with_aoi : bool ) -> List [ entities . Record ]: req = records_pb2 . ListRecordsRequest ( name = name , tags = tags , aoi = entities . aoi_to_pb ( aoi ), limit = limit , page = page , with_aoi = with_aoi ) if from_time is not None : req . from_time . FromDatetime ( from_time ) if to_time is not None : req . to_time . FromDatetime ( to_time ) records = [ entities . Record . from_pb ( resp . record ) for resp in self . stub . ListRecords ( req )] if limit != 0 and len ( records ) == limit : warnings . warn ( \"Maximum number of records reached. Call list_records(..., page=) or \" \"list_records(..., limit=) to get more records.\" ) return records @utils . catch_rpc_error def _load_aoi ( self , aoi_id : Union [ str , entities . Record ]) -> geometry . MultiPolygon : record = None if isinstance ( aoi_id , entities . Record ): record = aoi_id aoi_id = record . aoi_id resp = self . stub . GetAOI ( records_pb2 . GetAOIRequest ( id = aoi_id )) aoi = entities . aoi_from_pb ( resp . aoi ) if record : record . aoi = aoi return aoi @utils . catch_rpc_error def _add_records_tags ( self , records : List [ Union [ str , entities . Record ]], tags : Dict [ str , str ]) -> int : req = records_pb2 . AddRecordsTagsRequest ( ids = entities . get_ids ( records ), tags = tags ) return self . stub . AddRecordsTags ( req ) . nb @utils . catch_rpc_error def _remove_records_tags ( self , records : List [ Union [ str , entities . Record ]], tag_keys : List [ str ]) -> int : req = records_pb2 . RemoveRecordsTagsRequest ( ids = entities . get_ids ( records ), tagsKey = tag_keys ) return self . stub . RemoveRecordsTags ( req ) . nb @utils . catch_rpc_error def _delete_records ( self , records : List [ Union [ str , entities . Record ]], no_fail : bool ): req = records_pb2 . DeleteRecordsRequest ( ids = entities . get_ids ( records ), no_fail = no_fail ) self . stub . DeleteRecords ( req ) @utils . catch_rpc_error def _containers ( self , uris : Union [ str , List [ str ]]) -> Union [ entities . Container , List [ entities . Container ]]: singleton = isinstance ( uris , str ) if singleton : uris = [ uris ] req = operations_pb2 . GetContainersRequest ( uris = uris ) res = self . stub . GetContainers ( req ) containers = [ entities . Container . from_pb ( pb_container ) for pb_container in res . containers ] return containers [ 0 ] if singleton else containers @utils . catch_rpc_error def _index ( self , containers : List [ entities . Container ]): pb_containers = [] for container in containers : datasets = [ dataset . to_pb () for dataset in container . datasets ] pb_containers . append ( operations_pb2 . Container ( uri = container . uri , managed = container . managed , datasets = datasets )) for c in pb_containers : req = operations_pb2 . IndexDatasetsRequest ( container = c ) self . stub . IndexDatasets ( req ) @utils . catch_rpc_error def _index_dataset ( self , uri : str , record : Union [ str , entities . Record , Tuple [ str , Dict [ str , str ], datetime ]], instance : entities . VariableInstance , dformat : entities . DataFormat , bands : List [ int ], min_out : float , max_out : float , exponent : float , managed : bool ): ds_dtype = \"u1\" if isinstance ( record , tuple ) or dformat is None : try : with rasterio . open ( uri ) as ds : tile = entities . Tile . from_geotransform ( ds . transform , ds . crs , ds . shape [:: - 1 ]) ds_dtype = ds . dtypes [ 0 ] except Exception as e : raise ValueError ( f 'if \"record\" is a tuple or \"bands\" or \"dformat\" is not defined, geocube-client tries' f ' to deduce some information reading the file { uri } , but it encountered' f ' the following error : { e } .' ) if isinstance ( record , tuple ): aoi_id = self . create_aoi ( tile . geometry ( 4326 ), exist_ok = True ) r_name , r_tags , r_date = record record = self . create_record ( aoi_id , name = r_name , tags = r_tags , date = r_date , exist_ok = True ) if dformat is None : dformat = entities . DataFormat . from_user ( ds_dtype ) cs = [ entities . Container ( uri , managed = managed , datasets = [ entities . Dataset ( record , instance , bands = bands , dformat = entities . DataFormat . from_user ( dformat ), min_out = min_out , max_out = max_out , exponent = exponent )])] return self . index ( cs ) @utils . catch_rpc_error def _get_cube_metadata ( self , params : entities . CubeParams ) -> entities . CubeMetadata : cube_it = self . _get_cube_it ( params , headers_only = True ) return cube_it . metadata () @utils . catch_rpc_error def _get_cube_it ( self , params : entities . CubeParams , * , resampling_alg : entities . Resampling = entities . Resampling . undefined , headers_only : bool = False , compression : int = 0 , file_format = FileFormatRaw , file_pattern : str = None ) -> entities . CubeIterator : if self . downloader is not None and not headers_only : metadata = self . _get_cube_it ( params , headers_only = True ) . metadata () if resampling_alg != entities . Resampling . undefined : metadata . resampling_alg = resampling_alg return self . downloader . get_cube_it ( metadata , file_format = file_format , file_pattern = file_pattern , predownload = self . downloader . always_predownload ) common = { \"instances_id\" : [ params . instance ], \"crs\" : params . crs , \"pix_to_crs\" : layouts_pb2 . GeoTransform ( a = params . transform . c , b = params . transform . a , c = params . transform . b , d = params . transform . f , e = params . transform . d , f = params . transform . e ), \"size\" : layouts_pb2 . Size ( width = params . shape [ 0 ], height = params . shape [ 1 ]), \"compression_level\" : compression , \"headers_only\" : headers_only , \"format\" : file_format , \"resampling_alg\" : typing . cast ( int , resampling_alg . value ) - 1 } if params . records is not None : req = catalog_pb2 . GetCubeRequest ( ** common , grouped_records = records_pb2 . GroupedRecordIdsList ( records = [ records_pb2 . GroupedRecordIds ( ids = rs ) for rs in params . records ] )) else : from_time_pb = utils . pb_null_timestamp () if params . from_time is not None : from_time_pb . FromDatetime ( params . from_time ) to_time_pb = utils . pb_null_timestamp () if params . to_time is not None : to_time_pb . FromDatetime ( params . to_time ) req = catalog_pb2 . GetCubeRequest ( ** common , filters = records_pb2 . RecordFilters ( tags = params . tags , from_time = from_time_pb , to_time = to_time_pb )) return entities . CubeIterator ( self . stub . GetCube ( req ), file_format , file_pattern ) @utils . catch_rpc_error def _tile_aoi ( self , aoi : Union [ geometry . MultiPolygon , geometry . Polygon ], layout_name : Optional [ str ], layout : Optional [ entities . Layout ], resolution : Optional [ float ], crs : Optional [ str ], shape : Optional [ Tuple [ int , int ]]) -> List [ entities . Tile ]: \"\"\" TODO: use Grid or GridName \"\"\" aoi = entities . aoi_to_pb ( aoi ) if layout_name is not None : req = layouts_pb2 . TileAOIRequest ( aoi = aoi , layout_name = layout_name ) else : if layout is None : layout = entities . Layout . regular ( \"\" , crs , shape , resolution ) req = layouts_pb2 . TileAOIRequest ( aoi = aoi , layout = layout . to_pb ()) return [ entities . Tile . from_pb ( tile ) for resp in self . stub . TileAOI ( req ) for tile in resp . tiles ] @utils . catch_rpc_error def _get_xyz_tile ( self , instance : Union [ str , entities . VariableInstance ], records : List [ Union [ str , entities . Record ]], x : int , y : int , z : int , file : str ): req = catalog_pb2 . GetTileRequest ( records = records_pb2 . GroupedRecordIds ( ids = entities . get_ids ( records )), instance_id = entities . get_id ( instance ), x = x , y = y , z = z ) resp = self . stub . GetXYZTile ( req ) f = open ( file , \"wb\" ) f . write ( resp . image . data ) f . close () @utils . catch_rpc_error def _create_layout ( self , layout : entities . Layout , exist_ok ): try : self . stub . CreateLayout ( layouts_pb2 . CreateLayoutRequest ( layout = layout . to_pb ())) except grpc . RpcError as e : e = utils . GeocubeError . from_rpc ( e ) if not e . is_already_exists () or not exist_ok : raise @utils . catch_rpc_error def _layout ( self , name : str ) -> entities . Layout : res = self . stub . ListLayouts ( layouts_pb2 . ListLayoutsRequest ( name_like = name )) if len ( res . layouts ) == 0 : raise utils . GeocubeError ( \"layout\" , grpc . StatusCode . ALREADY_EXISTS . name , \"with name: \" + name ) return entities . Layout . from_pb ( res . layouts [ 0 ]) @utils . catch_rpc_error def _list_layouts ( self , name_like : str ) -> List [ entities . Layout ]: res = self . stub . ListLayouts ( layouts_pb2 . ListLayoutsRequest ( name_like = name_like )) return [ entities . Layout . from_pb ( layout ) for layout in res . layouts ] @utils . catch_rpc_error def _find_container_layouts ( self , instance : Union [ str , entities . VariableInstance ], records : List [ Union [ str , entities . Record ]], tags : Dict [ str , str ], from_time : datetime , to_time : datetime , aoi : geometry . MultiPolygon ) -> Dict [ str , List [ str ]]: if records is not None : req = layouts_pb2 . FindContainerLayoutsRequest ( instance_id = entities . get_id ( instance ), records = records_pb2 . RecordIdList ( ids = entities . get_ids ( records )) ) else : from_time_pb = utils . pb_null_timestamp () if from_time is not None : from_time_pb . FromDatetime ( from_time ) to_time_pb = utils . pb_null_timestamp () if to_time is not None : to_time_pb . FromDatetime ( to_time ) req = catalog_pb2 . FindContainerLayoutsRequest ( instance_id = entities . get_id ( instance ), filters = records_pb2 . RecordFiltersWithAOI ( aoi = aoi , tags = tags , from_time = from_time_pb , to_time = to_time_pb )) return { resp . layout_name : resp . container_uris for resp in self . stub . FindContainerLayouts ( req )} @utils . catch_rpc_error def _delete_layout ( self , name : str ): self . stub . DeleteLayout ( layouts_pb2 . DeleteLayoutRequest ( name = name )) @utils . catch_rpc_error def _create_grid ( self , grid : entities . Grid ): max_cells = min ( len ( grid . cells ), 10000000 ) while True : try : req = [ layouts_pb2 . CreateGridRequest ( grid = grid . to_pb ( max_cells * i , max_cells * ( i + 1 ))) for i in range (( len ( grid . cells ) - 1 ) // max_cells + 1 )] return self . stub . CreateGrid ( iter ( req )) except grpc . RpcError as e : e = utils . GeocubeError . from_rpc ( e ) if e . codename != \"RESOURCE_EXHAUSTED\" : raise r = parse . search ( \"( {volume:d} vs. {max:d} )\" , e . details ) max_cells //= max ( r [ \"volume\" ] // r [ \"max\" ], 2 ) @utils . catch_rpc_error def _list_grids ( self , name_like : str ) -> List [ entities . Grid ]: res = self . stub . ListGrids ( layouts_pb2 . ListGridsRequest ( name_like = name_like )) return [ entities . Grid . from_pb ( grid ) for grid in res . grids ] @utils . catch_rpc_error def _delete_grid ( self , name : str ): self . stub . DeleteGrid ( layouts_pb2 . DeleteGridRequest ( name = name ))","title":"Client"},{"location":"user-guide/client/client-reference/#geocube.Client.__init__","text":"Initialise the connexion to the Geocube Server Parameters: uri ( str ) \u2013 of the Geocube Server secure ( bool , default: False ) \u2013 True to use a TLS Connexion api_key ( str , default: '' ) \u2013 (optional) API Key if Geocube Server is secured using a bearer authentication verbose ( bool , default: True ) \u2013 set the default verbose mode Source code in geocube/client.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 def __init__ ( self , uri : str , secure : bool = False , api_key : str = \"\" , verbose : bool = True ): \"\"\" Initialise the connexion to the Geocube Server Args: uri: of the Geocube Server secure: True to use a TLS Connexion api_key: (optional) API Key if Geocube Server is secured using a bearer authentication verbose: set the default verbose mode \"\"\" assert uri is not None and uri != \"\" , \"geocube.Client: Cannot connect: uri is not defined\" self . pid = os . getpid () if secure : credentials = grpc . ssl_channel_credentials () if api_key != \"\" : token_credentials = grpc . access_token_call_credentials ( api_key ) credentials = grpc . composite_channel_credentials ( credentials , token_credentials ) self . _channel = grpc . secure_channel ( uri , credentials ) else : self . _channel = grpc . insecure_channel ( uri ) self . stub = Stub ( geocube_grpc . GeocubeStub ( self . _channel )) self . verbose = verbose if verbose : print ( \"Connected to Geocube v\" + self . version ()) self . downloader = None","title":"__init__"},{"location":"user-guide/client/client-reference/#geocube.Client.add_records_tags","text":"Add or update tags to a list of records Parameters: records ( List [ Union [ str , Record ]] ) \u2013 List of records to be updated tags ( Dict [ str , str ] ) \u2013 List of new tags or tags to be updated Returns: int \u2013 the number of updated records Source code in geocube/client.py 230 231 232 233 234 235 236 237 238 239 240 def add_records_tags ( self , records : List [ Union [ str , entities . Record ]], tags : Dict [ str , str ]) -> int : \"\"\" Add or update tags to a list of records Args: records: List of records to be updated tags: List of new tags or tags to be updated Returns: the number of updated records \"\"\" return self . _add_records_tags ( records , tags )","title":"add_records_tags"},{"location":"user-guide/client/client-reference/#geocube.Client.containers","text":"Get containers and their datasets by uris Parameters: uris ( Union [ str , List [ str ]] ) \u2013 uri or list of uris Source code in geocube/client.py 264 265 266 267 268 269 270 271 def containers ( self , uris : Union [ str , List [ str ]]) -> Union [ entities . Container , List [ entities . Container ]]: \"\"\" Get containers and their datasets by uris Args: uris: uri or list of uris \"\"\" return self . _containers ( uris )","title":"containers"},{"location":"user-guide/client/client-reference/#geocube.Client.create_aoi","text":"Create a new AOI. Raise an error if an AOI with the same coordinates already exists. The id of the AOI can be retrieved from the details of the error. Parameters: aoi ( Union [ Polygon , MultiPolygon ] ) \u2013 in geographic coordinates exist_ok ( bool , default: False ) \u2013 (optional): if already exists, do not raise an error and return the aoi_id Returns: str \u2013 the id of the AOI Source code in geocube/client.py 129 130 131 132 133 134 135 136 137 138 139 140 141 def create_aoi ( self , aoi : Union [ geometry . Polygon , geometry . MultiPolygon ], exist_ok : bool = False ) -> str : \"\"\" Create a new AOI. Raise an error if an AOI with the same coordinates already exists. The id of the AOI can be retrieved from the details of the error. Args: aoi: in geographic coordinates exist_ok: (optional): if already exists, do not raise an error and return the aoi_id Returns: the id of the AOI \"\"\" return self . _create_aoi ( aoi , exist_ok )","title":"create_aoi"},{"location":"user-guide/client/client-reference/#geocube.Client.create_grid","text":"Create a grid in the Geocube Source code in geocube/client.py 459 460 461 def create_grid ( self , grid : entities . Grid ): \"\"\" Create a grid in the Geocube\"\"\" return self . _create_grid ( grid )","title":"create_grid"},{"location":"user-guide/client/client-reference/#geocube.Client.create_layout","text":"Create a layout in the Geocube exist_ok: (optional, see warning): if already exists, do not raise an error. !!! WARNING: it does not mean that the layout already stored in the geocube is exactly the same !!! Source code in geocube/client.py 425 426 427 428 429 430 def create_layout ( self , layout : entities . Layout , exist_ok = False ): \"\"\" Create a layout in the Geocube exist_ok: (optional, see warning): if already exists, do not raise an error. !!! WARNING: it does not mean that the layout already stored in the geocube is exactly the same !!! \"\"\" return self . _create_layout ( layout , exist_ok )","title":"create_layout"},{"location":"user-guide/client/client-reference/#geocube.Client.create_palette","text":"Create a new palette from [0, 1] to RGBA, providing a list of index from 0 to 1. The intermediate values are linearly interpolated. Parameters: name ( str ) \u2013 Name of the palette colors ( List [ Tuple [ float , int , int , int , int ]] ) \u2013 a list of tuple[index, R, G, B, A] mapping index to the corresponding RGBA value replace ( bool , default: False ) \u2013 if a palette already exists with the same name, replace it else raise an error. Source code in geocube/client.py 102 103 104 105 106 107 108 109 110 111 112 def create_palette ( self , name : str , colors : List [ Tuple [ float , int , int , int , int ]], replace : bool = False ): \"\"\" Create a new palette from [0, 1] to RGBA, providing a list of index from 0 to 1. The intermediate values are linearly interpolated. Args: name: Name of the palette colors: a list of tuple[index, R, G, B, A] mapping index to the corresponding RGBA value replace: if a palette already exists with the same name, replace it else raise an error. \"\"\" return self . _create_palette ( name , colors , replace )","title":"create_palette"},{"location":"user-guide/client/client-reference/#geocube.Client.create_record","text":"Create a new record. A record is uniquely identified with the tuple (name, tags, date) Raise an error if a record with the same Name, Tags and Date already exists. Parameters: aoi_id ( str ) \u2013 uuid4 of the AOI. name ( str ) \u2013 of the records. tags ( Dict [ str , str ] ) \u2013 user-defined tags associated to the record. date ( datetime ) \u2013 date of the data referenced by the record. exist_ok ( bool , default: False ) \u2013 (optional, see warning): if already exists, do not raise an error !!! WARNING: it does not mean that the record in the geocube is the same: its aoi may be different !!! Returns: str \u2013 the ID of the record Source code in geocube/client.py 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 def create_record ( self , aoi_id : str , name : str , tags : Dict [ str , str ], date : datetime , exist_ok : bool = False ) \\ -> str : \"\"\" Create a new record. A record is uniquely identified with the tuple (name, tags, date) Raise an error if a record with the same Name, Tags and Date already exists. Args: aoi_id: uuid4 of the AOI. name: of the records. tags: user-defined tags associated to the record. date: date of the data referenced by the record. exist_ok: (optional, see warning): if already exists, do not raise an error !!! WARNING: it does not mean that the record in the geocube is the same: its aoi may be different !!! Returns: the ID of the record \"\"\" try : return self . create_records ([ aoi_id ], [ name ], [ tags ], [ date ])[ 0 ] except utils . GeocubeError as e : if e . is_already_exists () and exist_ok : record = self . list_records ( name , tags = tags , from_time = date , to_time = date )[ 0 ] if record . aoi_id != aoi_id : warnings . warn ( \"Record already exists in the Geocube but the aoi_id is different\" ) return record . id raise","title":"create_record"},{"location":"user-guide/client/client-reference/#geocube.Client.create_records","text":"Create a list of records. All inputs must have the same length. (see create_record for the description of the parameters) Source code in geocube/client.py 170 171 172 173 174 175 176 def create_records ( self , aoi_ids : List [ str ], names : List [ str ], tags : List [ Dict [ str , str ]], dates : List [ datetime ]) -> List [ str ]: \"\"\" Create a list of records. All inputs must have the same length. (see create_record for the description of the parameters) \"\"\" return self . _create_records ( aoi_ids , names , tags , dates )","title":"create_records"},{"location":"user-guide/client/client-reference/#geocube.Client.create_variable","text":"Create a single Variable Parameters: name ( str ) \u2013 Name of the variable dformat ( DataFormat ) \u2013 data format of the variable (min and max are the theoretical extrema) bands ( List [ str ] ) \u2013 Name of the bands unit ( str , default: '' ) \u2013 of the data (for user information only) description ( str , default: '' ) \u2013 of the data (for user information only) palette ( str , default: '' ) \u2013 for rendering in png (TileServer). Must be created using create_palette. resampling_alg ( Resampling , default: bilinear ) \u2013 when reprojection is needed (see entities.Resampling) exist_ok ( bool , default: False ) \u2013 (optional, see warning): if already exists, do not raise an error. !!! WARNING: it does not mean that the variable already stored in the geocube is exactly the same !!! Returns: Variable \u2013 the variable Source code in geocube/client.py 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 def create_variable ( self , name : str , dformat : entities . DataFormat , bands : List [ str ], unit : str = \"\" , description : str = \"\" , palette : str = \"\" , resampling_alg : entities . Resampling = entities . Resampling . bilinear , exist_ok : bool = False ) \\ -> entities . Variable : \"\"\" Create a single Variable Args: name: Name of the variable dformat: data format of the variable (min and max are the theoretical extrema) bands: Name of the bands unit: of the data (for user information only) description: of the data (for user information only) palette: for rendering in png (TileServer). Must be created using create_palette. resampling_alg: when reprojection is needed (see entities.Resampling) exist_ok: (optional, see warning): if already exists, do not raise an error. !!! WARNING: it does not mean that the variable already stored in the geocube is exactly the same !!! Returns: the variable \"\"\" return self . _create_variable ( name , dformat , bands , unit , description , palette , resampling_alg , exist_ok )","title":"create_variable"},{"location":"user-guide/client/client-reference/#geocube.Client.delete_grid","text":"Delete a grid by its name Source code in geocube/client.py 470 471 472 def delete_grid ( self , name : str = \"\" ): \"\"\" Delete a grid by its name \"\"\" return self . _delete_grid ( name )","title":"delete_grid"},{"location":"user-guide/client/client-reference/#geocube.Client.delete_layout","text":"Delete a layout from the Geocube Source code in geocube/client.py 455 456 457 def delete_layout ( self , name : str = \"\" ): \"\"\" Delete a layout from the Geocube \"\"\" return self . _delete_layout ( name )","title":"delete_layout"},{"location":"user-guide/client/client-reference/#geocube.Client.delete_records","text":"Delete records iif no dataset are indexed to them. Parameters: records ( List [ Union [ str , Record ]] ) \u2013 List of records to be deleted no_fail ( bool , default: False ) \u2013 if true, do not fail if some records still have datasets that refer to them, and delete the others Source code in geocube/client.py 254 255 256 257 258 259 260 261 262 def delete_records ( self , records : List [ Union [ str , entities . Record ]], no_fail : bool = False ): \"\"\" Delete records iif no dataset are indexed to them. Args: records: List of records to be deleted no_fail: if true, do not fail if some records still have datasets that refer to them, and delete the others \"\"\" return self . _delete_records ( records , no_fail )","title":"delete_records"},{"location":"user-guide/client/client-reference/#geocube.Client.find_container_layouts","text":"Find layouts of the containers covering an area or a list of records for a given instance Source code in geocube/client.py 445 446 447 448 449 450 451 452 453 def find_container_layouts ( self , instance : Union [ str , entities . VariableInstance ], records : List [ Union [ str , entities . Record ]] = None , tags : Dict [ str , str ] = None , from_time : datetime = None , to_time : datetime = None , aoi : geometry . MultiPolygon = None ) -> Dict [ str , List [ str ]]: \"\"\" Find layouts of the containers covering an area or a list of records for a given instance \"\"\" return self . _find_container_layouts ( instance , records , tags , from_time , to_time , aoi )","title":"find_container_layouts"},{"location":"user-guide/client/client-reference/#geocube.Client.get_cube","text":"Get a cube given a CubeParameters Parameters: params ( CubeParams ) \u2013 CubeParams (see entities.CubeParams) resampling_alg ( Resampling , default: undefined ) \u2013 if defined, overwrite the variable.Resampling used for reprojection. headers_only ( bool , default: False ) \u2013 Only returns the header of each image (gives an overview of the query) compression ( int , default: 0 ) \u2013 define a level of compression to speed up the transfer. (0: no compression, 1 fastest to 9 best, -2: huffman-only) The data is compressed by the server and decompressed by the Client. Compression=0 or -2 is advised if the bandwidth is not limited verbose ( bool , default: None ) \u2013 display information during the transfer (if None, use the default verbose mode) Returns: Tuple [ List [ array ], List [ GroupedRecords ]] \u2013 list of images (np.ndarray) and the list of corresponding records (several records can be returned for each image when they are grouped together, by date or something else. See entities.Record.group_by) Source code in geocube/client.py 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 def get_cube ( self , params : entities . CubeParams , * , resampling_alg : entities . Resampling = entities . Resampling . undefined , headers_only : bool = False , compression : int = 0 , verbose : bool = None ) \\ -> Tuple [ List [ np . array ], List [ entities . GroupedRecords ]]: \"\"\" Get a cube given a CubeParameters Args: params: CubeParams (see entities.CubeParams) resampling_alg: if defined, overwrite the variable.Resampling used for reprojection. headers_only: Only returns the header of each image (gives an overview of the query) compression: define a level of compression to speed up the transfer. (0: no compression, 1 fastest to 9 best, -2: huffman-only) The data is compressed by the server and decompressed by the Client. Compression=0 or -2 is advised if the bandwidth is not limited verbose: display information during the transfer (if None, use the default verbose mode) Returns: list of images (np.ndarray) and the list of corresponding records (several records can be returned for each image when they are grouped together, by date or something else. See entities.Record.group_by) \"\"\" cube = self . _get_cube_it ( params , resampling_alg = resampling_alg , headers_only = headers_only , compression = compression ) images , grouped_records = [], [] verbose = self . verbose if verbose is None else verbose if verbose : print ( \"GetCube returns {} images from {} datasets\" . format ( cube . count , cube . nb_datasets )) for image , metadata , err in cube : if err is not None : if err == cubeiterator . NOT_FOUND_ERROR : if verbose : print ( err ) continue raise ValueError ( err ) if verbose : min_date = metadata . min_date . strftime ( \"%Y-%m- %d _%H:%M:%S\" ) max_date = metadata . max_date . strftime ( \"%Y-%m- %d _%H:%M:%S\" ) print ( \"Image {} received ( {}{} kb) RecordTime: {} RecordName: {} Shape: {} \" . format ( cube . index + 1 , '<' if headers_only else '' , metadata . bytes // 1024 , min_date if min_date == max_date else min_date + \" to \" + max_date , metadata . grouped_records [ 0 ] . name , image . shape )) images . append ( image ) grouped_records . append ( metadata . grouped_records ) return images , grouped_records","title":"get_cube"},{"location":"user-guide/client/client-reference/#geocube.Client.get_cube_it","text":"Returns a cube iterator over the requested images Parameters: params ( CubeParams ) \u2013 CubeParams (see entities.CubeParams) resampling_alg ( Resampling , default: undefined ) \u2013 if defined, overwrite the variable.Resampling used for reprojection. headers_only \u2013 returns only the header of the dataset (use this option to control the output of get_cube) compression \u2013 define a level of compression to speed up the transfer (0: no compression, 1 fastest to 9 best, -2: huffman-only) The data is compressed by the server and decompressed by the Client. Compression=0 or -2 is advised if the bandwidth is not limited file_format \u2013 (optional) currently supported geocube.FileFormatRaw & geocube.FileFormatGTiff file_pattern \u2013 (optional) iif file_format != Raw, pattern of the file name. {#} will be replaced by the number of image, {date} and {id} by the value of the record Returns: CubeIterator \u2013 an iterator yielding an image, its associated records, an error (or None) and the size of the image client = Client('127.0.0.1:8080', False) cube_params = entities.CubeParams.from_records(\"+proj=utm +zone=31\", ... entities.geo_transform(366162, 4833123, 30), (512, 512), ... client.variable(name=\"test/rgb\").instance(\"master\"), records=client.list_records('france')) affine.Affine.translation(366162, 4833123)*affine.Affine.scale(30, -30)) cube_it = client.get_cube_it(cube_params) from matplotlib import pyplot as plt for image, , , err in cube_it: ... if err != cubeiterator.NOT_FOUND_ERROR: ... raise ValueError(err) ... if not err: ... plt.figure(cube_it.index+1) ... plt.imshow(image) Source code in geocube/client.py 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 def get_cube_it ( self , params : entities . CubeParams , * , resampling_alg : entities . Resampling = entities . Resampling . undefined , headers_only : bool = False , compression : int = 0 , file_format = FileFormatRaw , file_pattern : str = None ) -> entities . CubeIterator : \"\"\" Returns a cube iterator over the requested images Args: params: CubeParams (see entities.CubeParams) resampling_alg: if defined, overwrite the variable.Resampling used for reprojection. headers_only : returns only the header of the dataset (use this option to control the output of get_cube) compression : define a level of compression to speed up the transfer (0: no compression, 1 fastest to 9 best, -2: huffman-only) The data is compressed by the server and decompressed by the Client. Compression=0 or -2 is advised if the bandwidth is not limited file_format : (optional) currently supported geocube.FileFormatRaw & geocube.FileFormatGTiff file_pattern : (optional) iif file_format != Raw, pattern of the file name. {#} will be replaced by the number of image, {date} and {id} by the value of the record Returns: an iterator yielding an image, its associated records, an error (or None) and the size of the image >>> client = Client('127.0.0.1:8080', False) >>> cube_params = entities.CubeParams.from_records(\"+proj=utm +zone=31\", ... entities.geo_transform(366162, 4833123, 30), (512, 512), ... client.variable(name=\"test/rgb\").instance(\"master\"), records=client.list_records('france')) affine.Affine.translation(366162, 4833123)*affine.Affine.scale(30, -30)) >>> cube_it = client.get_cube_it(cube_params) >>> from matplotlib import pyplot as plt >>> for image, _, _, err in cube_it: ... if err != cubeiterator.NOT_FOUND_ERROR: ... raise ValueError(err) ... if not err: ... plt.figure(cube_it.index+1) ... plt.imshow(image) \"\"\" return self . _get_cube_it ( params , resampling_alg = resampling_alg , headers_only = headers_only , compression = compression , file_format = file_format , file_pattern = file_pattern )","title":"get_cube_it"},{"location":"user-guide/client/client-reference/#geocube.Client.get_record","text":"Deprecated: use record() instead Source code in geocube/client.py 178 179 180 def get_record ( self , _id : str ) -> entities . Record : \"\"\" Deprecated: use record() instead \"\"\" return self . record ( _id )","title":"get_record"},{"location":"user-guide/client/client-reference/#geocube.Client.get_records","text":"Get a list of records. Source code in geocube/client.py 188 189 190 191 192 def get_records ( self , ids : List [ str ]) -> List [ entities . Record ]: \"\"\" Get a list of records. \"\"\" return self . _get_records ( ids )","title":"get_records"},{"location":"user-guide/client/client-reference/#geocube.Client.get_xyz_tile","text":"Create a PNG file covering the (X,Y,Z) web-mercator tile, using the palette of the variable. Parameters: instance ( Union [ str , VariableInstance ] ) \u2013 instance of the variable records ( List [ Union [ str , Record ]] ) \u2013 list of records x ( int ) \u2013 coordinate of the web-mercator XYZ tile y ( int ) \u2013 coordinate of the web-mercator XYZ tile z ( int ) \u2013 coordinate of the web-mercator XYZ tile file ( str ) \u2013 output PNG file Source code in geocube/client.py 410 411 412 413 414 415 416 417 418 419 420 421 422 423 def get_xyz_tile ( self , instance : Union [ str , entities . VariableInstance ], records : List [ Union [ str , entities . Record ]], x : int , y : int , z : int , file : str ): \"\"\" Create a PNG file covering the (X,Y,Z) web-mercator tile, using the palette of the variable. Args: instance: instance of the variable records: list of records x: coordinate of the web-mercator XYZ tile y: coordinate of the web-mercator XYZ tile z: coordinate of the web-mercator XYZ tile file: output PNG file \"\"\" return self . _get_xyz_tile ( instance , records , x , y , z , file )","title":"get_xyz_tile"},{"location":"user-guide/client/client-reference/#geocube.Client.index","text":"Index a new container. Parameters: containers ( List [ Container ] ) \u2013 List of container to index. Source code in geocube/client.py 273 274 275 276 277 278 279 280 def index ( self , containers : List [ entities . Container ]): \"\"\" Index a new container. Args: containers: List of container to index. \"\"\" return self . _index ( containers )","title":"index"},{"location":"user-guide/client/client-reference/#geocube.Client.index_dataset","text":"Index the given \"bands\" of the dataset located at \"uri\", referenced by a record and an instance. Parameters: uri ( str ) \u2013 of the file to index record ( Union [ str , Record , Tuple [ str , Dict [ str , str ], datetime ]] ) \u2013 id of the record describing the data-take or a tuple (name, metadata, datetime) to create the record on the fly instance ( VariableInstance ) \u2013 describing the data dformat ( DataFormat ) \u2013 describing the internal format (see entities.DataFormat.from_user()) bands ( List [ int ] , default: None ) \u2013 subset of bands' file (start at 1) that maps to variable.bands (by default, all the bands) min_out ( float , default: None ) \u2013 (optional, default: instance.dformat.min_value, instance.dformat.dtype) maps dformat.min_value max_out ( float , default: None ) \u2013 (optional, default: instance.dformat.max_value, instance.dformat.dtype) maps dformat.max_value exponent ( float , default: 1 ) \u2013 (optional, default: 1) non-linear scaling between dformat.min_max_value to min_max_out. managed ( bool , default: False ) \u2013 if True, the geocube takes the ownership of the file, removing it if the dataset is removed Source code in geocube/client.py 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 def index_dataset ( self , uri : str , record : Union [ str , entities . Record , Tuple [ str , Dict [ str , str ], datetime ]], instance : entities . VariableInstance , dformat : entities . DataFormat , bands : List [ int ] = None , min_out : float = None , max_out : float = None , exponent : float = 1 , managed : bool = False ): \"\"\" Index the given \"bands\" of the dataset located at \"uri\", referenced by a record and an instance. Args: uri: of the file to index record: id of the record describing the data-take or a tuple (name, metadata, datetime) to create the record on the fly instance: describing the data dformat: describing the internal format (see entities.DataFormat.from_user()) bands: subset of bands' file (start at 1) that maps to `variable.bands` (by default, all the bands) min_out: (optional, default: instance.dformat.min_value, instance.dformat.dtype) maps dformat.min_value max_out: (optional, default: instance.dformat.max_value, instance.dformat.dtype) maps dformat.max_value exponent: (optional, default: 1) non-linear scaling between dformat.min_max_value to min_max_out. managed: if True, the geocube takes the ownership of the file, removing it if the dataset is removed \"\"\" return self . _index_dataset ( uri , record , instance , dformat , bands , min_out , max_out , exponent , managed )","title":"index_dataset"},{"location":"user-guide/client/client-reference/#geocube.Client.layout","text":"Get layout by name Source code in geocube/client.py 432 433 434 435 436 def layout ( self , name : str ) -> entities . Layout : \"\"\" Get layout by name \"\"\" return self . _layout ( name )","title":"layout"},{"location":"user-guide/client/client-reference/#geocube.Client.list_grids","text":"List grids by name name_like: pattern of the name. * and ? are supported to match all or any character. Source code in geocube/client.py 463 464 465 466 467 468 def list_grids ( self , name_like : str = \"\" ) -> List [ entities . Grid ]: \"\"\" List grids by name name_like: pattern of the name. * and ? are supported to match all or any character. \"\"\" return self . _list_grids ( name_like )","title":"list_grids"},{"location":"user-guide/client/client-reference/#geocube.Client.list_layouts","text":"List available layouts by name name_like: pattern of the name. * and ? are supported to match all or any character. Source code in geocube/client.py 438 439 440 441 442 443 def list_layouts ( self , name_like : str = \"\" ) -> List [ entities . Layout ]: \"\"\" List available layouts by name name_like: pattern of the name. * and ? are supported to match all or any character. \"\"\" return self . _list_layouts ( name_like )","title":"list_layouts"},{"location":"user-guide/client/client-reference/#geocube.Client.list_records","text":"List records given filters Parameters: name ( str , default: '' ) \u2013 pattern of the name. * and ? are supported to match all or any character. (?i) can be added at the end to be insensitive to case tags ( Dict [ str , str ] , default: None ) \u2013 list of mandatory tags. Support the same pattern as name. from_time ( datetime , default: None ) \u2013 filter by date to_time ( datetime , default: None ) \u2013 filter by date aoi ( MultiPolygon , default: None ) \u2013 records that intersect the AOI in geographic coordinates limit ( int , default: 10000 ) \u2013 the number of records returned (0 to return all records) page ( int , default: 0 ) \u2013 start at 0 with_aoi ( bool , default: False ) \u2013 also returns the AOI of the record. Otherwise, only the ID of the aoi is returned. load_aoi(record) can be called to retrieve the AOI later. Returns: List [ Record ] \u2013 a list of records Source code in geocube/client.py 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 def list_records ( self , name : str = \"\" , tags : Dict [ str , str ] = None , from_time : datetime = None , to_time : datetime = None , aoi : geometry . MultiPolygon = None , limit : int = 10000 , page : int = 0 , with_aoi : bool = False ) -> List [ entities . Record ]: \"\"\" List records given filters Args: name: pattern of the name. * and ? are supported to match all or any character. (?i) can be added at the end to be insensitive to case tags: list of mandatory tags. Support the same pattern as name. from_time: filter by date to_time: filter by date aoi: records that intersect the AOI in geographic coordinates limit: the number of records returned (0 to return all records) page: start at 0 with_aoi: also returns the AOI of the record. Otherwise, only the ID of the aoi is returned. load_aoi(record) can be called to retrieve the AOI later. Returns: a list of records \"\"\" return self . _list_records ( name , tags , from_time , to_time , aoi , limit , page , with_aoi )","title":"list_records"},{"location":"user-guide/client/client-reference/#geocube.Client.list_variables","text":"List all the variables given a pattern Parameters: name ( str , default: '' ) \u2013 pattern of the name. * and ? are supported to match all or any character. (?i) can be added at the end to be insensitive to case limit ( int , default: 0 ) \u2013 limit the number of variables returned page ( int , default: 0 ) \u2013 number of the page (starting at 0). Returns: List [ Variable ] \u2013 a list of variable Source code in geocube/client.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 def list_variables ( self , name : str = \"\" , limit : int = 0 , page : int = 0 ) -> List [ entities . Variable ]: \"\"\" List all the variables given a pattern Args: name: pattern of the name. * and ? are supported to match all or any character. (?i) can be added at the end to be insensitive to case limit: limit the number of variables returned page: number of the page (starting at 0). Returns: a list of variable \"\"\" return self . _list_variables ( name , limit , page )","title":"list_variables"},{"location":"user-guide/client/client-reference/#geocube.Client.load_aoi","text":"Load the geometry of the AOI of the given record Parameters: aoi_id ( Union [ str , Record ] ) \u2013 uuid of the AOI or the record. If the record is provided, its geometry will be updated Returns: MultiPolygon \u2013 the geometry of the AOI Source code in geocube/client.py 218 219 220 221 222 223 224 225 226 227 228 def load_aoi ( self , aoi_id : Union [ str , entities . Record ]) -> geometry . MultiPolygon : \"\"\" Load the geometry of the AOI of the given record Args: aoi_id: uuid of the AOI or the record. If the record is provided, its geometry will be updated Returns: the geometry of the AOI \"\"\" return self . _load_aoi ( aoi_id )","title":"load_aoi"},{"location":"user-guide/client/client-reference/#geocube.Client.record","text":"Get a record by id Source code in geocube/client.py 182 183 184 185 186 def record ( self , _id : str ) -> entities . Record : \"\"\" Get a record by id \"\"\" r = self . get_records ([ _id ]) assert len ( r ) > 0 , utils . GeocubeError ( \"get_record\" , grpc . StatusCode . NOT_FOUND . name , \"record with id \" + _id ) return r [ 0 ]","title":"record"},{"location":"user-guide/client/client-reference/#geocube.Client.remove_records_tags","text":"Remove tags keys from a list of records Parameters: records ( List [ Union [ str , Record ]] ) \u2013 List of records to be updated tag_keys ( List [ str ] ) \u2013 List of keys to be deleted Returns: int \u2013 the number of updated records Source code in geocube/client.py 242 243 244 245 246 247 248 249 250 251 252 def remove_records_tags ( self , records : List [ Union [ str , entities . Record ]], tag_keys : List [ str ]) -> int : \"\"\" Remove tags keys from a list of records Args: records: List of records to be updated tag_keys: List of keys to be deleted Returns: the number of updated records \"\"\" return self . _remove_records_tags ( records , tag_keys )","title":"remove_records_tags"},{"location":"user-guide/client/client-reference/#geocube.Client.tile_aoi","text":"Tile an AOI Parameters: aoi ( Union [ MultiPolygon , Polygon ] ) \u2013 AOI to be tiled in geographic coordinates crs ( Optional [ str ] , default: None ) \u2013 CRS of the tile (not the AOI) resolution ( Optional [ float ] , default: None ) \u2013 resolution of the tile shape ( Optional [ Tuple [ int , int ]] , default: None ) \u2013 shape of each tile layout_name ( Optional [ str ] , default: None ) \u2013 use a defined layout. layout ( Optional [ Layout ] , default: None ) \u2013 use a customer defined layout Returns: List [ Tile ] \u2013 a list of Tiles covering the AOI in the given CRS at the given resolution Source code in geocube/client.py 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 def tile_aoi ( self , aoi : Union [ geometry . MultiPolygon , geometry . Polygon ], layout_name : Optional [ str ] = None , layout : Optional [ entities . Layout ] = None , resolution : Optional [ float ] = None , crs : Optional [ str ] = None , shape : Optional [ Tuple [ int , int ]] = None ) -> List [ entities . Tile ]: \"\"\" Tile an AOI Args: aoi: AOI to be tiled in **geographic coordinates** crs: CRS of the tile (not the AOI) resolution: resolution of the tile shape: shape of each tile layout_name: use a defined layout. layout: use a customer defined layout Returns: a list of Tiles covering the AOI in the given CRS at the given resolution \"\"\" return self . _tile_aoi ( aoi , layout_name , layout , resolution , crs , shape )","title":"tile_aoi"},{"location":"user-guide/client/client-reference/#geocube.Client.variable","text":"Fetch a variable given an id, a name or an instance id (mutually exclusive) Parameters: name ( str , default: None ) \u2013 id_ ( str , default: None ) \u2013 internal id of the variable (uuid4) instance_id ( str , default: None ) \u2013 internal id of one instance of the variable (uuid4) Returns: Union [ Variable , VariableInstance ] \u2013 either a Variable (first two cases) or a VariableInstance (specialization of the variable) Source code in geocube/client.py 65 66 67 68 69 70 71 72 73 74 75 76 77 78 def variable ( self , name : str = None , id_ : str = None , instance_id : str = None ) \\ -> Union [ entities . Variable , entities . VariableInstance ]: \"\"\" Fetch a variable given an id, a name or an instance id (mutually exclusive) Args: name: id_: internal id of the variable (uuid4) instance_id: internal id of one instance of the variable (uuid4) Returns: either a Variable (first two cases) or a VariableInstance (specialization of the variable) \"\"\" return self . _variable ( name , id_ , instance_id )","title":"variable"},{"location":"user-guide/client/client-reference/#geocube.Client.version","text":"Returns the version of the Geocube Server Source code in geocube/client.py 61 62 63 def version ( self ) -> str : \"\"\" Returns the version of the Geocube Server \"\"\" return self . _version ()","title":"version"},{"location":"user-guide/client/consolidater-reference/","text":"Consolidater Bases: Client Source code in geocube/consolidater.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 class Consolidater ( Client ): def list_jobs ( self , name_like : str = \"\" , page = 0 , limit = 10 ): \"\"\" List jobs by name name_like: pattern of the name. * and ? are supported to match all or any character. \"\"\" return self . _list_jobs ( name_like , page , limit ) def job ( self , name : str ): \"\"\" Get job by name. Shortcut for ListJobs(name)[0]. Only few logs are loaded. \"\"\" return self . _job ( name ) def get_job ( self , job_id : Union [ str , entities . Job ], log_page = 0 , log_limit = 1000 ): \"\"\" Get job by id. Logs are loaded by pages, because some big jobs have too many logs to fit in a gRPC response. \"\"\" return self . _get_job ( job_id , log_page , log_limit ) @staticmethod def wait_job ( job : entities . Job , wait_secs = 15 , timeout_secs = None , verbose = True ): \"\"\" Wait for the job to finish or fail. If the execution level is step-by-step, it will automatically continue. If verbose=True, the last log is printed every time a state change is detected. \"\"\" prev_state = job . state while job . state not in [ 'DONE' , 'FAILED' , 'DONEBUTUNTIDY' ]: time . sleep ( wait_secs ) job . refresh ( log_limit = 1 if verbose else 0 ) if job . state != prev_state : prev_state = job . state if verbose : print ( job . logs [ - 1 ]) if job . waiting : job . next () if timeout_secs is not None : timeout_secs -= wait_secs if timeout_secs < 0 : raise TimeoutError ( f \"job { job . name } : state= { job . state } \" ) def remove_terminated_jobs ( self , name_like : str = \"\" , state : str = \"\" ): \"\"\" Remove all the jobs from the Geocube given a name pattern (by default, all terminated jobs) name_like: pattern of the name. * and ? are supported to match all or any character. state: state of the jobs to be removed. \"\"\" return self . _remove_terminated_jobs ( name_like , state ) def consolidate ( self , job_name : str , instance : Union [ str , entities . VariableInstance ], layout : Union [ str , entities . Layout ], * , records : Union [ List [ entities . RecordIdentifiers ], None ] = None , tags : Union [ Dict [ str , str ], None ] = None , from_time : Union [ datetime , None ] = None , to_time : Union [ datetime , None ] = None , collapse_on_record : Union [ entities . Record , str , None ] = None , execution_level : entities . ExecutionLevel = entities . ExecutionLevel . ASYNCHRONOUS ): return self . _consolidate ( job_name , instance , layout , records , tags , from_time , to_time , collapse_on_record , execution_level ) @utils . catch_rpc_error def _list_jobs ( self , name_like : str , page : int , limit : int ): res = self . stub . ListJobs ( operations_pb2 . ListJobsRequest ( name_like = name_like , page = page , limit = limit )) return [ entities . Job . from_pb ( self . stub , r ) for r in res . jobs ] @utils . catch_rpc_error def _job ( self , name : str ): res = self . stub . ListJobs ( operations_pb2 . ListJobsRequest ( name_like = name )) if len ( res . jobs ) == 0 : raise utils . GeocubeError ( \"job\" , \"NOT_FOUND\" , \"with name: \" + name ) return entities . Job . from_pb ( self . stub , res . jobs [ 0 ]) @utils . catch_rpc_error def _get_job ( self , job_id : Union [ str , entities . Job ], log_page , log_limit ): res = self . stub . GetJob ( operations_pb2 . GetJobRequest ( id = entities . get_id ( job_id ), log_page = log_page , log_limit = log_limit )) return entities . Job . from_pb ( self . stub , res . job ) @utils . catch_rpc_error def _remove_terminated_jobs ( self , name_like : str , state : str ): self . stub . CleanJobs ( operations_pb2 . CleanJobsRequest ( name_like = name_like , state = state )) @utils . catch_rpc_error def _consolidate ( self , job_name : str , instance : Union [ str , entities . VariableInstance ], layout : Union [ str , entities . Layout ], records : Union [ List [ entities . RecordIdentifiers ], None ], tags : Union [ Dict [ str , str ], None ], from_time : Union [ datetime , None ], to_time : Union [ datetime , None ], collapse_on_record : Union [ entities . Record , str , None ], execution_level : entities . ExecutionLevel ): common = { \"job_name\" : job_name , \"instance_id\" : entities . get_id ( instance ), \"layout_name\" : entities . get_id ( layout ), \"execution_level\" : execution_level . value , \"collapse_on_record_id\" : entities . get_id ( collapse_on_record ) if collapse_on_record is not None else \"\" , } if records is not None : req = operations_pb2 . ConsolidateRequest ( ** common , records = records_pb2 . RecordIdList ( ids = entities . get_ids ( records ))) if from_time is not None : warnings . warn ( \"from_time is ignored if records is provided as argument to consolidate\" ) if to_time is not None : warnings . warn ( \"to_time is ignored if records is provided as argument to consolidate\" ) if tags is not None : warnings . warn ( \"tags is ignored if records is provided as argument to consolidate\" ) else : from_time_pb = utils . pb_null_timestamp () if from_time is not None : from_time_pb . FromDatetime ( from_time ) to_time_pb = utils . pb_null_timestamp () if to_time is not None : to_time_pb . FromDatetime ( to_time ) req = operations_pb2 . ConsolidateRequest ( ** common , filters = records_pb2 . RecordFilters ( tags = tags , from_time = from_time_pb , to_time = to_time_pb )) return self . get_job ( self . stub . Consolidate ( req ) . job_id ) get_job ( job_id , log_page = 0 , log_limit = 1000 ) Get job by id. Logs are loaded by pages, because some big jobs have too many logs to fit in a gRPC response. Source code in geocube/consolidater.py 23 24 25 26 27 28 def get_job ( self , job_id : Union [ str , entities . Job ], log_page = 0 , log_limit = 1000 ): \"\"\" Get job by id. Logs are loaded by pages, because some big jobs have too many logs to fit in a gRPC response. \"\"\" return self . _get_job ( job_id , log_page , log_limit ) job ( name ) Get job by name. Shortcut for ListJobs(name)[0]. Only few logs are loaded. Source code in geocube/consolidater.py 19 20 21 def job ( self , name : str ): \"\"\" Get job by name. Shortcut for ListJobs(name)[0]. Only few logs are loaded. \"\"\" return self . _job ( name ) list_jobs ( name_like = '' , page = 0 , limit = 10 ) List jobs by name name_like: pattern of the name. * and ? are supported to match all or any character. Source code in geocube/consolidater.py 12 13 14 15 16 17 def list_jobs ( self , name_like : str = \"\" , page = 0 , limit = 10 ): \"\"\" List jobs by name name_like: pattern of the name. * and ? are supported to match all or any character. \"\"\" return self . _list_jobs ( name_like , page , limit ) remove_terminated_jobs ( name_like = '' , state = '' ) Remove all the jobs from the Geocube given a name pattern (by default, all terminated jobs) name_like: pattern of the name. * and ? are supported to match all or any character. state: state of the jobs to be removed. Source code in geocube/consolidater.py 52 53 54 55 56 57 58 def remove_terminated_jobs ( self , name_like : str = \"\" , state : str = \"\" ): \"\"\" Remove all the jobs from the Geocube given a name pattern (by default, all terminated jobs) name_like: pattern of the name. * and ? are supported to match all or any character. state: state of the jobs to be removed. \"\"\" return self . _remove_terminated_jobs ( name_like , state ) wait_job ( job , wait_secs = 15 , timeout_secs = None , verbose = True ) staticmethod Wait for the job to finish or fail. If the execution level is step-by-step, it will automatically continue. If verbose=True, the last log is printed every time a state change is detected. Source code in geocube/consolidater.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 @staticmethod def wait_job ( job : entities . Job , wait_secs = 15 , timeout_secs = None , verbose = True ): \"\"\" Wait for the job to finish or fail. If the execution level is step-by-step, it will automatically continue. If verbose=True, the last log is printed every time a state change is detected. \"\"\" prev_state = job . state while job . state not in [ 'DONE' , 'FAILED' , 'DONEBUTUNTIDY' ]: time . sleep ( wait_secs ) job . refresh ( log_limit = 1 if verbose else 0 ) if job . state != prev_state : prev_state = job . state if verbose : print ( job . logs [ - 1 ]) if job . waiting : job . next () if timeout_secs is not None : timeout_secs -= wait_secs if timeout_secs < 0 : raise TimeoutError ( f \"job { job . name } : state= { job . state } \" )","title":"Consolidater"},{"location":"user-guide/client/consolidater-reference/#consolidater","text":"Bases: Client Source code in geocube/consolidater.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 class Consolidater ( Client ): def list_jobs ( self , name_like : str = \"\" , page = 0 , limit = 10 ): \"\"\" List jobs by name name_like: pattern of the name. * and ? are supported to match all or any character. \"\"\" return self . _list_jobs ( name_like , page , limit ) def job ( self , name : str ): \"\"\" Get job by name. Shortcut for ListJobs(name)[0]. Only few logs are loaded. \"\"\" return self . _job ( name ) def get_job ( self , job_id : Union [ str , entities . Job ], log_page = 0 , log_limit = 1000 ): \"\"\" Get job by id. Logs are loaded by pages, because some big jobs have too many logs to fit in a gRPC response. \"\"\" return self . _get_job ( job_id , log_page , log_limit ) @staticmethod def wait_job ( job : entities . Job , wait_secs = 15 , timeout_secs = None , verbose = True ): \"\"\" Wait for the job to finish or fail. If the execution level is step-by-step, it will automatically continue. If verbose=True, the last log is printed every time a state change is detected. \"\"\" prev_state = job . state while job . state not in [ 'DONE' , 'FAILED' , 'DONEBUTUNTIDY' ]: time . sleep ( wait_secs ) job . refresh ( log_limit = 1 if verbose else 0 ) if job . state != prev_state : prev_state = job . state if verbose : print ( job . logs [ - 1 ]) if job . waiting : job . next () if timeout_secs is not None : timeout_secs -= wait_secs if timeout_secs < 0 : raise TimeoutError ( f \"job { job . name } : state= { job . state } \" ) def remove_terminated_jobs ( self , name_like : str = \"\" , state : str = \"\" ): \"\"\" Remove all the jobs from the Geocube given a name pattern (by default, all terminated jobs) name_like: pattern of the name. * and ? are supported to match all or any character. state: state of the jobs to be removed. \"\"\" return self . _remove_terminated_jobs ( name_like , state ) def consolidate ( self , job_name : str , instance : Union [ str , entities . VariableInstance ], layout : Union [ str , entities . Layout ], * , records : Union [ List [ entities . RecordIdentifiers ], None ] = None , tags : Union [ Dict [ str , str ], None ] = None , from_time : Union [ datetime , None ] = None , to_time : Union [ datetime , None ] = None , collapse_on_record : Union [ entities . Record , str , None ] = None , execution_level : entities . ExecutionLevel = entities . ExecutionLevel . ASYNCHRONOUS ): return self . _consolidate ( job_name , instance , layout , records , tags , from_time , to_time , collapse_on_record , execution_level ) @utils . catch_rpc_error def _list_jobs ( self , name_like : str , page : int , limit : int ): res = self . stub . ListJobs ( operations_pb2 . ListJobsRequest ( name_like = name_like , page = page , limit = limit )) return [ entities . Job . from_pb ( self . stub , r ) for r in res . jobs ] @utils . catch_rpc_error def _job ( self , name : str ): res = self . stub . ListJobs ( operations_pb2 . ListJobsRequest ( name_like = name )) if len ( res . jobs ) == 0 : raise utils . GeocubeError ( \"job\" , \"NOT_FOUND\" , \"with name: \" + name ) return entities . Job . from_pb ( self . stub , res . jobs [ 0 ]) @utils . catch_rpc_error def _get_job ( self , job_id : Union [ str , entities . Job ], log_page , log_limit ): res = self . stub . GetJob ( operations_pb2 . GetJobRequest ( id = entities . get_id ( job_id ), log_page = log_page , log_limit = log_limit )) return entities . Job . from_pb ( self . stub , res . job ) @utils . catch_rpc_error def _remove_terminated_jobs ( self , name_like : str , state : str ): self . stub . CleanJobs ( operations_pb2 . CleanJobsRequest ( name_like = name_like , state = state )) @utils . catch_rpc_error def _consolidate ( self , job_name : str , instance : Union [ str , entities . VariableInstance ], layout : Union [ str , entities . Layout ], records : Union [ List [ entities . RecordIdentifiers ], None ], tags : Union [ Dict [ str , str ], None ], from_time : Union [ datetime , None ], to_time : Union [ datetime , None ], collapse_on_record : Union [ entities . Record , str , None ], execution_level : entities . ExecutionLevel ): common = { \"job_name\" : job_name , \"instance_id\" : entities . get_id ( instance ), \"layout_name\" : entities . get_id ( layout ), \"execution_level\" : execution_level . value , \"collapse_on_record_id\" : entities . get_id ( collapse_on_record ) if collapse_on_record is not None else \"\" , } if records is not None : req = operations_pb2 . ConsolidateRequest ( ** common , records = records_pb2 . RecordIdList ( ids = entities . get_ids ( records ))) if from_time is not None : warnings . warn ( \"from_time is ignored if records is provided as argument to consolidate\" ) if to_time is not None : warnings . warn ( \"to_time is ignored if records is provided as argument to consolidate\" ) if tags is not None : warnings . warn ( \"tags is ignored if records is provided as argument to consolidate\" ) else : from_time_pb = utils . pb_null_timestamp () if from_time is not None : from_time_pb . FromDatetime ( from_time ) to_time_pb = utils . pb_null_timestamp () if to_time is not None : to_time_pb . FromDatetime ( to_time ) req = operations_pb2 . ConsolidateRequest ( ** common , filters = records_pb2 . RecordFilters ( tags = tags , from_time = from_time_pb , to_time = to_time_pb )) return self . get_job ( self . stub . Consolidate ( req ) . job_id )","title":"Consolidater"},{"location":"user-guide/client/consolidater-reference/#geocube.Consolidater.get_job","text":"Get job by id. Logs are loaded by pages, because some big jobs have too many logs to fit in a gRPC response. Source code in geocube/consolidater.py 23 24 25 26 27 28 def get_job ( self , job_id : Union [ str , entities . Job ], log_page = 0 , log_limit = 1000 ): \"\"\" Get job by id. Logs are loaded by pages, because some big jobs have too many logs to fit in a gRPC response. \"\"\" return self . _get_job ( job_id , log_page , log_limit )","title":"get_job"},{"location":"user-guide/client/consolidater-reference/#geocube.Consolidater.job","text":"Get job by name. Shortcut for ListJobs(name)[0]. Only few logs are loaded. Source code in geocube/consolidater.py 19 20 21 def job ( self , name : str ): \"\"\" Get job by name. Shortcut for ListJobs(name)[0]. Only few logs are loaded. \"\"\" return self . _job ( name )","title":"job"},{"location":"user-guide/client/consolidater-reference/#geocube.Consolidater.list_jobs","text":"List jobs by name name_like: pattern of the name. * and ? are supported to match all or any character. Source code in geocube/consolidater.py 12 13 14 15 16 17 def list_jobs ( self , name_like : str = \"\" , page = 0 , limit = 10 ): \"\"\" List jobs by name name_like: pattern of the name. * and ? are supported to match all or any character. \"\"\" return self . _list_jobs ( name_like , page , limit )","title":"list_jobs"},{"location":"user-guide/client/consolidater-reference/#geocube.Consolidater.remove_terminated_jobs","text":"Remove all the jobs from the Geocube given a name pattern (by default, all terminated jobs) name_like: pattern of the name. * and ? are supported to match all or any character. state: state of the jobs to be removed. Source code in geocube/consolidater.py 52 53 54 55 56 57 58 def remove_terminated_jobs ( self , name_like : str = \"\" , state : str = \"\" ): \"\"\" Remove all the jobs from the Geocube given a name pattern (by default, all terminated jobs) name_like: pattern of the name. * and ? are supported to match all or any character. state: state of the jobs to be removed. \"\"\" return self . _remove_terminated_jobs ( name_like , state )","title":"remove_terminated_jobs"},{"location":"user-guide/client/consolidater-reference/#geocube.Consolidater.wait_job","text":"Wait for the job to finish or fail. If the execution level is step-by-step, it will automatically continue. If verbose=True, the last log is printed every time a state change is detected. Source code in geocube/consolidater.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 @staticmethod def wait_job ( job : entities . Job , wait_secs = 15 , timeout_secs = None , verbose = True ): \"\"\" Wait for the job to finish or fail. If the execution level is step-by-step, it will automatically continue. If verbose=True, the last log is printed every time a state change is detected. \"\"\" prev_state = job . state while job . state not in [ 'DONE' , 'FAILED' , 'DONEBUTUNTIDY' ]: time . sleep ( wait_secs ) job . refresh ( log_limit = 1 if verbose else 0 ) if job . state != prev_state : prev_state = job . state if verbose : print ( job . logs [ - 1 ]) if job . waiting : job . next () if timeout_secs is not None : timeout_secs -= wait_secs if timeout_secs < 0 : raise TimeoutError ( f \"job { job . name } : state= { job . state } \" )","title":"wait_job"},{"location":"user-guide/entities/dataset-reference/","text":"Datasets & Containers Dataset A dataset is the metadata to retrieve an image from a file (see entities.Container). It is defined by a record and the instance of a variable. A dataset defines: - Which band(s) are indexed (usually all the bands, but it can be a subset) - How to map the value of its pixels to the dataformat of the variable. In more details: . the dataformat of the dataset (dformat.[no_data, min, max]) that describes the pixel of the image . the mapping from each pixel to the data format of the variable (variable.dformat). This mapping is defined as [MinOut, MaxOut, Exponent]. Attributes: record_id ( str ) \u2013 id of the record describing the data-take instance_id ( Union [ str , VariableInstance ] ) \u2013 describing the data. @warning Must be an instance of Variable if one of bands, dformat, min_out, max_out is None bands ( List [ int ] ) \u2013 subset of bands' container (start at 1) that maps to variable.bands (by default, all the bands) dformat ( DataFormat ) \u2013 describing the internal format (see entities.DataFormat.from_user()) min_out ( float ) \u2013 (optional, default: instance.dformat.min_value, instance.dformat.dtype) maps dformat.min_value max_out ( float ) \u2013 (optional, default: instance.dformat.max_value, instance.dformat.dtype) maps dformat.max_value exponent ( float ) \u2013 (optional, default: 1) non-linear scaling between dformat.min_max_value to min_max_out. Source code in geocube/entities/container.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 @dataclass class Dataset : \"\"\" A dataset is the metadata to retrieve an image from a file (see entities.Container). It is defined by a record and the instance of a variable. A dataset defines: - Which band(s) are indexed (usually all the bands, but it can be a subset) - How to map the value of its pixels to the dataformat of the variable. In more details: . the dataformat of the dataset (dformat.[no_data, min, max]) that describes the pixel of the image . the mapping from each pixel to the data format of the variable (variable.dformat). This mapping is defined as [MinOut, MaxOut, Exponent]. Attributes: record_id: id of the record describing the data-take instance_id: describing the data. @warning Must be an instance of Variable if one of bands, dformat, min_out, max_out is None bands: subset of bands' container (start at 1) that maps to `variable.bands` (by default, all the bands) dformat: describing the internal format (see entities.DataFormat.from_user()) min_out: (optional, default: instance.dformat.min_value, instance.dformat.dtype) maps dformat.min_value max_out: (optional, default: instance.dformat.max_value, instance.dformat.dtype) maps dformat.max_value exponent: (optional, default: 1) non-linear scaling between dformat.min_max_value to min_max_out. \"\"\" record_id : str instance_id : Union [ str , entities . VariableInstance ] container_subdir : str = \"\" bands : List [ int ] = None dformat : entities . DataFormat = None min_out : float = None max_out : float = None exponent : float = 1 def __post_init__ ( self ): if self . bands is None or self . min_out is None or self . max_out is None or self . dformat is None : assert isinstance ( self . instance_id , entities . VariableInstance ) if self . bands is None : self . bands = list ( range ( 1 , len ( self . instance_id . bands ) + 1 )) if self . min_out is None : self . min_out = self . instance_id . dformat . min_value if self . max_out is None : self . max_out = self . instance_id . dformat . max_value if self . dformat is None : self . dformat = self . instance_id . dformat self . instance_id = entities . get_id ( self . instance_id ) self . record_id = entities . get_id ( self . record_id ) if len ( self . bands ) == 0 : raise ValueError ( \"Bands must not be empty\" ) def to_pb ( self ) -> operations_pb2 . Dataset : pbd = operations_pb2 . Dataset ( record_id = self . record_id , instance_id = self . instance_id , container_subdir = self . container_subdir , dformat = self . dformat . to_pb (), real_min_value = self . min_out , real_max_value = self . max_out , exponent = self . exponent , bands = self . bands ) return pbd @classmethod def from_pb ( cls , pb : operations_pb2 . Dataset ): return cls ( record_id = pb . record_id , instance_id = pb . instance_id , container_subdir = pb . container_subdir , bands = pb . bands , dformat = entities . DataFormat . from_pb ( pb . dformat ), min_out = pb . real_min_value , max_out = pb . real_max_value , exponent = pb . exponent , ) Container Define a container of datasets. Usually a container is a file containing one dataset. But after a consolidation or if the container has several bands, it can contain several datasets. Attributes: uri ( str ) \u2013 URI of the file managed ( bool ) \u2013 True if the Geocube is responsible for the lifecycle of this file datasets ( List [ Dataset ] ) \u2013 List of datasets of the container Source code in geocube/entities/container.py 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 @dataclass class Container : \"\"\" Define a container of datasets. Usually a container is a file containing one dataset. But after a consolidation or if the container has several bands, it can contain several datasets. Attributes: uri: URI of the file managed: True if the Geocube is responsible for the lifecycle of this file datasets: List of datasets of the container \"\"\" uri : str managed : bool datasets : List [ Dataset ] @classmethod def from_pb ( cls , pb : operations_pb2 . Container ): return cls ( uri = pb . uri , managed = pb . managed , datasets = [ entities . Dataset . from_pb ( pb_dataset ) for pb_dataset in pb . datasets ], )","title":"Dataset & Container"},{"location":"user-guide/entities/dataset-reference/#datasets-containers","text":"","title":"Datasets &amp; Containers"},{"location":"user-guide/entities/dataset-reference/#dataset","text":"A dataset is the metadata to retrieve an image from a file (see entities.Container). It is defined by a record and the instance of a variable. A dataset defines: - Which band(s) are indexed (usually all the bands, but it can be a subset) - How to map the value of its pixels to the dataformat of the variable. In more details: . the dataformat of the dataset (dformat.[no_data, min, max]) that describes the pixel of the image . the mapping from each pixel to the data format of the variable (variable.dformat). This mapping is defined as [MinOut, MaxOut, Exponent]. Attributes: record_id ( str ) \u2013 id of the record describing the data-take instance_id ( Union [ str , VariableInstance ] ) \u2013 describing the data. @warning Must be an instance of Variable if one of bands, dformat, min_out, max_out is None bands ( List [ int ] ) \u2013 subset of bands' container (start at 1) that maps to variable.bands (by default, all the bands) dformat ( DataFormat ) \u2013 describing the internal format (see entities.DataFormat.from_user()) min_out ( float ) \u2013 (optional, default: instance.dformat.min_value, instance.dformat.dtype) maps dformat.min_value max_out ( float ) \u2013 (optional, default: instance.dformat.max_value, instance.dformat.dtype) maps dformat.max_value exponent ( float ) \u2013 (optional, default: 1) non-linear scaling between dformat.min_max_value to min_max_out. Source code in geocube/entities/container.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 @dataclass class Dataset : \"\"\" A dataset is the metadata to retrieve an image from a file (see entities.Container). It is defined by a record and the instance of a variable. A dataset defines: - Which band(s) are indexed (usually all the bands, but it can be a subset) - How to map the value of its pixels to the dataformat of the variable. In more details: . the dataformat of the dataset (dformat.[no_data, min, max]) that describes the pixel of the image . the mapping from each pixel to the data format of the variable (variable.dformat). This mapping is defined as [MinOut, MaxOut, Exponent]. Attributes: record_id: id of the record describing the data-take instance_id: describing the data. @warning Must be an instance of Variable if one of bands, dformat, min_out, max_out is None bands: subset of bands' container (start at 1) that maps to `variable.bands` (by default, all the bands) dformat: describing the internal format (see entities.DataFormat.from_user()) min_out: (optional, default: instance.dformat.min_value, instance.dformat.dtype) maps dformat.min_value max_out: (optional, default: instance.dformat.max_value, instance.dformat.dtype) maps dformat.max_value exponent: (optional, default: 1) non-linear scaling between dformat.min_max_value to min_max_out. \"\"\" record_id : str instance_id : Union [ str , entities . VariableInstance ] container_subdir : str = \"\" bands : List [ int ] = None dformat : entities . DataFormat = None min_out : float = None max_out : float = None exponent : float = 1 def __post_init__ ( self ): if self . bands is None or self . min_out is None or self . max_out is None or self . dformat is None : assert isinstance ( self . instance_id , entities . VariableInstance ) if self . bands is None : self . bands = list ( range ( 1 , len ( self . instance_id . bands ) + 1 )) if self . min_out is None : self . min_out = self . instance_id . dformat . min_value if self . max_out is None : self . max_out = self . instance_id . dformat . max_value if self . dformat is None : self . dformat = self . instance_id . dformat self . instance_id = entities . get_id ( self . instance_id ) self . record_id = entities . get_id ( self . record_id ) if len ( self . bands ) == 0 : raise ValueError ( \"Bands must not be empty\" ) def to_pb ( self ) -> operations_pb2 . Dataset : pbd = operations_pb2 . Dataset ( record_id = self . record_id , instance_id = self . instance_id , container_subdir = self . container_subdir , dformat = self . dformat . to_pb (), real_min_value = self . min_out , real_max_value = self . max_out , exponent = self . exponent , bands = self . bands ) return pbd @classmethod def from_pb ( cls , pb : operations_pb2 . Dataset ): return cls ( record_id = pb . record_id , instance_id = pb . instance_id , container_subdir = pb . container_subdir , bands = pb . bands , dformat = entities . DataFormat . from_pb ( pb . dformat ), min_out = pb . real_min_value , max_out = pb . real_max_value , exponent = pb . exponent , )","title":"Dataset"},{"location":"user-guide/entities/dataset-reference/#container","text":"Define a container of datasets. Usually a container is a file containing one dataset. But after a consolidation or if the container has several bands, it can contain several datasets. Attributes: uri ( str ) \u2013 URI of the file managed ( bool ) \u2013 True if the Geocube is responsible for the lifecycle of this file datasets ( List [ Dataset ] ) \u2013 List of datasets of the container Source code in geocube/entities/container.py 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 @dataclass class Container : \"\"\" Define a container of datasets. Usually a container is a file containing one dataset. But after a consolidation or if the container has several bands, it can contain several datasets. Attributes: uri: URI of the file managed: True if the Geocube is responsible for the lifecycle of this file datasets: List of datasets of the container \"\"\" uri : str managed : bool datasets : List [ Dataset ] @classmethod def from_pb ( cls , pb : operations_pb2 . Container ): return cls ( uri = pb . uri , managed = pb . managed , datasets = [ entities . Dataset . from_pb ( pb_dataset ) for pb_dataset in pb . datasets ], )","title":"Container"},{"location":"user-guide/entities/job-reference/","text":"Job Source code in geocube/entities/job.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 @dataclass class Job : _stub : Stub id : str name : str type : str state : str creation_time : datetime last_update_time : datetime logs : List [ str ] active_tasks : int failed_tasks : int execution_level : ExecutionLevel waiting : bool @classmethod def from_pb ( cls , stub : Stub , pb_job : operations_pb2 . Job ): return Job ( _stub = stub , id = pb_job . id , name = pb_job . name , type = pb_job . type , state = pb_job . state , creation_time = pb_job . creation_time . ToDatetime (), last_update_time = pb_job . last_update_time . ToDatetime (), logs = pb_job . logs , active_tasks = pb_job . active_tasks , failed_tasks = pb_job . failed_tasks , execution_level = ExecutionLevel ( pb_job . execution_level ), waiting = pb_job . waiting , ) @utils . catch_rpc_error def retry ( self , force : bool = False ): \"\"\" Retry a failed job Args: force: TO BE USED CAUTIOUSLY: retry the current state of the job, whatever the state. It can be unpredictable. Should only be used if the job is stuck in a pending state. \"\"\" self . _stub . RetryJob ( operations_pb2 . RetryJobRequest ( id = self . id , force_any_state = force )) @utils . catch_rpc_error def cancel ( self , force : bool = False ): \"\"\" Cancel the job if possible force: TO BE USED CAUTIOUSLY: cancel the current state of the job, whatever the state. It can be unpredictable. Should only be used if the job is stuck in a pending state.\"\"\" self . _stub . CancelJob ( operations_pb2 . CancelJobRequest ( id = self . id , force_any_state = force )) @utils . catch_rpc_error def next ( self ): \"\"\" Start the next step (must be in \"waiting\" state) \"\"\" if not self . waiting : raise Exception ( \"Job must be in waiting state\" ) self . _stub . ContinueJob ( operations_pb2 . ContinueJobRequest ( id = self . id )) @utils . catch_rpc_error def refresh ( self , log_page = 0 , log_limit = 1000 ): \"\"\" Reload a job from server (inplace operation) \"\"\" res = self . _stub . GetJob ( operations_pb2 . GetJobRequest ( id = self . id , log_page = log_page , log_limit = log_limit )) self . __dict__ = Job . from_pb ( self . _stub , res . job ) . __dict__ return self def tasks_from_logs ( self ) -> List [ Task ]: tasks = {} for i , log in enumerate ( self . logs ): log_task = parse . search ( \"Prepare {container:d} container(s) with {records:d} record(s) \" \"and {datasets:d} dataset(s) (Cell: {cell} , geographic: {coordinates} ) (id: {taskid} )\" , log ) if log_task is not None : if i < 3 : warnings . warn ( \"tasks_from_logs might have missed tasks. Please, reload job with more logs\" ) # Parse coordinates coordinates = parse . findall ( \" {lon:g} {lat:g} \" , log_task [ 'coordinates' ]) coordinates = geometry . LinearRing ([[ p [ 'lon' ], p [ 'lat' ]] for p in coordinates ]) tasks [ log_task [ 'taskid' ]] = Task ( log_task [ 'cell' ], log_task [ 'container' ], log_task [ 'records' ], log_task [ 'datasets' ], coordinates , \"\" ) else : log_task_status = parse . search ( \"TaskEvt received with status Task {status} (id: {taskid} ,\" , log ) if log_task_status is not None : task_id = log_task_status [ \"taskid\" ] if task_id in tasks : tasks [ task_id ] . status = log_task_status [ \"status\" ] else : warnings . warn ( f \"taskEvt for id { task_id } found, but task not found\" ) return list ( tasks . values ()) def deletion_job_from_logs ( self ) -> str : for log in self . logs : deletion_job = parse . search ( \"Create a deletion job to delete {nb_datasets:d} dataset(s): {name:S}\" , log ) if deletion_job is not None : return deletion_job [ \"name\" ] return \"\" def plot_tasks ( self ): tasks = self . tasks_from_logs () if len ( tasks ) == 0 : raise ValueError ( \"Tasks not found from logs. Cannot display\" ) color = [ 'r' if task . status == 'Failed' else 'g' if task . status == 'Successful' else 'black' for task in tasks ] base = utils . plot_aoi ( gpd . GeoSeries ([ task . coordinates for task in tasks ]), color = color ) for i , task in enumerate ( tasks ): center = task . coordinates . centroid base . text ( center . x , center . y , f \" { task . nb_records } rec \\n { task . nb_datasets } ds\" , ha = 'center' , va = 'center' , color = color [ i ]) base . set_title ( f \"Job ' { self . name } ' \\n \" f \" { len ( tasks ) } cells ( { self . active_tasks } active tasks - { self . failed_tasks } failed)\" ) return base def __repr__ ( self ): return \"Job {} ( {} )\" . format ( self . name , self . id ) def __str__ ( self ): if len ( self . logs ) > 20 : logs = f \" { self . logs [ 0 ] } \\n [+ { len ( self . logs ) - 20 } ...] \\n \" + ( \" \\n \" . join ( self . logs [ - 19 :])) else : logs = \" \\n \" . join ( self . logs ) return \"Job {} ( {} ) \\n \" \\ \" type {} \\n \" \\ \" state {} {} \\n \" \\ \" creation {} \\n \" \\ \" last_update {} \\n \" \\ \" active_tasks {} \\n \" \\ \" failed_tasks {} \\n \" \\ \" execution {} \\n \" \\ \" logs \\n {} \\n \" . format ( self . name , self . id , self . type , self . state , \"(waiting for user action)\" if self . waiting else \"\" , self . creation_time , self . last_update_time , self . active_tasks , self . failed_tasks , self . execution_level . name , logs ) cancel ( force = False ) Cancel the job if possible force: TO BE USED CAUTIOUSLY: cancel the current state of the job, whatever the state. It can be unpredictable. Should only be used if the job is stuck in a pending state. Source code in geocube/entities/job.py 78 79 80 81 82 83 @utils . catch_rpc_error def cancel ( self , force : bool = False ): \"\"\" Cancel the job if possible force: TO BE USED CAUTIOUSLY: cancel the current state of the job, whatever the state. It can be unpredictable. Should only be used if the job is stuck in a pending state.\"\"\" self . _stub . CancelJob ( operations_pb2 . CancelJobRequest ( id = self . id , force_any_state = force )) next () Start the next step (must be in \"waiting\" state) Source code in geocube/entities/job.py 85 86 87 88 89 90 @utils . catch_rpc_error def next ( self ): \"\"\" Start the next step (must be in \"waiting\" state) \"\"\" if not self . waiting : raise Exception ( \"Job must be in waiting state\" ) self . _stub . ContinueJob ( operations_pb2 . ContinueJobRequest ( id = self . id )) refresh ( log_page = 0 , log_limit = 1000 ) Reload a job from server (inplace operation) Source code in geocube/entities/job.py 92 93 94 95 96 97 @utils . catch_rpc_error def refresh ( self , log_page = 0 , log_limit = 1000 ): \"\"\" Reload a job from server (inplace operation) \"\"\" res = self . _stub . GetJob ( operations_pb2 . GetJobRequest ( id = self . id , log_page = log_page , log_limit = log_limit )) self . __dict__ = Job . from_pb ( self . _stub , res . job ) . __dict__ return self retry ( force = False ) Retry a failed job Parameters: force ( bool , default: False ) \u2013 TO BE USED CAUTIOUSLY: retry the current state of the job, whatever the state. It can be unpredictable. Should only be used if the job is stuck in a pending state. Source code in geocube/entities/job.py 66 67 68 69 70 71 72 73 74 75 76 @utils . catch_rpc_error def retry ( self , force : bool = False ): \"\"\" Retry a failed job Args: force: TO BE USED CAUTIOUSLY: retry the current state of the job, whatever the state. It can be unpredictable. Should only be used if the job is stuck in a pending state. \"\"\" self . _stub . RetryJob ( operations_pb2 . RetryJobRequest ( id = self . id , force_any_state = force ))","title":"Job"},{"location":"user-guide/entities/job-reference/#job","text":"Source code in geocube/entities/job.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 @dataclass class Job : _stub : Stub id : str name : str type : str state : str creation_time : datetime last_update_time : datetime logs : List [ str ] active_tasks : int failed_tasks : int execution_level : ExecutionLevel waiting : bool @classmethod def from_pb ( cls , stub : Stub , pb_job : operations_pb2 . Job ): return Job ( _stub = stub , id = pb_job . id , name = pb_job . name , type = pb_job . type , state = pb_job . state , creation_time = pb_job . creation_time . ToDatetime (), last_update_time = pb_job . last_update_time . ToDatetime (), logs = pb_job . logs , active_tasks = pb_job . active_tasks , failed_tasks = pb_job . failed_tasks , execution_level = ExecutionLevel ( pb_job . execution_level ), waiting = pb_job . waiting , ) @utils . catch_rpc_error def retry ( self , force : bool = False ): \"\"\" Retry a failed job Args: force: TO BE USED CAUTIOUSLY: retry the current state of the job, whatever the state. It can be unpredictable. Should only be used if the job is stuck in a pending state. \"\"\" self . _stub . RetryJob ( operations_pb2 . RetryJobRequest ( id = self . id , force_any_state = force )) @utils . catch_rpc_error def cancel ( self , force : bool = False ): \"\"\" Cancel the job if possible force: TO BE USED CAUTIOUSLY: cancel the current state of the job, whatever the state. It can be unpredictable. Should only be used if the job is stuck in a pending state.\"\"\" self . _stub . CancelJob ( operations_pb2 . CancelJobRequest ( id = self . id , force_any_state = force )) @utils . catch_rpc_error def next ( self ): \"\"\" Start the next step (must be in \"waiting\" state) \"\"\" if not self . waiting : raise Exception ( \"Job must be in waiting state\" ) self . _stub . ContinueJob ( operations_pb2 . ContinueJobRequest ( id = self . id )) @utils . catch_rpc_error def refresh ( self , log_page = 0 , log_limit = 1000 ): \"\"\" Reload a job from server (inplace operation) \"\"\" res = self . _stub . GetJob ( operations_pb2 . GetJobRequest ( id = self . id , log_page = log_page , log_limit = log_limit )) self . __dict__ = Job . from_pb ( self . _stub , res . job ) . __dict__ return self def tasks_from_logs ( self ) -> List [ Task ]: tasks = {} for i , log in enumerate ( self . logs ): log_task = parse . search ( \"Prepare {container:d} container(s) with {records:d} record(s) \" \"and {datasets:d} dataset(s) (Cell: {cell} , geographic: {coordinates} ) (id: {taskid} )\" , log ) if log_task is not None : if i < 3 : warnings . warn ( \"tasks_from_logs might have missed tasks. Please, reload job with more logs\" ) # Parse coordinates coordinates = parse . findall ( \" {lon:g} {lat:g} \" , log_task [ 'coordinates' ]) coordinates = geometry . LinearRing ([[ p [ 'lon' ], p [ 'lat' ]] for p in coordinates ]) tasks [ log_task [ 'taskid' ]] = Task ( log_task [ 'cell' ], log_task [ 'container' ], log_task [ 'records' ], log_task [ 'datasets' ], coordinates , \"\" ) else : log_task_status = parse . search ( \"TaskEvt received with status Task {status} (id: {taskid} ,\" , log ) if log_task_status is not None : task_id = log_task_status [ \"taskid\" ] if task_id in tasks : tasks [ task_id ] . status = log_task_status [ \"status\" ] else : warnings . warn ( f \"taskEvt for id { task_id } found, but task not found\" ) return list ( tasks . values ()) def deletion_job_from_logs ( self ) -> str : for log in self . logs : deletion_job = parse . search ( \"Create a deletion job to delete {nb_datasets:d} dataset(s): {name:S}\" , log ) if deletion_job is not None : return deletion_job [ \"name\" ] return \"\" def plot_tasks ( self ): tasks = self . tasks_from_logs () if len ( tasks ) == 0 : raise ValueError ( \"Tasks not found from logs. Cannot display\" ) color = [ 'r' if task . status == 'Failed' else 'g' if task . status == 'Successful' else 'black' for task in tasks ] base = utils . plot_aoi ( gpd . GeoSeries ([ task . coordinates for task in tasks ]), color = color ) for i , task in enumerate ( tasks ): center = task . coordinates . centroid base . text ( center . x , center . y , f \" { task . nb_records } rec \\n { task . nb_datasets } ds\" , ha = 'center' , va = 'center' , color = color [ i ]) base . set_title ( f \"Job ' { self . name } ' \\n \" f \" { len ( tasks ) } cells ( { self . active_tasks } active tasks - { self . failed_tasks } failed)\" ) return base def __repr__ ( self ): return \"Job {} ( {} )\" . format ( self . name , self . id ) def __str__ ( self ): if len ( self . logs ) > 20 : logs = f \" { self . logs [ 0 ] } \\n [+ { len ( self . logs ) - 20 } ...] \\n \" + ( \" \\n \" . join ( self . logs [ - 19 :])) else : logs = \" \\n \" . join ( self . logs ) return \"Job {} ( {} ) \\n \" \\ \" type {} \\n \" \\ \" state {} {} \\n \" \\ \" creation {} \\n \" \\ \" last_update {} \\n \" \\ \" active_tasks {} \\n \" \\ \" failed_tasks {} \\n \" \\ \" execution {} \\n \" \\ \" logs \\n {} \\n \" . format ( self . name , self . id , self . type , self . state , \"(waiting for user action)\" if self . waiting else \"\" , self . creation_time , self . last_update_time , self . active_tasks , self . failed_tasks , self . execution_level . name , logs )","title":"Job"},{"location":"user-guide/entities/job-reference/#geocube.entities.Job.cancel","text":"Cancel the job if possible force: TO BE USED CAUTIOUSLY: cancel the current state of the job, whatever the state. It can be unpredictable. Should only be used if the job is stuck in a pending state. Source code in geocube/entities/job.py 78 79 80 81 82 83 @utils . catch_rpc_error def cancel ( self , force : bool = False ): \"\"\" Cancel the job if possible force: TO BE USED CAUTIOUSLY: cancel the current state of the job, whatever the state. It can be unpredictable. Should only be used if the job is stuck in a pending state.\"\"\" self . _stub . CancelJob ( operations_pb2 . CancelJobRequest ( id = self . id , force_any_state = force ))","title":"cancel"},{"location":"user-guide/entities/job-reference/#geocube.entities.Job.next","text":"Start the next step (must be in \"waiting\" state) Source code in geocube/entities/job.py 85 86 87 88 89 90 @utils . catch_rpc_error def next ( self ): \"\"\" Start the next step (must be in \"waiting\" state) \"\"\" if not self . waiting : raise Exception ( \"Job must be in waiting state\" ) self . _stub . ContinueJob ( operations_pb2 . ContinueJobRequest ( id = self . id ))","title":"next"},{"location":"user-guide/entities/job-reference/#geocube.entities.Job.refresh","text":"Reload a job from server (inplace operation) Source code in geocube/entities/job.py 92 93 94 95 96 97 @utils . catch_rpc_error def refresh ( self , log_page = 0 , log_limit = 1000 ): \"\"\" Reload a job from server (inplace operation) \"\"\" res = self . _stub . GetJob ( operations_pb2 . GetJobRequest ( id = self . id , log_page = log_page , log_limit = log_limit )) self . __dict__ = Job . from_pb ( self . _stub , res . job ) . __dict__ return self","title":"refresh"},{"location":"user-guide/entities/job-reference/#geocube.entities.Job.retry","text":"Retry a failed job Parameters: force ( bool , default: False ) \u2013 TO BE USED CAUTIOUSLY: retry the current state of the job, whatever the state. It can be unpredictable. Should only be used if the job is stuck in a pending state. Source code in geocube/entities/job.py 66 67 68 69 70 71 72 73 74 75 76 @utils . catch_rpc_error def retry ( self , force : bool = False ): \"\"\" Retry a failed job Args: force: TO BE USED CAUTIOUSLY: retry the current state of the job, whatever the state. It can be unpredictable. Should only be used if the job is stuck in a pending state. \"\"\" self . _stub . RetryJob ( operations_pb2 . RetryJobRequest ( id = self . id , force_any_state = force ))","title":"retry"},{"location":"user-guide/entities/layout-reference/","text":"Layout Layout Attributes: overviews_min_size: Maximum width or height of the smallest overview level. 0: No overview, -1: default=256. interlacing_pattern: To define how to interlace the records, the blocks, the bands and the overviews. See https://airbusgeo.github.io/geocube/user-guide/grpc/#geocube-ConsolidationParams Source code in geocube/entities/layout.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 @dataclass class Layout : \"\"\" Layout Attributes: overviews_min_size: Maximum width or height of the smallest overview level. 0: No overview, -1: default=256. interlacing_pattern: To define how to interlace the records, the blocks, the bands and the overviews. See https://airbusgeo.github.io/geocube/user-guide/grpc/#geocube-ConsolidationParams \"\"\" name : str grid_flags : List [ str ] grid_parameters : Dict [ str , str ] block_shape : Tuple [ int , int ] max_records : int = field ( default = 1000 ) overviews_min_size : int = field ( default =- 1 ) interlacing_pattern : str = field ( default = MUCOGPattern ) @classmethod def from_pb ( cls , pb_layout : layouts_pb2 . Layout ): return cls ( pb_layout . name , pb_layout . grid_flags , pb_layout . grid_parameters , ( pb_layout . block_x_size , pb_layout . block_y_size ), pb_layout . max_records , pb_layout . overviews_min_size , pb_layout . interlacing_pattern ) def to_pb ( self ): return layouts_pb2 . Layout ( name = self . name , grid_flags = self . grid_flags , grid_parameters = self . grid_parameters , block_x_size = self . block_shape [ 0 ], block_y_size = self . block_shape [ 1 ], max_records = self . max_records , overviews_min_size = self . overviews_min_size , interlacing_pattern = self . interlacing_pattern ) @classmethod def regular ( cls , name : str , crs : str , cell_size : Union [ int , Tuple [ int , int ]], resolution : float , block_size : int = 256 , max_records : int = 1000 , overviews_min_size : int = - 1 , interlacing_pattern = MUCOGPattern , origin : Tuple [ float , float ] = None ): grid_parameters = { \"grid\" : \"regular\" , \"crs\" : crs , \"resolution\" : f \" { resolution } \" , } if isinstance ( cell_size , tuple ): grid_parameters [ \"cell_x_size\" ] = f \" { cell_size [ 0 ] } \" grid_parameters [ \"cell_y_size\" ] = f \" { cell_size [ 1 ] } \" else : grid_parameters [ \"cell_size\" ] = f \" { cell_size } \" if origin is not None : grid_parameters [ \"ox\" ] = f \" { origin [ 0 ] } \" grid_parameters [ \"oy\" ] = f \" { origin [ 1 ] } \" return cls ( name = name , grid_parameters = grid_parameters , grid_flags = [], block_shape = ( block_size , block_size ), max_records = max_records , overviews_min_size = overviews_min_size , interlacing_pattern = interlacing_pattern ) @classmethod def single_cell ( cls , name : str , crs : str , resolution : int , block_size : int = 256 , max_records : int = 1000 , overviews_min_size : int = - 1 , interlacing_pattern = MUCOGPattern ): grid_parameters = { \"grid\" : \"singlecell\" , \"crs\" : crs , \"resolution\" : f \" { resolution } \" , } grid_flags = [] return cls ( name = name , grid_parameters = grid_parameters , grid_flags = grid_flags , block_shape = ( block_size , block_size ), max_records = max_records , overviews_min_size = overviews_min_size , interlacing_pattern = interlacing_pattern ) @classmethod def web_mercator ( cls , name : str , z_level : int , cell_size : int = 4096 , ** kwargs ): \"\"\" Define a regular layout using web-mercator projection at a given z_level \"\"\" earth_perimeter = 2 * 6378137 * math . pi ox , oy , resolution = - earth_perimeter / 2 , earth_perimeter / 2 , earth_perimeter / ( 256 * ( 1 << z_level )) return Layout . regular ( name , \"epsg:3857\" , cell_size = cell_size , resolution = resolution , origin = ( ox , oy ), ** kwargs ) def __repr__ ( self ): return f \"Layout ' { self . name } '\" def __str__ ( self ): return \"Layout ' {} ' \\n \" \\ \" grid_flags \\n {} \\n \" \\ \" grid_parameters \\n {} \\n \" \\ \" block_shape {} \\n \" \\ \" max_records {} \\n \" \\ \" overview_min_size {} \\n \" \\ \" interlacing_pattern {} \\n \" . format ( self . name , \" \\n \" . join ( self . grid_flags ), pprint . pformat ( self . grid_parameters , indent = 7 , width = 1 ), self . block_shape , self . max_records , self . overviews_min_size , self . interlacing_pattern ) web_mercator ( name , z_level , cell_size = 4096 , ** kwargs ) classmethod Define a regular layout using web-mercator projection at a given z_level Source code in geocube/entities/layout.py 98 99 100 101 102 103 @classmethod def web_mercator ( cls , name : str , z_level : int , cell_size : int = 4096 , ** kwargs ): \"\"\" Define a regular layout using web-mercator projection at a given z_level \"\"\" earth_perimeter = 2 * 6378137 * math . pi ox , oy , resolution = - earth_perimeter / 2 , earth_perimeter / 2 , earth_perimeter / ( 256 * ( 1 << z_level )) return Layout . regular ( name , \"epsg:3857\" , cell_size = cell_size , resolution = resolution , origin = ( ox , oy ), ** kwargs )","title":"Layout & Grid"},{"location":"user-guide/entities/layout-reference/#layout","text":"Layout Attributes: overviews_min_size: Maximum width or height of the smallest overview level. 0: No overview, -1: default=256. interlacing_pattern: To define how to interlace the records, the blocks, the bands and the overviews. See https://airbusgeo.github.io/geocube/user-guide/grpc/#geocube-ConsolidationParams Source code in geocube/entities/layout.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 @dataclass class Layout : \"\"\" Layout Attributes: overviews_min_size: Maximum width or height of the smallest overview level. 0: No overview, -1: default=256. interlacing_pattern: To define how to interlace the records, the blocks, the bands and the overviews. See https://airbusgeo.github.io/geocube/user-guide/grpc/#geocube-ConsolidationParams \"\"\" name : str grid_flags : List [ str ] grid_parameters : Dict [ str , str ] block_shape : Tuple [ int , int ] max_records : int = field ( default = 1000 ) overviews_min_size : int = field ( default =- 1 ) interlacing_pattern : str = field ( default = MUCOGPattern ) @classmethod def from_pb ( cls , pb_layout : layouts_pb2 . Layout ): return cls ( pb_layout . name , pb_layout . grid_flags , pb_layout . grid_parameters , ( pb_layout . block_x_size , pb_layout . block_y_size ), pb_layout . max_records , pb_layout . overviews_min_size , pb_layout . interlacing_pattern ) def to_pb ( self ): return layouts_pb2 . Layout ( name = self . name , grid_flags = self . grid_flags , grid_parameters = self . grid_parameters , block_x_size = self . block_shape [ 0 ], block_y_size = self . block_shape [ 1 ], max_records = self . max_records , overviews_min_size = self . overviews_min_size , interlacing_pattern = self . interlacing_pattern ) @classmethod def regular ( cls , name : str , crs : str , cell_size : Union [ int , Tuple [ int , int ]], resolution : float , block_size : int = 256 , max_records : int = 1000 , overviews_min_size : int = - 1 , interlacing_pattern = MUCOGPattern , origin : Tuple [ float , float ] = None ): grid_parameters = { \"grid\" : \"regular\" , \"crs\" : crs , \"resolution\" : f \" { resolution } \" , } if isinstance ( cell_size , tuple ): grid_parameters [ \"cell_x_size\" ] = f \" { cell_size [ 0 ] } \" grid_parameters [ \"cell_y_size\" ] = f \" { cell_size [ 1 ] } \" else : grid_parameters [ \"cell_size\" ] = f \" { cell_size } \" if origin is not None : grid_parameters [ \"ox\" ] = f \" { origin [ 0 ] } \" grid_parameters [ \"oy\" ] = f \" { origin [ 1 ] } \" return cls ( name = name , grid_parameters = grid_parameters , grid_flags = [], block_shape = ( block_size , block_size ), max_records = max_records , overviews_min_size = overviews_min_size , interlacing_pattern = interlacing_pattern ) @classmethod def single_cell ( cls , name : str , crs : str , resolution : int , block_size : int = 256 , max_records : int = 1000 , overviews_min_size : int = - 1 , interlacing_pattern = MUCOGPattern ): grid_parameters = { \"grid\" : \"singlecell\" , \"crs\" : crs , \"resolution\" : f \" { resolution } \" , } grid_flags = [] return cls ( name = name , grid_parameters = grid_parameters , grid_flags = grid_flags , block_shape = ( block_size , block_size ), max_records = max_records , overviews_min_size = overviews_min_size , interlacing_pattern = interlacing_pattern ) @classmethod def web_mercator ( cls , name : str , z_level : int , cell_size : int = 4096 , ** kwargs ): \"\"\" Define a regular layout using web-mercator projection at a given z_level \"\"\" earth_perimeter = 2 * 6378137 * math . pi ox , oy , resolution = - earth_perimeter / 2 , earth_perimeter / 2 , earth_perimeter / ( 256 * ( 1 << z_level )) return Layout . regular ( name , \"epsg:3857\" , cell_size = cell_size , resolution = resolution , origin = ( ox , oy ), ** kwargs ) def __repr__ ( self ): return f \"Layout ' { self . name } '\" def __str__ ( self ): return \"Layout ' {} ' \\n \" \\ \" grid_flags \\n {} \\n \" \\ \" grid_parameters \\n {} \\n \" \\ \" block_shape {} \\n \" \\ \" max_records {} \\n \" \\ \" overview_min_size {} \\n \" \\ \" interlacing_pattern {} \\n \" . format ( self . name , \" \\n \" . join ( self . grid_flags ), pprint . pformat ( self . grid_parameters , indent = 7 , width = 1 ), self . block_shape , self . max_records , self . overviews_min_size , self . interlacing_pattern )","title":"Layout"},{"location":"user-guide/entities/layout-reference/#geocube.entities.Layout.web_mercator","text":"Define a regular layout using web-mercator projection at a given z_level Source code in geocube/entities/layout.py 98 99 100 101 102 103 @classmethod def web_mercator ( cls , name : str , z_level : int , cell_size : int = 4096 , ** kwargs ): \"\"\" Define a regular layout using web-mercator projection at a given z_level \"\"\" earth_perimeter = 2 * 6378137 * math . pi ox , oy , resolution = - earth_perimeter / 2 , earth_perimeter / 2 , earth_perimeter / ( 256 * ( 1 << z_level )) return Layout . regular ( name , \"epsg:3857\" , cell_size = cell_size , resolution = resolution , origin = ( ox , oy ), ** kwargs )","title":"web_mercator"},{"location":"user-guide/entities/record-reference/","text":"Record Source code in geocube/entities/record.py 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 @dataclass class Record : id : str name : str datetime : datetime tags : Dict [ str , str ] aoi_id : str _aoi : geometry . MultiPolygon = geometry . MultiPolygon () @classmethod def from_pb ( cls , pb : records_pb2 . Record ): return cls ( id = pb . id , name = pb . name , tags = { key : value for key , value in pb . tags . items ()}, datetime = pb . time . ToDatetime (), aoi_id = pb . aoi_id , _aoi = aoi_from_pb ( pb . aoi ) ) @classmethod def from_geodataframe ( cls , gdf : gpd . GeoDataFrame ): return cls ( id = gdf [ \"id\" ] . iloc [ 0 ], name = gdf [ \"name\" ] . iloc [ 0 ], tags = { k : v for k , v in gdf [ \"tags\" ] . iloc [ 0 ]}, datetime = gdf [ \"datetime\" ] . iloc [ 0 ], aoi_id = gdf [ \"aoi_id\" ] . iloc [ 0 ], _aoi = gdf . geometry . iloc [ 0 ] ) def to_pb ( self ) -> records_pb2 . Record : pb = records_pb2 . Record ( id = self . id , name = self . name , tags = { key : value for key , value in self . tags . items ()}, aoi_id = self . aoi_id ) pb . time . FromDatetime ( self . datetime ) return pb def geodataframe ( self ) -> gpd . GeoDataFrame : self . _check_aoi () return gpd . GeoDataFrame ( { \"id\" : [ self . id ], \"name\" : [ self . name ], \"tags\" : [[( k , v ) for k , v in self . tags . items ()]], \"datetime\" : [ str ( self . datetime )], \"aoi_id\" : [ self . aoi_id ], \"geometry\" : [ self . aoi ] }, crs = 'epsg:4326' ) @property @utils . catch_rpc_error def aoi ( self ) -> geometry . MultiPolygon : self . _check_aoi () return self . _aoi @aoi . setter def aoi ( self , aoi : geometry . MultiPolygon ): self . _aoi = aoi def __repr__ ( self ): return \"Record {} ( {} )\" . format ( self . name , self . id ) def __str__ ( self ): return \"Record {} ( {} ) \\n \" \\ \" datetime {} \\n \" \\ \" tags \\n {} \\n \" \\ \" aoi_id {} \\n \" . format ( self . name , self . id , self . datetime , pprint . pformat ( self . tags , indent = 6 , width = 1 ), self . aoi_id ) + \\ \" aoi {} \\n \" . format ( self . aoi if not self . _aoi . is_empty else \"(not loaded)\" ) @staticmethod def key_date ( r : Record ): \"\"\" Returns the date of the record (without time). It's a GroupByKeyFunc, thus it can be used to group_by.\"\"\" return r . datetime . date () @staticmethod def key_datetime ( r : Record ): \"\"\" Returns the datetime of the record. It's a GroupByKeyFunc, thus it can be used to group_by.\"\"\" return r . datetime @staticmethod def group_by ( records : List [ Union [ Record , GroupedRecords ]], func_key : GroupByKeyFunc ) -> List [ GroupedRecords ]: \"\"\" group_by groups the records of the list by the key provided by the func_key(Record) Returns a list of lists of records Args: records : list of records to group. If records is a list of list, records is flattened. func_key : function taking a record and returning a key (e.g. entities.Record.key_date, lambda r:r.datetime) Returns: A list of grouped records (which is actually a list of records) \"\"\" if len ( records ) == 0 : return records if isinstance ( records [ 0 ], list ): records = [ r for rs in records for r in rs ] return Record . group_by ( records , func_key ) dict_rs = {} for r in records : k = func_key ( r ) if k not in dict_rs : dict_rs [ k ] = [ r ] else : dict_rs [ k ] . append ( r ) return list ( dict_rs . values ()) @staticmethod def list_to_geodataframe ( records : List [ Record ]) -> gpd . GeoDataFrame : return gpd . GeoDataFrame ( { \"id\" : [ r . id for r in records ], \"name\" : [ r . name for r in records ], \"tags\" : [[( k , v ) for k , v in r . tags . items ()] for r in records ], \"datetime\" : [ str ( r . datetime ) for r in records ], \"aoi_id\" : [ r . aoi_id for r in records ], \"geometry\" : [ r . aoi for r in records ], }, crs = 'epsg:4326' ) def _check_aoi ( self , raise_if_empty = True ) -> bool : if self . _aoi . is_empty : if raise_if_empty : raise ReferenceError ( \"AOI is not loaded. Call 'client.load_aoi(record)'\" ) return False return True group_by ( records , func_key ) staticmethod group_by groups the records of the list by the key provided by the func_key(Record) Returns a list of lists of records Parameters: records \u2013 list of records to group. If records is a list of list, records is flattened. func_key \u2013 function taking a record and returning a key (e.g. entities.Record.key_date, lambda r:r.datetime) Returns: List [ GroupedRecords ] \u2013 A list of grouped records (which is actually a list of records) Source code in geocube/entities/record.py 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 @staticmethod def group_by ( records : List [ Union [ Record , GroupedRecords ]], func_key : GroupByKeyFunc ) -> List [ GroupedRecords ]: \"\"\" group_by groups the records of the list by the key provided by the func_key(Record) Returns a list of lists of records Args: records : list of records to group. If records is a list of list, records is flattened. func_key : function taking a record and returning a key (e.g. entities.Record.key_date, lambda r:r.datetime) Returns: A list of grouped records (which is actually a list of records) \"\"\" if len ( records ) == 0 : return records if isinstance ( records [ 0 ], list ): records = [ r for rs in records for r in rs ] return Record . group_by ( records , func_key ) dict_rs = {} for r in records : k = func_key ( r ) if k not in dict_rs : dict_rs [ k ] = [ r ] else : dict_rs [ k ] . append ( r ) return list ( dict_rs . values ()) key_date ( r ) staticmethod Returns the date of the record (without time). It's a GroupByKeyFunc, thus it can be used to group_by. Source code in geocube/entities/record.py 131 132 133 134 135 @staticmethod def key_date ( r : Record ): \"\"\" Returns the date of the record (without time). It's a GroupByKeyFunc, thus it can be used to group_by.\"\"\" return r . datetime . date () key_datetime ( r ) staticmethod Returns the datetime of the record. It's a GroupByKeyFunc, thus it can be used to group_by. Source code in geocube/entities/record.py 137 138 139 140 141 @staticmethod def key_datetime ( r : Record ): \"\"\" Returns the datetime of the record. It's a GroupByKeyFunc, thus it can be used to group_by.\"\"\" return r . datetime","title":"Records"},{"location":"user-guide/entities/record-reference/#record","text":"Source code in geocube/entities/record.py 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 @dataclass class Record : id : str name : str datetime : datetime tags : Dict [ str , str ] aoi_id : str _aoi : geometry . MultiPolygon = geometry . MultiPolygon () @classmethod def from_pb ( cls , pb : records_pb2 . Record ): return cls ( id = pb . id , name = pb . name , tags = { key : value for key , value in pb . tags . items ()}, datetime = pb . time . ToDatetime (), aoi_id = pb . aoi_id , _aoi = aoi_from_pb ( pb . aoi ) ) @classmethod def from_geodataframe ( cls , gdf : gpd . GeoDataFrame ): return cls ( id = gdf [ \"id\" ] . iloc [ 0 ], name = gdf [ \"name\" ] . iloc [ 0 ], tags = { k : v for k , v in gdf [ \"tags\" ] . iloc [ 0 ]}, datetime = gdf [ \"datetime\" ] . iloc [ 0 ], aoi_id = gdf [ \"aoi_id\" ] . iloc [ 0 ], _aoi = gdf . geometry . iloc [ 0 ] ) def to_pb ( self ) -> records_pb2 . Record : pb = records_pb2 . Record ( id = self . id , name = self . name , tags = { key : value for key , value in self . tags . items ()}, aoi_id = self . aoi_id ) pb . time . FromDatetime ( self . datetime ) return pb def geodataframe ( self ) -> gpd . GeoDataFrame : self . _check_aoi () return gpd . GeoDataFrame ( { \"id\" : [ self . id ], \"name\" : [ self . name ], \"tags\" : [[( k , v ) for k , v in self . tags . items ()]], \"datetime\" : [ str ( self . datetime )], \"aoi_id\" : [ self . aoi_id ], \"geometry\" : [ self . aoi ] }, crs = 'epsg:4326' ) @property @utils . catch_rpc_error def aoi ( self ) -> geometry . MultiPolygon : self . _check_aoi () return self . _aoi @aoi . setter def aoi ( self , aoi : geometry . MultiPolygon ): self . _aoi = aoi def __repr__ ( self ): return \"Record {} ( {} )\" . format ( self . name , self . id ) def __str__ ( self ): return \"Record {} ( {} ) \\n \" \\ \" datetime {} \\n \" \\ \" tags \\n {} \\n \" \\ \" aoi_id {} \\n \" . format ( self . name , self . id , self . datetime , pprint . pformat ( self . tags , indent = 6 , width = 1 ), self . aoi_id ) + \\ \" aoi {} \\n \" . format ( self . aoi if not self . _aoi . is_empty else \"(not loaded)\" ) @staticmethod def key_date ( r : Record ): \"\"\" Returns the date of the record (without time). It's a GroupByKeyFunc, thus it can be used to group_by.\"\"\" return r . datetime . date () @staticmethod def key_datetime ( r : Record ): \"\"\" Returns the datetime of the record. It's a GroupByKeyFunc, thus it can be used to group_by.\"\"\" return r . datetime @staticmethod def group_by ( records : List [ Union [ Record , GroupedRecords ]], func_key : GroupByKeyFunc ) -> List [ GroupedRecords ]: \"\"\" group_by groups the records of the list by the key provided by the func_key(Record) Returns a list of lists of records Args: records : list of records to group. If records is a list of list, records is flattened. func_key : function taking a record and returning a key (e.g. entities.Record.key_date, lambda r:r.datetime) Returns: A list of grouped records (which is actually a list of records) \"\"\" if len ( records ) == 0 : return records if isinstance ( records [ 0 ], list ): records = [ r for rs in records for r in rs ] return Record . group_by ( records , func_key ) dict_rs = {} for r in records : k = func_key ( r ) if k not in dict_rs : dict_rs [ k ] = [ r ] else : dict_rs [ k ] . append ( r ) return list ( dict_rs . values ()) @staticmethod def list_to_geodataframe ( records : List [ Record ]) -> gpd . GeoDataFrame : return gpd . GeoDataFrame ( { \"id\" : [ r . id for r in records ], \"name\" : [ r . name for r in records ], \"tags\" : [[( k , v ) for k , v in r . tags . items ()] for r in records ], \"datetime\" : [ str ( r . datetime ) for r in records ], \"aoi_id\" : [ r . aoi_id for r in records ], \"geometry\" : [ r . aoi for r in records ], }, crs = 'epsg:4326' ) def _check_aoi ( self , raise_if_empty = True ) -> bool : if self . _aoi . is_empty : if raise_if_empty : raise ReferenceError ( \"AOI is not loaded. Call 'client.load_aoi(record)'\" ) return False return True","title":"Record"},{"location":"user-guide/entities/record-reference/#geocube.entities.Record.group_by","text":"group_by groups the records of the list by the key provided by the func_key(Record) Returns a list of lists of records Parameters: records \u2013 list of records to group. If records is a list of list, records is flattened. func_key \u2013 function taking a record and returning a key (e.g. entities.Record.key_date, lambda r:r.datetime) Returns: List [ GroupedRecords ] \u2013 A list of grouped records (which is actually a list of records) Source code in geocube/entities/record.py 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 @staticmethod def group_by ( records : List [ Union [ Record , GroupedRecords ]], func_key : GroupByKeyFunc ) -> List [ GroupedRecords ]: \"\"\" group_by groups the records of the list by the key provided by the func_key(Record) Returns a list of lists of records Args: records : list of records to group. If records is a list of list, records is flattened. func_key : function taking a record and returning a key (e.g. entities.Record.key_date, lambda r:r.datetime) Returns: A list of grouped records (which is actually a list of records) \"\"\" if len ( records ) == 0 : return records if isinstance ( records [ 0 ], list ): records = [ r for rs in records for r in rs ] return Record . group_by ( records , func_key ) dict_rs = {} for r in records : k = func_key ( r ) if k not in dict_rs : dict_rs [ k ] = [ r ] else : dict_rs [ k ] . append ( r ) return list ( dict_rs . values ())","title":"group_by"},{"location":"user-guide/entities/record-reference/#geocube.entities.Record.key_date","text":"Returns the date of the record (without time). It's a GroupByKeyFunc, thus it can be used to group_by. Source code in geocube/entities/record.py 131 132 133 134 135 @staticmethod def key_date ( r : Record ): \"\"\" Returns the date of the record (without time). It's a GroupByKeyFunc, thus it can be used to group_by.\"\"\" return r . datetime . date ()","title":"key_date"},{"location":"user-guide/entities/record-reference/#geocube.entities.Record.key_datetime","text":"Returns the datetime of the record. It's a GroupByKeyFunc, thus it can be used to group_by. Source code in geocube/entities/record.py 137 138 139 140 141 @staticmethod def key_datetime ( r : Record ): \"\"\" Returns the datetime of the record. It's a GroupByKeyFunc, thus it can be used to group_by.\"\"\" return r . datetime","title":"key_datetime"},{"location":"user-guide/entities/variable-reference/","text":"Variable & Instance Variable Bases: _ProxyVariable from geocube import Client client = Client('127.0.0.1:8080') vs = client.list_variables(\"test\") for v in vs: ... v.delete() profile = {'dformat': ('f8', -1, 0, 1), 'bands': ['R', 'G', 'B']} v = client.create_variable('test/vegetation/NDVI', **profile) v2 = client.variable('test/vegetation/NDVI') v.id==v2.id True vi = v.instance('master') v.description = \"normalize difference vegetation index \" vi.instance_metadata = {'version': 'v1'} vi2 = client.variable('test/vegetation/NDVI').instance('master') vi.id == vi2.id True Source code in geocube/entities/variable.py 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 class Variable ( _ProxyVariable ): \"\"\" >>> from geocube import Client >>> client = Client('127.0.0.1:8080') >>> vs = client.list_variables(\"test\") >>> for v in vs: ... v.delete() >>> profile = {'dformat': ('f8', -1, 0, 1), \\ 'bands': ['R', 'G', 'B']} >>> v = client.create_variable('test/vegetation/NDVI', **profile) >>> v2 = client.variable('test/vegetation/NDVI') >>> v.id==v2.id True >>> vi = v.instance('master') >>> v.description = \"normalize difference vegetation index \" >>> vi.instance_metadata = {'version': 'v1'} >>> vi2 = client.variable('test/vegetation/NDVI').instance('master') >>> vi.id == vi2.id True \"\"\" @classmethod def from_pb ( cls , stub : Stub , pb : variables_pb2 . Variable ): return cls ( _BaseVariable ( stub = stub , id = pb . id , name = pb . name , unit = pb . unit , description = pb . description , dformat = entities . DataFormat . from_pb ( pb . dformat ), bands = [ b for b in pb . bands ], palette = pb . palette , resampling_alg = entities . pb_resampling [ pb . resampling_alg ], ), { pbi . name : Instance . from_pb ( pbi ) for pbi in pb . instances }) def __init__ ( self , base_variable , instances = None ): super () . __init__ ( base_variable ) self . instances = instances if instances is not None else {} @property def id ( self ) -> str : return self . variable_id @property def name ( self ) -> str : return self . variable_name @utils . catch_rpc_error def instance ( self , name : Union [ None , str ] = None ) -> VariableInstance : \"\"\" Load the given instance Args: name: of the instance (or if None: the default instance if exists) Returns: Specialization of the variable \"\"\" if name is None : if len ( self . instances ) != 1 : raise utils . GeocubeError ( \"instance\" , grpc . StatusCode . NOT_FOUND . name , f \"Default instance does not exist for variable { self . variable_name } \" f \" (or more than one instance is defined).\" ) return VariableInstance ( self , next ( iter ( self . instances . values ()))) if name not in self . instances : raise utils . GeocubeError ( \"instance\" , grpc . StatusCode . NOT_FOUND . name , f \"Instance { name } does not exist for variable { self . variable_name } . \" f \"To instantiate a variable, use instantiate()\" ) return VariableInstance ( self , self . instances [ name ]) @utils . catch_rpc_error def instantiate ( self , name : str , metadata : Dict [ str , str ]) -> VariableInstance : \"\"\" Instantiate the variable (create a specialization) Args: name: of the instance metadata: of the instance (e.g. processing parameters, version...) can be empty Returns: The specialization of this variable \"\"\" if name in self . instances : if metadata is not None and self . instances [ name ] . metadata != metadata : raise utils . GeocubeError ( \"instantiate\" , grpc . StatusCode . ALREADY_EXISTS . name , \"Use instance( {} ).add_metadata(key, value) and del_metadata(key) \" \"to update the metadata\" . format ( name )) else : req = variables_pb2 . InstantiateVariableRequest ( variable_id = self . id , instance_name = name , instance_metadata = metadata ) self . instances [ name ] = Instance . from_pb ( self . client . InstantiateVariable ( req ) . instance ) return VariableInstance ( self , self . instances [ name ]) @utils . catch_rpc_error def delete_instances ( self , pattern = '' ): \"\"\" delete empty instances whose name match pattern (only * and ? are supported) \"\"\" pattern = re . escape ( pattern ) . replace ( \" \\\\ *\" , \".*\" ) . replace ( \" \\\\ ?\" , \".\" ) for instance in self . instances . values (): if re . match ( pattern , instance . name ): req = variables_pb2 . DeleteInstanceRequest ( id = instance . id ) self . client . DeleteInstance ( req ) @utils . catch_rpc_error def delete ( self ): self . delete_instances ( '' ) req = variables_pb2 . DeleteVariableRequest ( id = self . id ) self . client . DeleteVariable ( req ) def config_consolidation ( self , dformat : entities . DataFormat , exponent = 1. , compression : entities . Compression = entities . Compression . LOSSLESS , creation_params : Dict [ str , str ] = None , resampling_alg : entities . Resampling = entities . Resampling . near ): \"\"\" See entities.ConsolidationParams \"\"\" self . consolidation_params = entities . ConsolidationParams ( dformat = entities . DataFormat . from_user ( dformat ), exponent = exponent , compression = compression , creation_params = {} if creation_params is None else creation_params , resampling_alg = resampling_alg ) def __str__ ( self ): return \" {} \\n \" \\ \"Instances: {} \\n \" \\ . format ( _ProxyVariable . __str__ ( self ), self . instances ) config_consolidation ( dformat , exponent = 1.0 , compression = entities . Compression . LOSSLESS , creation_params = None , resampling_alg = entities . Resampling . near ) See entities.ConsolidationParams Source code in geocube/entities/variable.py 302 303 304 305 306 307 308 309 310 def config_consolidation ( self , dformat : entities . DataFormat , exponent = 1. , compression : entities . Compression = entities . Compression . LOSSLESS , creation_params : Dict [ str , str ] = None , resampling_alg : entities . Resampling = entities . Resampling . near ): \"\"\" See entities.ConsolidationParams \"\"\" self . consolidation_params = entities . ConsolidationParams ( dformat = entities . DataFormat . from_user ( dformat ), exponent = exponent , compression = compression , creation_params = {} if creation_params is None else creation_params , resampling_alg = resampling_alg ) delete_instances ( pattern = '' ) delete empty instances whose name match pattern (only * and ? are supported) Source code in geocube/entities/variable.py 287 288 289 290 291 292 293 294 @utils . catch_rpc_error def delete_instances ( self , pattern = '' ): \"\"\" delete empty instances whose name match pattern (only * and ? are supported) \"\"\" pattern = re . escape ( pattern ) . replace ( \" \\\\ *\" , \".*\" ) . replace ( \" \\\\ ?\" , \".\" ) for instance in self . instances . values (): if re . match ( pattern , instance . name ): req = variables_pb2 . DeleteInstanceRequest ( id = instance . id ) self . client . DeleteInstance ( req ) instance ( name = None ) Load the given instance Parameters: name ( Union [None, str ] , default: None ) \u2013 of the instance (or if None: the default instance if exists) Returns: VariableInstance \u2013 Specialization of the variable Source code in geocube/entities/variable.py 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 @utils . catch_rpc_error def instance ( self , name : Union [ None , str ] = None ) -> VariableInstance : \"\"\" Load the given instance Args: name: of the instance (or if None: the default instance if exists) Returns: Specialization of the variable \"\"\" if name is None : if len ( self . instances ) != 1 : raise utils . GeocubeError ( \"instance\" , grpc . StatusCode . NOT_FOUND . name , f \"Default instance does not exist for variable { self . variable_name } \" f \" (or more than one instance is defined).\" ) return VariableInstance ( self , next ( iter ( self . instances . values ()))) if name not in self . instances : raise utils . GeocubeError ( \"instance\" , grpc . StatusCode . NOT_FOUND . name , f \"Instance { name } does not exist for variable { self . variable_name } . \" f \"To instantiate a variable, use instantiate()\" ) return VariableInstance ( self , self . instances [ name ]) instantiate ( name , metadata ) Instantiate the variable (create a specialization) Args: name: of the instance metadata: of the instance (e.g. processing parameters, version...) can be empty Returns: VariableInstance \u2013 The specialization of this variable Source code in geocube/entities/variable.py 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 @utils . catch_rpc_error def instantiate ( self , name : str , metadata : Dict [ str , str ]) -> VariableInstance : \"\"\" Instantiate the variable (create a specialization) Args: name: of the instance metadata: of the instance (e.g. processing parameters, version...) can be empty Returns: The specialization of this variable \"\"\" if name in self . instances : if metadata is not None and self . instances [ name ] . metadata != metadata : raise utils . GeocubeError ( \"instantiate\" , grpc . StatusCode . ALREADY_EXISTS . name , \"Use instance( {} ).add_metadata(key, value) and del_metadata(key) \" \"to update the metadata\" . format ( name )) else : req = variables_pb2 . InstantiateVariableRequest ( variable_id = self . id , instance_name = name , instance_metadata = metadata ) self . instances [ name ] = Instance . from_pb ( self . client . InstantiateVariable ( req ) . instance ) return VariableInstance ( self , self . instances [ name ]) Instance Bases: _ProxyVariable , Instance VariableInstance is an instantiation of a Variable. It inherits from Variable (except for id() and name() that are replaced by variable_id() and variable_name() to prevent confusion with id and name of the instance) and from Instance (except for id() and name() that are replaced by instance_id() and instance_name()) Source code in geocube/entities/variable.py 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 class VariableInstance ( _ProxyVariable , Instance ): \"\"\" VariableInstance is an instantiation of a Variable. It inherits from Variable (except for id() and name() that are replaced by variable_id() and variable_name() to prevent confusion with id and name of the instance) and from Instance (except for id() and name() that are replaced by instance_id() and instance_name()) \"\"\" def __init__ ( self , variable : Variable , instance : Instance ): _ProxyVariable . __init__ ( self , variable . _variable ) self . _instance = instance @property def instance_id ( self ) -> str : return self . _instance . id @property def instance_name ( self ) -> str : return self . _instance . name @property def metadata ( self ) -> Dict [ str , str ]: return self . _instance . metadata @instance_name . setter @utils . catch_rpc_error def instance_name ( self , name ): if self . instance_name != name : req = variables_pb2 . UpdateInstanceRequest ( id = self . instance_id , name = utils . pb_string ( name )) self . client . UpdateInstance ( req ) self . _instance . name = name @utils . catch_rpc_error def add_metadata ( self , key : str , value : str ): if key not in self . metadata or self . metadata [ key ] != value : req = variables_pb2 . UpdateInstanceRequest ( id = self . instance_id , add_metadata = { key : value }) self . client . UpdateInstance ( req ) self . _instance . metadata [ key ] = value @utils . catch_rpc_error def del_metadata ( self , key : str ): if key in self . metadata : req = variables_pb2 . UpdateInstanceRequest ( id = self . instance_id , del_metadata_keys = [ key ]) self . client . UpdateInstance ( req ) del self . _instance . metadata [ key ] else : raise ValueError ( f \" { self . __repr__ () } : { key } does not exist in metadata\" ) def __repr__ ( self ): return \"VariableInstance {} : {} ( {} )\" . format ( self . variable_name , self . instance_name , self . instance_id ) def __str__ ( self ): return \" {} {} \" . format ( _ProxyVariable . __str__ ( self ), self . _instance . __str__ ())","title":"Variable"},{"location":"user-guide/entities/variable-reference/#variable-instance","text":"","title":"Variable &amp; Instance"},{"location":"user-guide/entities/variable-reference/#variable","text":"Bases: _ProxyVariable from geocube import Client client = Client('127.0.0.1:8080') vs = client.list_variables(\"test\") for v in vs: ... v.delete() profile = {'dformat': ('f8', -1, 0, 1), 'bands': ['R', 'G', 'B']} v = client.create_variable('test/vegetation/NDVI', **profile) v2 = client.variable('test/vegetation/NDVI') v.id==v2.id True vi = v.instance('master') v.description = \"normalize difference vegetation index \" vi.instance_metadata = {'version': 'v1'} vi2 = client.variable('test/vegetation/NDVI').instance('master') vi.id == vi2.id True Source code in geocube/entities/variable.py 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 class Variable ( _ProxyVariable ): \"\"\" >>> from geocube import Client >>> client = Client('127.0.0.1:8080') >>> vs = client.list_variables(\"test\") >>> for v in vs: ... v.delete() >>> profile = {'dformat': ('f8', -1, 0, 1), \\ 'bands': ['R', 'G', 'B']} >>> v = client.create_variable('test/vegetation/NDVI', **profile) >>> v2 = client.variable('test/vegetation/NDVI') >>> v.id==v2.id True >>> vi = v.instance('master') >>> v.description = \"normalize difference vegetation index \" >>> vi.instance_metadata = {'version': 'v1'} >>> vi2 = client.variable('test/vegetation/NDVI').instance('master') >>> vi.id == vi2.id True \"\"\" @classmethod def from_pb ( cls , stub : Stub , pb : variables_pb2 . Variable ): return cls ( _BaseVariable ( stub = stub , id = pb . id , name = pb . name , unit = pb . unit , description = pb . description , dformat = entities . DataFormat . from_pb ( pb . dformat ), bands = [ b for b in pb . bands ], palette = pb . palette , resampling_alg = entities . pb_resampling [ pb . resampling_alg ], ), { pbi . name : Instance . from_pb ( pbi ) for pbi in pb . instances }) def __init__ ( self , base_variable , instances = None ): super () . __init__ ( base_variable ) self . instances = instances if instances is not None else {} @property def id ( self ) -> str : return self . variable_id @property def name ( self ) -> str : return self . variable_name @utils . catch_rpc_error def instance ( self , name : Union [ None , str ] = None ) -> VariableInstance : \"\"\" Load the given instance Args: name: of the instance (or if None: the default instance if exists) Returns: Specialization of the variable \"\"\" if name is None : if len ( self . instances ) != 1 : raise utils . GeocubeError ( \"instance\" , grpc . StatusCode . NOT_FOUND . name , f \"Default instance does not exist for variable { self . variable_name } \" f \" (or more than one instance is defined).\" ) return VariableInstance ( self , next ( iter ( self . instances . values ()))) if name not in self . instances : raise utils . GeocubeError ( \"instance\" , grpc . StatusCode . NOT_FOUND . name , f \"Instance { name } does not exist for variable { self . variable_name } . \" f \"To instantiate a variable, use instantiate()\" ) return VariableInstance ( self , self . instances [ name ]) @utils . catch_rpc_error def instantiate ( self , name : str , metadata : Dict [ str , str ]) -> VariableInstance : \"\"\" Instantiate the variable (create a specialization) Args: name: of the instance metadata: of the instance (e.g. processing parameters, version...) can be empty Returns: The specialization of this variable \"\"\" if name in self . instances : if metadata is not None and self . instances [ name ] . metadata != metadata : raise utils . GeocubeError ( \"instantiate\" , grpc . StatusCode . ALREADY_EXISTS . name , \"Use instance( {} ).add_metadata(key, value) and del_metadata(key) \" \"to update the metadata\" . format ( name )) else : req = variables_pb2 . InstantiateVariableRequest ( variable_id = self . id , instance_name = name , instance_metadata = metadata ) self . instances [ name ] = Instance . from_pb ( self . client . InstantiateVariable ( req ) . instance ) return VariableInstance ( self , self . instances [ name ]) @utils . catch_rpc_error def delete_instances ( self , pattern = '' ): \"\"\" delete empty instances whose name match pattern (only * and ? are supported) \"\"\" pattern = re . escape ( pattern ) . replace ( \" \\\\ *\" , \".*\" ) . replace ( \" \\\\ ?\" , \".\" ) for instance in self . instances . values (): if re . match ( pattern , instance . name ): req = variables_pb2 . DeleteInstanceRequest ( id = instance . id ) self . client . DeleteInstance ( req ) @utils . catch_rpc_error def delete ( self ): self . delete_instances ( '' ) req = variables_pb2 . DeleteVariableRequest ( id = self . id ) self . client . DeleteVariable ( req ) def config_consolidation ( self , dformat : entities . DataFormat , exponent = 1. , compression : entities . Compression = entities . Compression . LOSSLESS , creation_params : Dict [ str , str ] = None , resampling_alg : entities . Resampling = entities . Resampling . near ): \"\"\" See entities.ConsolidationParams \"\"\" self . consolidation_params = entities . ConsolidationParams ( dformat = entities . DataFormat . from_user ( dformat ), exponent = exponent , compression = compression , creation_params = {} if creation_params is None else creation_params , resampling_alg = resampling_alg ) def __str__ ( self ): return \" {} \\n \" \\ \"Instances: {} \\n \" \\ . format ( _ProxyVariable . __str__ ( self ), self . instances )","title":"Variable"},{"location":"user-guide/entities/variable-reference/#geocube.entities.Variable.config_consolidation","text":"See entities.ConsolidationParams Source code in geocube/entities/variable.py 302 303 304 305 306 307 308 309 310 def config_consolidation ( self , dformat : entities . DataFormat , exponent = 1. , compression : entities . Compression = entities . Compression . LOSSLESS , creation_params : Dict [ str , str ] = None , resampling_alg : entities . Resampling = entities . Resampling . near ): \"\"\" See entities.ConsolidationParams \"\"\" self . consolidation_params = entities . ConsolidationParams ( dformat = entities . DataFormat . from_user ( dformat ), exponent = exponent , compression = compression , creation_params = {} if creation_params is None else creation_params , resampling_alg = resampling_alg )","title":"config_consolidation"},{"location":"user-guide/entities/variable-reference/#geocube.entities.Variable.delete_instances","text":"delete empty instances whose name match pattern (only * and ? are supported) Source code in geocube/entities/variable.py 287 288 289 290 291 292 293 294 @utils . catch_rpc_error def delete_instances ( self , pattern = '' ): \"\"\" delete empty instances whose name match pattern (only * and ? are supported) \"\"\" pattern = re . escape ( pattern ) . replace ( \" \\\\ *\" , \".*\" ) . replace ( \" \\\\ ?\" , \".\" ) for instance in self . instances . values (): if re . match ( pattern , instance . name ): req = variables_pb2 . DeleteInstanceRequest ( id = instance . id ) self . client . DeleteInstance ( req )","title":"delete_instances"},{"location":"user-guide/entities/variable-reference/#geocube.entities.Variable.instance","text":"Load the given instance Parameters: name ( Union [None, str ] , default: None ) \u2013 of the instance (or if None: the default instance if exists) Returns: VariableInstance \u2013 Specialization of the variable Source code in geocube/entities/variable.py 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 @utils . catch_rpc_error def instance ( self , name : Union [ None , str ] = None ) -> VariableInstance : \"\"\" Load the given instance Args: name: of the instance (or if None: the default instance if exists) Returns: Specialization of the variable \"\"\" if name is None : if len ( self . instances ) != 1 : raise utils . GeocubeError ( \"instance\" , grpc . StatusCode . NOT_FOUND . name , f \"Default instance does not exist for variable { self . variable_name } \" f \" (or more than one instance is defined).\" ) return VariableInstance ( self , next ( iter ( self . instances . values ()))) if name not in self . instances : raise utils . GeocubeError ( \"instance\" , grpc . StatusCode . NOT_FOUND . name , f \"Instance { name } does not exist for variable { self . variable_name } . \" f \"To instantiate a variable, use instantiate()\" ) return VariableInstance ( self , self . instances [ name ])","title":"instance"},{"location":"user-guide/entities/variable-reference/#geocube.entities.Variable.instantiate","text":"Instantiate the variable (create a specialization) Args: name: of the instance metadata: of the instance (e.g. processing parameters, version...) can be empty Returns: VariableInstance \u2013 The specialization of this variable Source code in geocube/entities/variable.py 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 @utils . catch_rpc_error def instantiate ( self , name : str , metadata : Dict [ str , str ]) -> VariableInstance : \"\"\" Instantiate the variable (create a specialization) Args: name: of the instance metadata: of the instance (e.g. processing parameters, version...) can be empty Returns: The specialization of this variable \"\"\" if name in self . instances : if metadata is not None and self . instances [ name ] . metadata != metadata : raise utils . GeocubeError ( \"instantiate\" , grpc . StatusCode . ALREADY_EXISTS . name , \"Use instance( {} ).add_metadata(key, value) and del_metadata(key) \" \"to update the metadata\" . format ( name )) else : req = variables_pb2 . InstantiateVariableRequest ( variable_id = self . id , instance_name = name , instance_metadata = metadata ) self . instances [ name ] = Instance . from_pb ( self . client . InstantiateVariable ( req ) . instance ) return VariableInstance ( self , self . instances [ name ])","title":"instantiate"},{"location":"user-guide/entities/variable-reference/#instance","text":"Bases: _ProxyVariable , Instance VariableInstance is an instantiation of a Variable. It inherits from Variable (except for id() and name() that are replaced by variable_id() and variable_name() to prevent confusion with id and name of the instance) and from Instance (except for id() and name() that are replaced by instance_id() and instance_name()) Source code in geocube/entities/variable.py 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 class VariableInstance ( _ProxyVariable , Instance ): \"\"\" VariableInstance is an instantiation of a Variable. It inherits from Variable (except for id() and name() that are replaced by variable_id() and variable_name() to prevent confusion with id and name of the instance) and from Instance (except for id() and name() that are replaced by instance_id() and instance_name()) \"\"\" def __init__ ( self , variable : Variable , instance : Instance ): _ProxyVariable . __init__ ( self , variable . _variable ) self . _instance = instance @property def instance_id ( self ) -> str : return self . _instance . id @property def instance_name ( self ) -> str : return self . _instance . name @property def metadata ( self ) -> Dict [ str , str ]: return self . _instance . metadata @instance_name . setter @utils . catch_rpc_error def instance_name ( self , name ): if self . instance_name != name : req = variables_pb2 . UpdateInstanceRequest ( id = self . instance_id , name = utils . pb_string ( name )) self . client . UpdateInstance ( req ) self . _instance . name = name @utils . catch_rpc_error def add_metadata ( self , key : str , value : str ): if key not in self . metadata or self . metadata [ key ] != value : req = variables_pb2 . UpdateInstanceRequest ( id = self . instance_id , add_metadata = { key : value }) self . client . UpdateInstance ( req ) self . _instance . metadata [ key ] = value @utils . catch_rpc_error def del_metadata ( self , key : str ): if key in self . metadata : req = variables_pb2 . UpdateInstanceRequest ( id = self . instance_id , del_metadata_keys = [ key ]) self . client . UpdateInstance ( req ) del self . _instance . metadata [ key ] else : raise ValueError ( f \" { self . __repr__ () } : { key } does not exist in metadata\" ) def __repr__ ( self ): return \"VariableInstance {} : {} ( {} )\" . format ( self . variable_name , self . instance_name , self . instance_id ) def __str__ ( self ): return \" {} {} \" . format ( _ProxyVariable . __str__ ( self ), self . _instance . __str__ ())","title":"Instance"},{"location":"user-guide/getcube/cubemetadata-reference/","text":"Cube Metadata Source code in geocube/entities/cube_metadata.py 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 @dataclass class CubeMetadata : slices : List [ SliceMetadata ] crs : str transform : affine . Affine shape : Tuple [ int , int ] dformat : entities . DataFormat resampling_alg : entities . Resampling @classmethod def from_pb ( cls , pb : catalog_pb2 . GetCubeResponseHeader ): return cls ( slices = [], crs = pb . crs , transform = affine . Affine . from_gdal ( pb . geotransform . a , pb . geotransform . b , pb . geotransform . c , pb . geotransform . d , pb . geotransform . e , pb . geotransform . f , ), shape = ( 0 , 0 ), dformat = entities . DataFormat . from_pb ( pb . ref_dformat ), resampling_alg = entities . pb_resampling [ pb . resampling_alg ] ) def info ( self , verbose = True ): files = set () datasets = 0 for s in self . slices : files = files . union ( s . containers ) datasets += len ( s . metadata ) containers = len ( files ) images = len ( self . slices ) temporal_fragmentation = 0 if images <= 1 else ( containers - 1 ) / ( datasets - 1 ) spatial_fragmentation = 0 if datasets <= 1 else 1 - images / datasets if verbose : print ( f \" { datasets } dataset(s) in { containers } container(s) for { images } image(s) \\n \" f \" - temporal fragmentation: { 100 * temporal_fragmentation : .0f } % \\n \" f \" - spatial fragmentation: { 100 * spatial_fragmentation : .0f } % \\n \" ) return { \"datasets\" : datasets , \"containers\" : containers , \"images\" : images , \"temporal_fragmentation\" : temporal_fragmentation , \"spatial_fragmentation\" : spatial_fragmentation }","title":"CubeMetadata"},{"location":"user-guide/getcube/cubemetadata-reference/#cube-metadata","text":"Source code in geocube/entities/cube_metadata.py 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 @dataclass class CubeMetadata : slices : List [ SliceMetadata ] crs : str transform : affine . Affine shape : Tuple [ int , int ] dformat : entities . DataFormat resampling_alg : entities . Resampling @classmethod def from_pb ( cls , pb : catalog_pb2 . GetCubeResponseHeader ): return cls ( slices = [], crs = pb . crs , transform = affine . Affine . from_gdal ( pb . geotransform . a , pb . geotransform . b , pb . geotransform . c , pb . geotransform . d , pb . geotransform . e , pb . geotransform . f , ), shape = ( 0 , 0 ), dformat = entities . DataFormat . from_pb ( pb . ref_dformat ), resampling_alg = entities . pb_resampling [ pb . resampling_alg ] ) def info ( self , verbose = True ): files = set () datasets = 0 for s in self . slices : files = files . union ( s . containers ) datasets += len ( s . metadata ) containers = len ( files ) images = len ( self . slices ) temporal_fragmentation = 0 if images <= 1 else ( containers - 1 ) / ( datasets - 1 ) spatial_fragmentation = 0 if datasets <= 1 else 1 - images / datasets if verbose : print ( f \" { datasets } dataset(s) in { containers } container(s) for { images } image(s) \\n \" f \" - temporal fragmentation: { 100 * temporal_fragmentation : .0f } % \\n \" f \" - spatial fragmentation: { 100 * spatial_fragmentation : .0f } % \\n \" ) return { \"datasets\" : datasets , \"containers\" : containers , \"images\" : images , \"temporal_fragmentation\" : temporal_fragmentation , \"spatial_fragmentation\" : spatial_fragmentation }","title":"Cube Metadata"},{"location":"user-guide/getcube/cubeparams-reference/","text":"Cube parameters Source code in geocube/entities/cube_params.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 @dataclass class CubeParams : _instance_id : str _records_id : Union [ List [ entities . GroupedRecordIds ], None ] tile : entities . Tile tags : Union [ Dict [ str , str ], None ] from_time : Union [ datetime , None ] to_time : Union [ datetime , None ] @classmethod def from_tags ( cls , crs : str , transform : Union [ affine . Affine , Tuple6Float ], shape : Tuple [ int , int ], instance : Union [ str , entities . VariableInstance , None ], tags : Dict [ str , str ], from_time : datetime = None , to_time : datetime = None ) -> entities . CubeParams : \"\"\" Create a set of parameters to get a cube from record tags Args: crs: of the output images (images will be reprojected on the fly if necessary) transform: of the requested cube (images will be rescaled on the fly if necessary) shape: of the requested cube (@warning shape is the transpose of numpy shape) instance: of the requested data tags: of the records to be requested from_time: (optional) to filter the records to_time: (optional) to filter the records Returns: A CubeParams to be passed as a parameter of a get_cube request \"\"\" return cls . from_tile ( entities . Tile . from_geotransform ( transform , crs , shape ), instance , tags = tags , from_time = from_time , to_time = to_time ) @classmethod def from_records ( cls , records : List [ entities . RecordIdentifiers ], crs : str , transform : Union [ affine . Affine , Tuple6Float ], shape : Tuple [ int , int ], instance : Union [ str , entities . VariableInstance , None ]) -> entities . CubeParams : \"\"\" Create a set of parameters to get a cube from a list of records Args: crs: of the output images (images will be reprojected on the fly if necessary) transform: of the requested cube (images will be rescaled on the fly if necessary) shape: of the requested cube (@warning shape is the transpose of numpy shape) instance: of the requested data records: to be retrieved Returns: A CubeParams to be passed as a parameter of a get_cube request \"\"\" return cls . from_tile ( entities . Tile . from_geotransform ( transform , crs , shape ), instance , records = records ) @classmethod def from_tile ( cls , tile : entities . Tile , instance : Union [ str , entities . VariableInstance , None ], records : List [ entities . RecordIdentifiers ] = None , tags : Dict [ str , str ] = None , from_time : datetime = None , to_time : datetime = None ) \\ -> entities . CubeParams : \"\"\" Args: tile: defining the Cube to be retrieved (images will be reprojected on the fly if necessary) instance: of the requested data records: (optional) to be retrieved tags: of the records to be requested from_time: (optional) to filter the records to_time: (optional) to filter the records Returns: A CubeParams to be passed as a parameter of a get_cube request \"\"\" return cls ( tile = tile , _instance_id = entities . get_id ( instance ) if instance else None , _records_id = CubeParams . _parse_grouped_record_ids ( records ), tags = tags , from_time = from_time , to_time = to_time ) @property def crs ( self ) -> str : return self . tile . crs @property def transform ( self ) -> affine . Affine : return self . tile . transform @property def shape ( self ) -> Tuple [ int , int ]: return self . tile . shape @property def records ( self ) -> List [ entities . GroupedRecordIds ]: return self . _records_id @records . setter def records ( self , records : List [ entities . RecordIdentifiers ]): self . _records_id = CubeParams . _parse_grouped_record_ids ( records ) @property def instance ( self ) -> str : return self . _instance_id @instance . setter def instance ( self , instance : Union [ str , entities . VariableInstance ]): self . _instance_id = entities . get_id ( instance ) @staticmethod def _parse_grouped_record_ids ( records : List [ entities . RecordIdentifiers ]) \\ -> Union [ List [ entities . GroupedRecordIds ], None ]: return [ CubeParams . _parse_record_ids ( rs ) for rs in records ] if records is not None else None @staticmethod def _parse_record_ids ( records : entities . RecordIdentifiers ) -> List [ str ]: if isinstance ( records , gpd . GeoDataFrame ): return list ( records [ 'id' ]) return entities . get_ids ( records ) from_records ( records , crs , transform , shape , instance ) classmethod Create a set of parameters to get a cube from a list of records Parameters: crs ( str ) \u2013 of the output images (images will be reprojected on the fly if necessary) transform ( Union [ Affine , Tuple6Float ] ) \u2013 of the requested cube (images will be rescaled on the fly if necessary) shape ( Tuple [ int , int ] ) \u2013 of the requested cube (@warning shape is the transpose of numpy shape) instance ( Union [ str , VariableInstance , None] ) \u2013 of the requested data records ( List [ RecordIdentifiers ] ) \u2013 to be retrieved Returns: CubeParams \u2013 A CubeParams to be passed as a parameter of a get_cube request Source code in geocube/entities/cube_params.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 @classmethod def from_records ( cls , records : List [ entities . RecordIdentifiers ], crs : str , transform : Union [ affine . Affine , Tuple6Float ], shape : Tuple [ int , int ], instance : Union [ str , entities . VariableInstance , None ]) -> entities . CubeParams : \"\"\" Create a set of parameters to get a cube from a list of records Args: crs: of the output images (images will be reprojected on the fly if necessary) transform: of the requested cube (images will be rescaled on the fly if necessary) shape: of the requested cube (@warning shape is the transpose of numpy shape) instance: of the requested data records: to be retrieved Returns: A CubeParams to be passed as a parameter of a get_cube request \"\"\" return cls . from_tile ( entities . Tile . from_geotransform ( transform , crs , shape ), instance , records = records ) from_tags ( crs , transform , shape , instance , tags , from_time = None , to_time = None ) classmethod Create a set of parameters to get a cube from record tags Parameters: crs ( str ) \u2013 of the output images (images will be reprojected on the fly if necessary) transform ( Union [ Affine , Tuple6Float ] ) \u2013 of the requested cube (images will be rescaled on the fly if necessary) shape ( Tuple [ int , int ] ) \u2013 of the requested cube (@warning shape is the transpose of numpy shape) instance ( Union [ str , VariableInstance , None] ) \u2013 of the requested data tags ( Dict [ str , str ] ) \u2013 of the records to be requested from_time ( datetime , default: None ) \u2013 (optional) to filter the records to_time ( datetime , default: None ) \u2013 (optional) to filter the records Returns: CubeParams \u2013 A CubeParams to be passed as a parameter of a get_cube request Source code in geocube/entities/cube_params.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 @classmethod def from_tags ( cls , crs : str , transform : Union [ affine . Affine , Tuple6Float ], shape : Tuple [ int , int ], instance : Union [ str , entities . VariableInstance , None ], tags : Dict [ str , str ], from_time : datetime = None , to_time : datetime = None ) -> entities . CubeParams : \"\"\" Create a set of parameters to get a cube from record tags Args: crs: of the output images (images will be reprojected on the fly if necessary) transform: of the requested cube (images will be rescaled on the fly if necessary) shape: of the requested cube (@warning shape is the transpose of numpy shape) instance: of the requested data tags: of the records to be requested from_time: (optional) to filter the records to_time: (optional) to filter the records Returns: A CubeParams to be passed as a parameter of a get_cube request \"\"\" return cls . from_tile ( entities . Tile . from_geotransform ( transform , crs , shape ), instance , tags = tags , from_time = from_time , to_time = to_time ) from_tile ( tile , instance , records = None , tags = None , from_time = None , to_time = None ) classmethod Parameters: tile ( Tile ) \u2013 defining the Cube to be retrieved (images will be reprojected on the fly if necessary) instance ( Union [ str , VariableInstance , None] ) \u2013 of the requested data records ( List [ RecordIdentifiers ] , default: None ) \u2013 (optional) to be retrieved tags ( Dict [ str , str ] , default: None ) \u2013 of the records to be requested from_time ( datetime , default: None ) \u2013 (optional) to filter the records to_time ( datetime , default: None ) \u2013 (optional) to filter the records Returns: CubeParams \u2013 A CubeParams to be passed as a parameter of a get_cube request Source code in geocube/entities/cube_params.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 @classmethod def from_tile ( cls , tile : entities . Tile , instance : Union [ str , entities . VariableInstance , None ], records : List [ entities . RecordIdentifiers ] = None , tags : Dict [ str , str ] = None , from_time : datetime = None , to_time : datetime = None ) \\ -> entities . CubeParams : \"\"\" Args: tile: defining the Cube to be retrieved (images will be reprojected on the fly if necessary) instance: of the requested data records: (optional) to be retrieved tags: of the records to be requested from_time: (optional) to filter the records to_time: (optional) to filter the records Returns: A CubeParams to be passed as a parameter of a get_cube request \"\"\" return cls ( tile = tile , _instance_id = entities . get_id ( instance ) if instance else None , _records_id = CubeParams . _parse_grouped_record_ids ( records ), tags = tags , from_time = from_time , to_time = to_time )","title":"CubeParams"},{"location":"user-guide/getcube/cubeparams-reference/#cube-parameters","text":"Source code in geocube/entities/cube_params.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 @dataclass class CubeParams : _instance_id : str _records_id : Union [ List [ entities . GroupedRecordIds ], None ] tile : entities . Tile tags : Union [ Dict [ str , str ], None ] from_time : Union [ datetime , None ] to_time : Union [ datetime , None ] @classmethod def from_tags ( cls , crs : str , transform : Union [ affine . Affine , Tuple6Float ], shape : Tuple [ int , int ], instance : Union [ str , entities . VariableInstance , None ], tags : Dict [ str , str ], from_time : datetime = None , to_time : datetime = None ) -> entities . CubeParams : \"\"\" Create a set of parameters to get a cube from record tags Args: crs: of the output images (images will be reprojected on the fly if necessary) transform: of the requested cube (images will be rescaled on the fly if necessary) shape: of the requested cube (@warning shape is the transpose of numpy shape) instance: of the requested data tags: of the records to be requested from_time: (optional) to filter the records to_time: (optional) to filter the records Returns: A CubeParams to be passed as a parameter of a get_cube request \"\"\" return cls . from_tile ( entities . Tile . from_geotransform ( transform , crs , shape ), instance , tags = tags , from_time = from_time , to_time = to_time ) @classmethod def from_records ( cls , records : List [ entities . RecordIdentifiers ], crs : str , transform : Union [ affine . Affine , Tuple6Float ], shape : Tuple [ int , int ], instance : Union [ str , entities . VariableInstance , None ]) -> entities . CubeParams : \"\"\" Create a set of parameters to get a cube from a list of records Args: crs: of the output images (images will be reprojected on the fly if necessary) transform: of the requested cube (images will be rescaled on the fly if necessary) shape: of the requested cube (@warning shape is the transpose of numpy shape) instance: of the requested data records: to be retrieved Returns: A CubeParams to be passed as a parameter of a get_cube request \"\"\" return cls . from_tile ( entities . Tile . from_geotransform ( transform , crs , shape ), instance , records = records ) @classmethod def from_tile ( cls , tile : entities . Tile , instance : Union [ str , entities . VariableInstance , None ], records : List [ entities . RecordIdentifiers ] = None , tags : Dict [ str , str ] = None , from_time : datetime = None , to_time : datetime = None ) \\ -> entities . CubeParams : \"\"\" Args: tile: defining the Cube to be retrieved (images will be reprojected on the fly if necessary) instance: of the requested data records: (optional) to be retrieved tags: of the records to be requested from_time: (optional) to filter the records to_time: (optional) to filter the records Returns: A CubeParams to be passed as a parameter of a get_cube request \"\"\" return cls ( tile = tile , _instance_id = entities . get_id ( instance ) if instance else None , _records_id = CubeParams . _parse_grouped_record_ids ( records ), tags = tags , from_time = from_time , to_time = to_time ) @property def crs ( self ) -> str : return self . tile . crs @property def transform ( self ) -> affine . Affine : return self . tile . transform @property def shape ( self ) -> Tuple [ int , int ]: return self . tile . shape @property def records ( self ) -> List [ entities . GroupedRecordIds ]: return self . _records_id @records . setter def records ( self , records : List [ entities . RecordIdentifiers ]): self . _records_id = CubeParams . _parse_grouped_record_ids ( records ) @property def instance ( self ) -> str : return self . _instance_id @instance . setter def instance ( self , instance : Union [ str , entities . VariableInstance ]): self . _instance_id = entities . get_id ( instance ) @staticmethod def _parse_grouped_record_ids ( records : List [ entities . RecordIdentifiers ]) \\ -> Union [ List [ entities . GroupedRecordIds ], None ]: return [ CubeParams . _parse_record_ids ( rs ) for rs in records ] if records is not None else None @staticmethod def _parse_record_ids ( records : entities . RecordIdentifiers ) -> List [ str ]: if isinstance ( records , gpd . GeoDataFrame ): return list ( records [ 'id' ]) return entities . get_ids ( records )","title":"Cube parameters"},{"location":"user-guide/getcube/cubeparams-reference/#geocube.entities.CubeParams.from_records","text":"Create a set of parameters to get a cube from a list of records Parameters: crs ( str ) \u2013 of the output images (images will be reprojected on the fly if necessary) transform ( Union [ Affine , Tuple6Float ] ) \u2013 of the requested cube (images will be rescaled on the fly if necessary) shape ( Tuple [ int , int ] ) \u2013 of the requested cube (@warning shape is the transpose of numpy shape) instance ( Union [ str , VariableInstance , None] ) \u2013 of the requested data records ( List [ RecordIdentifiers ] ) \u2013 to be retrieved Returns: CubeParams \u2013 A CubeParams to be passed as a parameter of a get_cube request Source code in geocube/entities/cube_params.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 @classmethod def from_records ( cls , records : List [ entities . RecordIdentifiers ], crs : str , transform : Union [ affine . Affine , Tuple6Float ], shape : Tuple [ int , int ], instance : Union [ str , entities . VariableInstance , None ]) -> entities . CubeParams : \"\"\" Create a set of parameters to get a cube from a list of records Args: crs: of the output images (images will be reprojected on the fly if necessary) transform: of the requested cube (images will be rescaled on the fly if necessary) shape: of the requested cube (@warning shape is the transpose of numpy shape) instance: of the requested data records: to be retrieved Returns: A CubeParams to be passed as a parameter of a get_cube request \"\"\" return cls . from_tile ( entities . Tile . from_geotransform ( transform , crs , shape ), instance , records = records )","title":"from_records"},{"location":"user-guide/getcube/cubeparams-reference/#geocube.entities.CubeParams.from_tags","text":"Create a set of parameters to get a cube from record tags Parameters: crs ( str ) \u2013 of the output images (images will be reprojected on the fly if necessary) transform ( Union [ Affine , Tuple6Float ] ) \u2013 of the requested cube (images will be rescaled on the fly if necessary) shape ( Tuple [ int , int ] ) \u2013 of the requested cube (@warning shape is the transpose of numpy shape) instance ( Union [ str , VariableInstance , None] ) \u2013 of the requested data tags ( Dict [ str , str ] ) \u2013 of the records to be requested from_time ( datetime , default: None ) \u2013 (optional) to filter the records to_time ( datetime , default: None ) \u2013 (optional) to filter the records Returns: CubeParams \u2013 A CubeParams to be passed as a parameter of a get_cube request Source code in geocube/entities/cube_params.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 @classmethod def from_tags ( cls , crs : str , transform : Union [ affine . Affine , Tuple6Float ], shape : Tuple [ int , int ], instance : Union [ str , entities . VariableInstance , None ], tags : Dict [ str , str ], from_time : datetime = None , to_time : datetime = None ) -> entities . CubeParams : \"\"\" Create a set of parameters to get a cube from record tags Args: crs: of the output images (images will be reprojected on the fly if necessary) transform: of the requested cube (images will be rescaled on the fly if necessary) shape: of the requested cube (@warning shape is the transpose of numpy shape) instance: of the requested data tags: of the records to be requested from_time: (optional) to filter the records to_time: (optional) to filter the records Returns: A CubeParams to be passed as a parameter of a get_cube request \"\"\" return cls . from_tile ( entities . Tile . from_geotransform ( transform , crs , shape ), instance , tags = tags , from_time = from_time , to_time = to_time )","title":"from_tags"},{"location":"user-guide/getcube/cubeparams-reference/#geocube.entities.CubeParams.from_tile","text":"Parameters: tile ( Tile ) \u2013 defining the Cube to be retrieved (images will be reprojected on the fly if necessary) instance ( Union [ str , VariableInstance , None] ) \u2013 of the requested data records ( List [ RecordIdentifiers ] , default: None ) \u2013 (optional) to be retrieved tags ( Dict [ str , str ] , default: None ) \u2013 of the records to be requested from_time ( datetime , default: None ) \u2013 (optional) to filter the records to_time ( datetime , default: None ) \u2013 (optional) to filter the records Returns: CubeParams \u2013 A CubeParams to be passed as a parameter of a get_cube request Source code in geocube/entities/cube_params.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 @classmethod def from_tile ( cls , tile : entities . Tile , instance : Union [ str , entities . VariableInstance , None ], records : List [ entities . RecordIdentifiers ] = None , tags : Dict [ str , str ] = None , from_time : datetime = None , to_time : datetime = None ) \\ -> entities . CubeParams : \"\"\" Args: tile: defining the Cube to be retrieved (images will be reprojected on the fly if necessary) instance: of the requested data records: (optional) to be retrieved tags: of the records to be requested from_time: (optional) to filter the records to_time: (optional) to filter the records Returns: A CubeParams to be passed as a parameter of a get_cube request \"\"\" return cls ( tile = tile , _instance_id = entities . get_id ( instance ) if instance else None , _records_id = CubeParams . _parse_grouped_record_ids ( records ), tags = tags , from_time = from_time , to_time = to_time )","title":"from_tile"},{"location":"user-guide/getcube/tile-reference/","text":"Tile Source code in geocube/entities/tile.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 @dataclass class Tile : crs : str transform : affine . Affine # Pixel to crs shape : Tuple [ int , int ] @classmethod def from_pb ( cls , pb : layouts_pb2 . Tile ): return cls ( pb . crs , affine . Affine ( pb . transform . b , pb . transform . c , pb . transform . a , pb . transform . e , pb . transform . f , pb . transform . d ), shape = ( int ( pb . size_px . width ), int ( pb . size_px . height )) ) @classmethod def from_geotransform ( cls , transform : Union [ affine . Affine , Tuple [ float , float , float , float , float , float ]], crs : Union [ str , int ], shape : Tuple [ int , int ]) -> Tile : \"\"\" Create a tile from a geotransform, a crs and a shape Args: transform: geotransform from pixel coordinates to CRS. crs: Coordinate Reference System of the tile shape: shape of the tile (in pixel) (@warning shape is the transpose of numpy shape) Returns: A new tile \"\"\" return cls ( crs_to_str ( crs ), Tile . _parse_geotransform ( transform ), shape ) @classmethod def from_record ( cls , record : entities . Record , crs : Union [ str , int ], resolution : float ) -> Tile : \"\"\" Create a tile that cover the record in the crs at a given resolution Warning: record.aoi must be loaded (with client.load_aoi()) Warning: Check the `result.shape` as the size might be huge ! Warning: the aoi is converted to the crs, but it might be imprecise at the borders Args: record: crs: Coordinate Reference System of the tile resolution: resolution of the pixel in the CRS Returns: A new tile \"\"\" return Tile . from_aoi ( record . aoi , crs , resolution ) @classmethod def from_bbox ( cls , bbox : Tuple [ float , float , float , float ], crs : Union [ str , int ], resolution : Union [ float , Tuple [ float , float ]]) -> Tile : \"\"\" Create a tile from a bbox, a crs and a resolution Args: bbox : (x1, y1, x2, y2) in crs coordinates crs : (Coordinate Reference System) of the tile resolution : of the pixel in the CRS Returns: A new tile \"\"\" rx , ry = resolution if isinstance ( resolution , tuple ) else ( resolution , - resolution ) x1 , y1 , x2 , y2 = bbox if math . copysign ( 1 , rx ) * ( x2 - x1 ) < 0 : x1 , x2 = x2 , x1 if math . copysign ( 1 , ry ) * ( y2 - y1 ) < 0 : y1 , y2 = y2 , y1 transform = geo_transform ( x1 , y1 , resolution ) sx , sy = ( ~ transform ) * ( x2 , y2 ) return cls ( crs_to_str ( crs ), transform , ( math . ceil ( sx ), math . ceil ( sy ))) @classmethod def from_aoi ( cls , aoi : geometry . MultiPolygon , crs : Union [ str , int ], resolution : Union [ float , Tuple [ float , float ]]) -> Tile : \"\"\" Args: aoi : multipolygon in 4326 coordinates crs : (Coordinate Reference System) of the tile resolution : of the pixel in the CRS Returns: A new tile \"\"\" return Tile . from_bbox ( gpd . GeoSeries ( aoi , crs = 4326 ) . to_crs ( crs ) . total_bounds , crs = crs , resolution = resolution ) def __str__ ( self ): return \"Tile {} \\n \" \\ \" transform: ( {} , {} {} , {} , {} {} ) \\n \" \\ \" bounds: {} {} \\n \" \\ \" shape: {} \\n \" \\ \" crs: {} \\n \" . format ( self . shape , self . transform . c , self . transform . a , self . transform . b , self . transform . f , self . transform . d , self . transform . e , self . transform * ( 0 , 0 ), self . transform * self . shape , self . shape , self . crs ) def __repr__ ( self ): return self . __str__ () def geoseries ( self ) -> gpd . GeoSeries : x1 , y1 = self . transform * ( 0 , 0 ) x2 , y2 = self . transform * self . shape p = geometry . Polygon ([[ x1 , y1 ], [ x1 , y2 ], [ x2 , y2 ], [ x2 , y1 ], [ x1 , y1 ]]) return gpd . GeoSeries ( p , crs = self . crs ) def geometry ( self , to_crs : Union [ str , int ] = None ): gs = self . geoseries () if to_crs is not None : gs = gs . to_crs ( crs_to_str ( to_crs )) return gs . iloc [ 0 ] def reshape ( self , i1 , j1 , i2 , j2 ) -> entities . Tile : \"\"\" Create a new Tile using the coordinate pixels @warning inverse of numpy coordinates \"\"\" return Tile . from_bbox ( self . transform * ( i1 , j1 ) + self . transform * ( i2 , j2 ), self . crs , resolution = ( self . transform . a , self . transform . e )) @staticmethod def _parse_geotransform ( transform : Union [ affine . Affine , Tuple [ float , float , float , float , float , float ]]) \\ -> affine . Affine : if isinstance ( transform , affine . Affine ): return transform return affine . Affine . from_gdal ( * transform ) @staticmethod def to_geoseries ( tiles : List [ Tile ]): \"\"\" return list of Tiles as geoseries \"\"\" return gpd . GeoSeries ( pd . concat ([ t . geoseries () . to_crs ( \"epsg:4326\" ) for t in tiles ])) @staticmethod def plot ( tiles : List [ Tile ], ** kwargs ): \"\"\" kwargs: additional arguments for utils.plot_aoi \"\"\" return utils . plot_aoi ( Tile . to_geoseries ( tiles ), ** kwargs ) from_aoi ( aoi , crs , resolution ) classmethod Parameters: aoi \u2013 multipolygon in 4326 coordinates crs \u2013 (Coordinate Reference System) of the tile resolution \u2013 of the pixel in the CRS Returns: Tile \u2013 A new tile Source code in geocube/entities/tile.py 105 106 107 108 109 110 111 112 113 114 115 116 117 118 @classmethod def from_aoi ( cls , aoi : geometry . MultiPolygon , crs : Union [ str , int ], resolution : Union [ float , Tuple [ float , float ]]) -> Tile : \"\"\" Args: aoi : multipolygon in 4326 coordinates crs : (Coordinate Reference System) of the tile resolution : of the pixel in the CRS Returns: A new tile \"\"\" return Tile . from_bbox ( gpd . GeoSeries ( aoi , crs = 4326 ) . to_crs ( crs ) . total_bounds , crs = crs , resolution = resolution ) from_bbox ( bbox , crs , resolution ) classmethod Create a tile from a bbox, a crs and a resolution Args: bbox : (x1, y1, x2, y2) in crs coordinates crs : (Coordinate Reference System) of the tile resolution : of the pixel in the CRS Returns: Tile \u2013 A new tile Source code in geocube/entities/tile.py 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 @classmethod def from_bbox ( cls , bbox : Tuple [ float , float , float , float ], crs : Union [ str , int ], resolution : Union [ float , Tuple [ float , float ]]) -> Tile : \"\"\" Create a tile from a bbox, a crs and a resolution Args: bbox : (x1, y1, x2, y2) in crs coordinates crs : (Coordinate Reference System) of the tile resolution : of the pixel in the CRS Returns: A new tile \"\"\" rx , ry = resolution if isinstance ( resolution , tuple ) else ( resolution , - resolution ) x1 , y1 , x2 , y2 = bbox if math . copysign ( 1 , rx ) * ( x2 - x1 ) < 0 : x1 , x2 = x2 , x1 if math . copysign ( 1 , ry ) * ( y2 - y1 ) < 0 : y1 , y2 = y2 , y1 transform = geo_transform ( x1 , y1 , resolution ) sx , sy = ( ~ transform ) * ( x2 , y2 ) return cls ( crs_to_str ( crs ), transform , ( math . ceil ( sx ), math . ceil ( sy ))) from_geotransform ( transform , crs , shape ) classmethod Create a tile from a geotransform, a crs and a shape Args: transform: geotransform from pixel coordinates to CRS. crs: Coordinate Reference System of the tile shape: shape of the tile (in pixel) (@warning shape is the transpose of numpy shape) Returns: Tile \u2013 A new tile Source code in geocube/entities/tile.py 50 51 52 53 54 55 56 57 58 59 60 61 62 63 @classmethod def from_geotransform ( cls , transform : Union [ affine . Affine , Tuple [ float , float , float , float , float , float ]], crs : Union [ str , int ], shape : Tuple [ int , int ]) -> Tile : \"\"\" Create a tile from a geotransform, a crs and a shape Args: transform: geotransform from pixel coordinates to CRS. crs: Coordinate Reference System of the tile shape: shape of the tile (in pixel) (@warning shape is the transpose of numpy shape) Returns: A new tile \"\"\" return cls ( crs_to_str ( crs ), Tile . _parse_geotransform ( transform ), shape ) from_record ( record , crs , resolution ) classmethod Create a tile that cover the record in the crs at a given resolution Warning: record.aoi must be loaded (with client.load_aoi()) Warning: Check the result.shape as the size might be huge ! Warning: the aoi is converted to the crs, but it might be imprecise at the borders Parameters: record ( Record ) \u2013 crs ( Union [ str , int ] ) \u2013 Coordinate Reference System of the tile resolution ( float ) \u2013 resolution of the pixel in the CRS Returns: Tile \u2013 A new tile Source code in geocube/entities/tile.py 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 @classmethod def from_record ( cls , record : entities . Record , crs : Union [ str , int ], resolution : float ) -> Tile : \"\"\" Create a tile that cover the record in the crs at a given resolution Warning: record.aoi must be loaded (with client.load_aoi()) Warning: Check the `result.shape` as the size might be huge ! Warning: the aoi is converted to the crs, but it might be imprecise at the borders Args: record: crs: Coordinate Reference System of the tile resolution: resolution of the pixel in the CRS Returns: A new tile \"\"\" return Tile . from_aoi ( record . aoi , crs , resolution ) plot ( tiles , ** kwargs ) staticmethod kwargs: additional arguments for utils.plot_aoi Source code in geocube/entities/tile.py 164 165 166 167 @staticmethod def plot ( tiles : List [ Tile ], ** kwargs ): \"\"\" kwargs: additional arguments for utils.plot_aoi \"\"\" return utils . plot_aoi ( Tile . to_geoseries ( tiles ), ** kwargs ) reshape ( i1 , j1 , i2 , j2 ) Create a new Tile using the coordinate pixels @warning inverse of numpy coordinates Source code in geocube/entities/tile.py 146 147 148 149 150 def reshape ( self , i1 , j1 , i2 , j2 ) -> entities . Tile : \"\"\" Create a new Tile using the coordinate pixels @warning inverse of numpy coordinates \"\"\" return Tile . from_bbox ( self . transform * ( i1 , j1 ) + self . transform * ( i2 , j2 ), self . crs , resolution = ( self . transform . a , self . transform . e )) to_geoseries ( tiles ) staticmethod return list of Tiles as geoseries Source code in geocube/entities/tile.py 159 160 161 162 @staticmethod def to_geoseries ( tiles : List [ Tile ]): \"\"\" return list of Tiles as geoseries \"\"\" return gpd . GeoSeries ( pd . concat ([ t . geoseries () . to_crs ( \"epsg:4326\" ) for t in tiles ]))","title":"Tile"},{"location":"user-guide/getcube/tile-reference/#tile","text":"Source code in geocube/entities/tile.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 @dataclass class Tile : crs : str transform : affine . Affine # Pixel to crs shape : Tuple [ int , int ] @classmethod def from_pb ( cls , pb : layouts_pb2 . Tile ): return cls ( pb . crs , affine . Affine ( pb . transform . b , pb . transform . c , pb . transform . a , pb . transform . e , pb . transform . f , pb . transform . d ), shape = ( int ( pb . size_px . width ), int ( pb . size_px . height )) ) @classmethod def from_geotransform ( cls , transform : Union [ affine . Affine , Tuple [ float , float , float , float , float , float ]], crs : Union [ str , int ], shape : Tuple [ int , int ]) -> Tile : \"\"\" Create a tile from a geotransform, a crs and a shape Args: transform: geotransform from pixel coordinates to CRS. crs: Coordinate Reference System of the tile shape: shape of the tile (in pixel) (@warning shape is the transpose of numpy shape) Returns: A new tile \"\"\" return cls ( crs_to_str ( crs ), Tile . _parse_geotransform ( transform ), shape ) @classmethod def from_record ( cls , record : entities . Record , crs : Union [ str , int ], resolution : float ) -> Tile : \"\"\" Create a tile that cover the record in the crs at a given resolution Warning: record.aoi must be loaded (with client.load_aoi()) Warning: Check the `result.shape` as the size might be huge ! Warning: the aoi is converted to the crs, but it might be imprecise at the borders Args: record: crs: Coordinate Reference System of the tile resolution: resolution of the pixel in the CRS Returns: A new tile \"\"\" return Tile . from_aoi ( record . aoi , crs , resolution ) @classmethod def from_bbox ( cls , bbox : Tuple [ float , float , float , float ], crs : Union [ str , int ], resolution : Union [ float , Tuple [ float , float ]]) -> Tile : \"\"\" Create a tile from a bbox, a crs and a resolution Args: bbox : (x1, y1, x2, y2) in crs coordinates crs : (Coordinate Reference System) of the tile resolution : of the pixel in the CRS Returns: A new tile \"\"\" rx , ry = resolution if isinstance ( resolution , tuple ) else ( resolution , - resolution ) x1 , y1 , x2 , y2 = bbox if math . copysign ( 1 , rx ) * ( x2 - x1 ) < 0 : x1 , x2 = x2 , x1 if math . copysign ( 1 , ry ) * ( y2 - y1 ) < 0 : y1 , y2 = y2 , y1 transform = geo_transform ( x1 , y1 , resolution ) sx , sy = ( ~ transform ) * ( x2 , y2 ) return cls ( crs_to_str ( crs ), transform , ( math . ceil ( sx ), math . ceil ( sy ))) @classmethod def from_aoi ( cls , aoi : geometry . MultiPolygon , crs : Union [ str , int ], resolution : Union [ float , Tuple [ float , float ]]) -> Tile : \"\"\" Args: aoi : multipolygon in 4326 coordinates crs : (Coordinate Reference System) of the tile resolution : of the pixel in the CRS Returns: A new tile \"\"\" return Tile . from_bbox ( gpd . GeoSeries ( aoi , crs = 4326 ) . to_crs ( crs ) . total_bounds , crs = crs , resolution = resolution ) def __str__ ( self ): return \"Tile {} \\n \" \\ \" transform: ( {} , {} {} , {} , {} {} ) \\n \" \\ \" bounds: {} {} \\n \" \\ \" shape: {} \\n \" \\ \" crs: {} \\n \" . format ( self . shape , self . transform . c , self . transform . a , self . transform . b , self . transform . f , self . transform . d , self . transform . e , self . transform * ( 0 , 0 ), self . transform * self . shape , self . shape , self . crs ) def __repr__ ( self ): return self . __str__ () def geoseries ( self ) -> gpd . GeoSeries : x1 , y1 = self . transform * ( 0 , 0 ) x2 , y2 = self . transform * self . shape p = geometry . Polygon ([[ x1 , y1 ], [ x1 , y2 ], [ x2 , y2 ], [ x2 , y1 ], [ x1 , y1 ]]) return gpd . GeoSeries ( p , crs = self . crs ) def geometry ( self , to_crs : Union [ str , int ] = None ): gs = self . geoseries () if to_crs is not None : gs = gs . to_crs ( crs_to_str ( to_crs )) return gs . iloc [ 0 ] def reshape ( self , i1 , j1 , i2 , j2 ) -> entities . Tile : \"\"\" Create a new Tile using the coordinate pixels @warning inverse of numpy coordinates \"\"\" return Tile . from_bbox ( self . transform * ( i1 , j1 ) + self . transform * ( i2 , j2 ), self . crs , resolution = ( self . transform . a , self . transform . e )) @staticmethod def _parse_geotransform ( transform : Union [ affine . Affine , Tuple [ float , float , float , float , float , float ]]) \\ -> affine . Affine : if isinstance ( transform , affine . Affine ): return transform return affine . Affine . from_gdal ( * transform ) @staticmethod def to_geoseries ( tiles : List [ Tile ]): \"\"\" return list of Tiles as geoseries \"\"\" return gpd . GeoSeries ( pd . concat ([ t . geoseries () . to_crs ( \"epsg:4326\" ) for t in tiles ])) @staticmethod def plot ( tiles : List [ Tile ], ** kwargs ): \"\"\" kwargs: additional arguments for utils.plot_aoi \"\"\" return utils . plot_aoi ( Tile . to_geoseries ( tiles ), ** kwargs )","title":"Tile"},{"location":"user-guide/getcube/tile-reference/#geocube.entities.Tile.from_aoi","text":"Parameters: aoi \u2013 multipolygon in 4326 coordinates crs \u2013 (Coordinate Reference System) of the tile resolution \u2013 of the pixel in the CRS Returns: Tile \u2013 A new tile Source code in geocube/entities/tile.py 105 106 107 108 109 110 111 112 113 114 115 116 117 118 @classmethod def from_aoi ( cls , aoi : geometry . MultiPolygon , crs : Union [ str , int ], resolution : Union [ float , Tuple [ float , float ]]) -> Tile : \"\"\" Args: aoi : multipolygon in 4326 coordinates crs : (Coordinate Reference System) of the tile resolution : of the pixel in the CRS Returns: A new tile \"\"\" return Tile . from_bbox ( gpd . GeoSeries ( aoi , crs = 4326 ) . to_crs ( crs ) . total_bounds , crs = crs , resolution = resolution )","title":"from_aoi"},{"location":"user-guide/getcube/tile-reference/#geocube.entities.Tile.from_bbox","text":"Create a tile from a bbox, a crs and a resolution Args: bbox : (x1, y1, x2, y2) in crs coordinates crs : (Coordinate Reference System) of the tile resolution : of the pixel in the CRS Returns: Tile \u2013 A new tile Source code in geocube/entities/tile.py 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 @classmethod def from_bbox ( cls , bbox : Tuple [ float , float , float , float ], crs : Union [ str , int ], resolution : Union [ float , Tuple [ float , float ]]) -> Tile : \"\"\" Create a tile from a bbox, a crs and a resolution Args: bbox : (x1, y1, x2, y2) in crs coordinates crs : (Coordinate Reference System) of the tile resolution : of the pixel in the CRS Returns: A new tile \"\"\" rx , ry = resolution if isinstance ( resolution , tuple ) else ( resolution , - resolution ) x1 , y1 , x2 , y2 = bbox if math . copysign ( 1 , rx ) * ( x2 - x1 ) < 0 : x1 , x2 = x2 , x1 if math . copysign ( 1 , ry ) * ( y2 - y1 ) < 0 : y1 , y2 = y2 , y1 transform = geo_transform ( x1 , y1 , resolution ) sx , sy = ( ~ transform ) * ( x2 , y2 ) return cls ( crs_to_str ( crs ), transform , ( math . ceil ( sx ), math . ceil ( sy )))","title":"from_bbox"},{"location":"user-guide/getcube/tile-reference/#geocube.entities.Tile.from_geotransform","text":"Create a tile from a geotransform, a crs and a shape Args: transform: geotransform from pixel coordinates to CRS. crs: Coordinate Reference System of the tile shape: shape of the tile (in pixel) (@warning shape is the transpose of numpy shape) Returns: Tile \u2013 A new tile Source code in geocube/entities/tile.py 50 51 52 53 54 55 56 57 58 59 60 61 62 63 @classmethod def from_geotransform ( cls , transform : Union [ affine . Affine , Tuple [ float , float , float , float , float , float ]], crs : Union [ str , int ], shape : Tuple [ int , int ]) -> Tile : \"\"\" Create a tile from a geotransform, a crs and a shape Args: transform: geotransform from pixel coordinates to CRS. crs: Coordinate Reference System of the tile shape: shape of the tile (in pixel) (@warning shape is the transpose of numpy shape) Returns: A new tile \"\"\" return cls ( crs_to_str ( crs ), Tile . _parse_geotransform ( transform ), shape )","title":"from_geotransform"},{"location":"user-guide/getcube/tile-reference/#geocube.entities.Tile.from_record","text":"Create a tile that cover the record in the crs at a given resolution Warning: record.aoi must be loaded (with client.load_aoi()) Warning: Check the result.shape as the size might be huge ! Warning: the aoi is converted to the crs, but it might be imprecise at the borders Parameters: record ( Record ) \u2013 crs ( Union [ str , int ] ) \u2013 Coordinate Reference System of the tile resolution ( float ) \u2013 resolution of the pixel in the CRS Returns: Tile \u2013 A new tile Source code in geocube/entities/tile.py 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 @classmethod def from_record ( cls , record : entities . Record , crs : Union [ str , int ], resolution : float ) -> Tile : \"\"\" Create a tile that cover the record in the crs at a given resolution Warning: record.aoi must be loaded (with client.load_aoi()) Warning: Check the `result.shape` as the size might be huge ! Warning: the aoi is converted to the crs, but it might be imprecise at the borders Args: record: crs: Coordinate Reference System of the tile resolution: resolution of the pixel in the CRS Returns: A new tile \"\"\" return Tile . from_aoi ( record . aoi , crs , resolution )","title":"from_record"},{"location":"user-guide/getcube/tile-reference/#geocube.entities.Tile.plot","text":"kwargs: additional arguments for utils.plot_aoi Source code in geocube/entities/tile.py 164 165 166 167 @staticmethod def plot ( tiles : List [ Tile ], ** kwargs ): \"\"\" kwargs: additional arguments for utils.plot_aoi \"\"\" return utils . plot_aoi ( Tile . to_geoseries ( tiles ), ** kwargs )","title":"plot"},{"location":"user-guide/getcube/tile-reference/#geocube.entities.Tile.reshape","text":"Create a new Tile using the coordinate pixels @warning inverse of numpy coordinates Source code in geocube/entities/tile.py 146 147 148 149 150 def reshape ( self , i1 , j1 , i2 , j2 ) -> entities . Tile : \"\"\" Create a new Tile using the coordinate pixels @warning inverse of numpy coordinates \"\"\" return Tile . from_bbox ( self . transform * ( i1 , j1 ) + self . transform * ( i2 , j2 ), self . crs , resolution = ( self . transform . a , self . transform . e ))","title":"reshape"},{"location":"user-guide/getcube/tile-reference/#geocube.entities.Tile.to_geoseries","text":"return list of Tiles as geoseries Source code in geocube/entities/tile.py 159 160 161 162 @staticmethod def to_geoseries ( tiles : List [ Tile ]): \"\"\" return list of Tiles as geoseries \"\"\" return gpd . GeoSeries ( pd . concat ([ t . geoseries () . to_crs ( \"epsg:4326\" ) for t in tiles ]))","title":"to_geoseries"}]}